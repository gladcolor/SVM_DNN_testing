{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE822_HW2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1jS19KitmzfFJ7EHKaibSYIn9UnBMQbrl",
      "authorship_tag": "ABX9TyM2i685Gw2C7jlGLGawfap4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gladcolor/SVM_DNN_testing/blob/master/CSCE822_HW2_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PEaZ-2GOFjp"
      },
      "source": [
        "# Classification using SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIBmefr5003e"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWb6nL5k31q"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "# import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.linear_model import LinearRegression as LR\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v7rzRQdFVpI",
        "outputId": "5bf180f3-4731-49c7-c153-310f4b9cd09f"
      },
      "source": [
        "cwd = r'/content/drive/MyDrive/USC_courses/CSCE822'\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "% cd $cwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/USC_courses/CSCE822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZDU1PIxnTs"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICR2HJwxq37"
      },
      "source": [
        "def print_str_unique(df):\n",
        "    for col in df.columns:\n",
        "        if original_data.dtypes[col] == np.object:            \n",
        "            unique_cnt = len(df[col].unique())\n",
        "            print(f'Column {col.rjust(13)} has {unique_cnt:5} unique values.')\n",
        "\n",
        "def count_column_nan(df):\n",
        "    row_cnt = len(df)\n",
        "    for col in df.columns:\n",
        "        nan_cnt = df[col].isna().sum()\n",
        "        percent_str = f'({(nan_cnt / row_cnt * 100):3.1f}%)'.rjust(7)\n",
        "        print(f'Column {str(col).rjust(13)} has {nan_cnt:4} {percent_str} nan values.')       \n",
        "\n",
        "def impute_df(df, strategy=\"most_frequent\"):\n",
        "    \n",
        "    numeric_cols = ['BuildingArea', 'YearBuilt', 'Car']\n",
        "    nominal_cols = ['CouncilArea']\n",
        "\n",
        "    my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "    council_area_with_imputed_values = my_imputer.fit_transform(df[nominal_cols])\n",
        "    imputed_df = df.copy()\n",
        "    imputed_df.loc[:, nominal_cols] = council_area_with_imputed_values\n",
        "\n",
        "\n",
        "    if strategy == \"most_frequent\":\n",
        "        my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "        data_with_imputed_values = my_imputer.fit_transform(df)        \n",
        "        imputed_df.loc[:, :] = data_with_imputed_values\n",
        "\n",
        "    if strategy == \"mean\":\n",
        "        my_imputer = SimpleImputer(strategy=\"mean\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    if strategy == \"median\":\n",
        "        my_imputer = SimpleImputer(strategy=\"median\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    return imputed_df\n",
        "\n",
        "def encode_dates(imputed_df):\n",
        "    imputed_df['Date'] = pd.to_datetime(imputed_df['Date']) \n",
        "    imputed_df['Ori_Date'] = pd.to_datetime('1970-01-01', format='YY-m-d', errors='ignore')\n",
        "    imputed_df['Ori_Date'] = pd.to_datetime(imputed_df['Ori_Date'])\n",
        "    imputed_df['delta_days'] = imputed_df['Date'] - imputed_df['Ori_Date']\n",
        "    imputed_df['delta_days'] = imputed_df['delta_days'].dt.days\n",
        "    imputed_df = imputed_df.drop(columns=['Date', 'Ori_Date'])\n",
        "     \n",
        "    return imputed_df\n",
        "\n",
        "\n",
        "\n",
        "def encoder_nominals(imputed_df, encode_method='one_hot'):\n",
        "    # print(f'Encode methods: {ENCODING_METHODS_DICT.keys()} \\n')\n",
        "    \n",
        "    ce_encoder = ENCODING_METHODS_DICT[encode_method](cols = ENCODING_COLUMNS)\n",
        "\n",
        "    y = imputed_df['Price_class'].copy()\n",
        "    \n",
        "    for drop_column in DROPPED_COLUMNS:\n",
        "        try:\n",
        "            imputed_df = imputed_df.drop(columns=drop_column).copy()\n",
        "        except:\n",
        "            pass\n",
        "            # print(f'Columns: {drop_column} have already dropped before.')\n",
        "\n",
        "    encoded_df = ce_encoder.fit_transform(imputed_df, y=y) \n",
        "\n",
        "    return encoded_df\n",
        "\n",
        "def assign_price_class(imputed_df):\n",
        "    row_cnt = len(imputed_df)\n",
        "    price_class_cnt = 5\n",
        "    class_step = int(row_cnt / price_class_cnt)\n",
        "    price_bins = list(range(class_step, row_cnt,  class_step))\n",
        "\n",
        "    imputed_df.loc[0:price_bins[0], 'Price_class'] = '0' # 'bottom_value'\n",
        "    imputed_df.loc[price_bins[0]:price_bins[1], 'Price_class'] = '1' # 'low_value'\n",
        "    imputed_df.loc[price_bins[1]:price_bins[2], 'Price_class'] = '2' # 'medium_value'\n",
        "    imputed_df.loc[price_bins[2]:price_bins[3], 'Price_class'] = '3' # 'high_value'\n",
        "    imputed_df.loc[price_bins[3]:row_cnt, 'Price_class'] = '4'  #  'top_value'\n",
        "\n",
        "    imputed_df['Price_class'] = imputed_df['Price_class'].astype(int)\n",
        "\n",
        "    # gb = imputed_df.groupby('Price_class')['Price_class'].count().to_frame()\n",
        "    # gb.columns = ['Count']\n",
        "    # custom_dict = {'bottom_value': 0, 'low_value': 1, 'medium_value': 2, 'high_value': 3, 'top_value': 4}\n",
        "    # gb.sort_index(key=lambda x: x.map(custom_dict))\n",
        "    # print(\"Price class counts:\")\n",
        "    return imputed_df    \n",
        "\n",
        "\n",
        "def split_data(encoded_df):\n",
        "    X = encoded_df.drop(columns=['Price_class'])\n",
        "    y = encoded_df['Price_class']\n",
        "\n",
        "    train_ratio = 0.75\n",
        "    validation_ratio = 0.10\n",
        "    test_ratio = 0.15\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size= (1 - train_ratio), random_state = 0)\n",
        "\n",
        "    xVal, xTest, yVal, yTest = train_test_split(xTest, yTest, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 0) \n",
        "\n",
        "    \n",
        "    return xTrain, yTrain, xVal, yVal, xTest, yTest   \n",
        "\n",
        "def standardize_data(encoded_df, class_col='Price_class'):\n",
        "    labels = encoded_df[class_col].copy()\n",
        "    data_df = encoded_df.drop(columns=[class_col])\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    scaler.fit(data_df) \n",
        "    data_df.iloc[:, :] = scaler.transform(data_df)\n",
        "    data_df.loc[:, class_col] = labels\n",
        "    return data_df\n",
        "           \n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIMZpvts08nT"
      },
      "source": [
        "## Load and understand the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-o6yMjxeL4am",
        "outputId": "48fa9490-3949-4928-fd01-7869882f56d4"
      },
      "source": [
        "test_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000.zip'\n",
        "test_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "train_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000.zip'\n",
        "train_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000_Label.zip'\n",
        "\n",
        "train_df = pd.read_csv(train_csv, header=None)\n",
        "train_label_df = pd.read_csv(train_label_csv, header=None)\n",
        "test_df = pd.read_csv(test_csv, header=None)\n",
        "test_label_df = pd.read_csv(test_label_csv, header=None)\n",
        "\n",
        "print(\"Training sets samples:\")\n",
        "train_df.sample(4)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets samples:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>300</th>\n",
              "      <th>301</th>\n",
              "      <th>302</th>\n",
              "      <th>303</th>\n",
              "      <th>304</th>\n",
              "      <th>305</th>\n",
              "      <th>306</th>\n",
              "      <th>307</th>\n",
              "      <th>308</th>\n",
              "      <th>309</th>\n",
              "      <th>310</th>\n",
              "      <th>311</th>\n",
              "      <th>312</th>\n",
              "      <th>313</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>197000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91</td>\n",
              "      <td>1</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>170</td>\n",
              "      <td>419</td>\n",
              "      <td>447</td>\n",
              "      <td>315</td>\n",
              "      <td>7</td>\n",
              "      <td>911</td>\n",
              "      <td>350</td>\n",
              "      <td>854</td>\n",
              "      <td>310</td>\n",
              "      <td>2114</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>6006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>1696</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>1978</td>\n",
              "      <td>332</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>87</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>53</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>83</td>\n",
              "      <td>64</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>66</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>42</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>51</td>\n",
              "      <td>8</td>\n",
              "      <td>85</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>18</td>\n",
              "      <td>346</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6532</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>96</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>458</td>\n",
              "      <td>481</td>\n",
              "      <td>381</td>\n",
              "      <td>7</td>\n",
              "      <td>871</td>\n",
              "      <td>310</td>\n",
              "      <td>745</td>\n",
              "      <td>250</td>\n",
              "      <td>2463</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>705.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27</td>\n",
              "      <td>36</td>\n",
              "      <td>2380</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>389</td>\n",
              "      <td>...</td>\n",
              "      <td>91</td>\n",
              "      <td>89</td>\n",
              "      <td>47</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>47</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>15</td>\n",
              "      <td>76</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>23</td>\n",
              "      <td>290</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>11</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>410</td>\n",
              "      <td>442</td>\n",
              "      <td>301</td>\n",
              "      <td>6</td>\n",
              "      <td>513</td>\n",
              "      <td>330</td>\n",
              "      <td>509</td>\n",
              "      <td>300</td>\n",
              "      <td>1216</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>2078.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>36</td>\n",
              "      <td>32</td>\n",
              "      <td>1128</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>1965</td>\n",
              "      <td>1968</td>\n",
              "      <td>308</td>\n",
              "      <td>...</td>\n",
              "      <td>78</td>\n",
              "      <td>74</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>66</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>169</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3687</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>21</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>483</td>\n",
              "      <td>512</td>\n",
              "      <td>393</td>\n",
              "      <td>7</td>\n",
              "      <td>746</td>\n",
              "      <td>290</td>\n",
              "      <td>651</td>\n",
              "      <td>250</td>\n",
              "      <td>1857</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>2318.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25</td>\n",
              "      <td>14</td>\n",
              "      <td>1522</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>1988</td>\n",
              "      <td>1986</td>\n",
              "      <td>408</td>\n",
              "      <td>...</td>\n",
              "      <td>84</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>77</td>\n",
              "      <td>63</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>5</td>\n",
              "      <td>80</td>\n",
              "      <td>48</td>\n",
              "      <td>18</td>\n",
              "      <td>83</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>18</td>\n",
              "      <td>339</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 334 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1         2    3         4    ...  329  330  331  332  333\n",
              "939        1.0   40       1.0   40  197000.0  ...    3   30   18  346  132\n",
              "6532  999000.0   46       1.0   46  196000.0  ...    2   39   23  290  205\n",
              "3792  999000.0   46  999000.0   46  196000.0  ...    2   12    7  169  117\n",
              "3687  999000.0   46       1.0   46  196000.0  ...    4   58   18  339  149\n",
              "\n",
              "[4 rows x 334 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "ESJ1v2ctmXMn",
        "outputId": "22c73e20-f11f-4e85-c40f-5a7c762f66d5"
      },
      "source": [
        "print(\"County nan data:\")\n",
        "\n",
        "print(f\"Train data have {train_df.isna().sum().sum()} nan values.\")\n",
        "print(f\"Test data have {test_df.isna().sum().sum()} nan values.\")\n",
        "\n",
        "train_1 = train_df[train_label_df[0] == 1]\n",
        "train_0 = train_df[train_label_df[0] == 0]\n",
        "\n",
        "def sample_train_dataset(positive_count=len(train_1), negative_count=len(train_1)):\n",
        "    positive_count = len(train_1)\n",
        "    negative_count = len(train_1)\n",
        "\n",
        "    balanced_train = np.concatenate((train_1.sample(positive_count, replace=True), train_0.sample(negative_count, replace=True)), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    print(f\"Positive sample counts in the training set: {positive_count}\")\n",
        "    print(f\"Negative sample counts in the training set: {negative_count}\")\n",
        "\n",
        "    return balanced_train, balanced_train_label\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Positive sample counts: {len(train_1)}\")\n",
        "print(f\"Negative sample counts: {len(train_0)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "County nan data:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-503c67d49420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"County nan data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train data have {train_df.isna().sum().sum()} nan values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test data have {test_df.isna().sum().sum()} nan values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIJ1ofkC2EWC"
      },
      "source": [
        "## Train 10 SVM models in an ensemble learning manner\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBFsjulHaEzl"
      },
      "source": [
        "### Train 10 models witouth cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SPV2nT8aFWq",
        "outputId": "c5d5f43d-761d-44a5-8f96-3e79ce5f94c9"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "trained_model_list = []\n",
        "\n",
        "score_roc_auc_list = []\n",
        "score_precision_list = []\n",
        "score_recall_list = []\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "     # create a balancd training set\n",
        "    train_1 = train_df[train_label_df[0] == 1].sample(frac=1)  # shuffle\n",
        "\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    # Use SVM\n",
        "    # clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "    #                                           kernel='rbf',\n",
        "    #                                           verbose=True, probability=True))\n",
        "    \n",
        "    # Use random forest\n",
        "    clf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=500))\n",
        "\n",
        "    clf.fit(balanced_train, balanced_train_label)\n",
        "\n",
        "    trained_model_list.append(clf)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "Training # 2 model...\n",
            "Training # 3 model...\n",
            "Training # 4 model...\n",
            "Training # 5 model...\n",
            "Training # 6 model...\n",
            "Training # 7 model...\n",
            "Training # 8 model...\n",
            "Training # 9 model...\n",
            "Training # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boerEWK9mXbH"
      },
      "source": [
        "### Evaluate the trained 10 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtWI6u3bQrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245d8be4-0f9c-4b22-995a-b7bed8c5a7df"
      },
      "source": [
        "print(\"Evaluating...\")\n",
        "test_pred_list = []\n",
        "for idx, clf in enumerate(trained_model_list):\n",
        "    print(f\"Testing # {idx + 1} model...\")\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n",
            "Testing # 1 model...\n",
            "Testing # 2 model...\n",
            "Testing # 3 model...\n",
            "Testing # 4 model...\n",
            "Testing # 5 model...\n",
            "Testing # 6 model...\n",
            "Testing # 7 model...\n",
            "Testing # 8 model...\n",
            "Testing # 9 model...\n",
            "Testing # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggjXh9sZkvZw"
      },
      "source": [
        "### Print out assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ8Uu_LWktVA",
        "outputId": "f6ed9cbd-d17a-4401-f84d-b2af22b17053"
      },
      "source": [
        "test_pred_all = np.array(test_pred_list)\n",
        "\n",
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "\n",
        "recall_score = metrics.recall_score(np.array(test_label_df), pred_label, average='macro')\n",
        "mcc_score = metrics.matthews_corrcoef(np.array(test_label_df), pred_label)\n",
        "roc_auc_score = metrics.roc_auc_score(test_label_df, test_pred_all[:, :, 1].mean(axis=0), average=None)\n",
        "\n",
        "print(\"precision_score:\", precision_score)\n",
        "print(\"recall_score:\", recall_score)\n",
        "print(\"mcc_score:\", mcc_score)\n",
        "print(\"roc_auc_score:\", roc_auc_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_score: 0.5383174018953414\n",
            "recall_score: 0.6096338049093124\n",
            "mcc_score: 0.12962843151138675\n",
            "roc_auc_score: 0.6366664750885578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4z2zIzAie9p"
      },
      "source": [
        "### Save the predicted label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2yYSrHbiejk"
      },
      "source": [
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "np.savetxt('predict.csv', pred_label, fmt='%d' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCMeGlv0xCxn"
      },
      "source": [
        "## Train 10 models with cross validation (validating scores: precision, recall, and ROC area)\n",
        "Will take about 30 min to train 300 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjcBiDkexMev",
        "outputId": "e8cf3a93-5049-4fa1-9081-edf8d6b35429"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "score_accuracy_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "def simple_matthews_corrcoef(true_np, predict_np):\n",
        "    cm = metrics.confusion_matrix(true_np, predict_np)\n",
        "    assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "\n",
        "    return MCC\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # # calcuate precision, recall, AUC. actually train the model 300 times.\n",
        "    score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    trained_model_list.append(clf)\n",
        "    scores_list.append(scores)\n",
        "\n",
        "    scores_precision_list.append(score_precision)\n",
        "    scores_recall_list.append(score_recall)\n",
        "    # scores_roc_auc_list.append(score_roc_auc)\n",
        "\n",
        "    # To calculate MCC only, actally train 100 models.\n",
        "    # score_accuracy = cross_validate(clf, balanced_train, balanced_train_label, cv=10, return_estimator=True)\n",
        "    # score_accuracy_list.append(score_accuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 2 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 3 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 4 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 5 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 6 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 7 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 8 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 9 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 10 model...\n",
            "[LibSVM][LibSVM][LibSVM]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7DzfmynGXm1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPNIsc_BGlJk"
      },
      "source": [
        "## Train 10 models with cross validation (validating scores:  Matthew coefficient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnN9j0L_Gfyr",
        "outputId": "8e6d402c-502c-4c34-e3f0-14af94d835e4"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "score_accuracy_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "def simple_matthews_corrcoef(true_np, predict_np):\n",
        "    cm = metrics.confusion_matrix(true_np, predict_np)\n",
        "    assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "\n",
        "    return MCC\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # calcuate precision, recall, AUC. actually train the model 300 times.\n",
        "    # score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    # score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    # score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    # print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    # print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    # print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    # trained_model_list.append(clf)\n",
        "    # scores_list.append(scores)\n",
        "\n",
        "    # scores_precision_list.append(score_precision)\n",
        "    # scores_recall_list.append(score_recall)\n",
        "    # scores_roc_auc_list.append(score_roc_auc)\n",
        "\n",
        "    # To calculate MCC only, actally train 100 models.\n",
        "    score_accuracy = cross_validate(clf, balanced_train, balanced_train_label, cv=10, return_estimator=True)\n",
        "    score_accuracy_list.append(score_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 2 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 3 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 4 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 5 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 6 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 7 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 8 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 9 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 10 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpKVvB2mDsHS",
        "outputId": "6d557517-1a89-4892-fb21-41947e1d800d"
      },
      "source": [
        "# Evaluate models (100 models in total)\n",
        "def test_mcc_from_cross_validation(score_accuracy_list):\n",
        "    mcc_list = []\n",
        "    for idx, fold in enumerate(score_accuracy_list):\n",
        "        print(f\"Evaluating #{idx + 1} fold...\")\n",
        "        clfs = fold['estimator']\n",
        "        for idx2, clf in enumerate(clfs):\n",
        "            predict_labels = clf.predict(test_df)\n",
        "            mcc = metrics.matthews_corrcoef(test_label_df, predict_labels)\n",
        "            mcc_list.append(mcc)\n",
        "            print(f'Fold {idx + 1}, classifier # {idx2 + 1}, matthews_corrcoef: {mcc:0.4f}')\n",
        "    mcc_np = np.array(mcc_list)\n",
        "    return mcc_np.mean()\n",
        "\n",
        "mcc_mean = test_mcc_from_cross_validation(score_accuracy_list)\n",
        "print()\n",
        "print(\"MCC mean is: %0.4f\" % mcc_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating #1 fold...\n",
            "Fold 1, classifier # 1, matthews_corrcoef: 0.1127\n",
            "Fold 1, classifier # 2, matthews_corrcoef: 0.1097\n",
            "Fold 1, classifier # 3, matthews_corrcoef: 0.1204\n",
            "Fold 1, classifier # 4, matthews_corrcoef: 0.1191\n",
            "Fold 1, classifier # 5, matthews_corrcoef: 0.1175\n",
            "Fold 1, classifier # 6, matthews_corrcoef: 0.1200\n",
            "Fold 1, classifier # 7, matthews_corrcoef: 0.1165\n",
            "Fold 1, classifier # 8, matthews_corrcoef: 0.1136\n",
            "Fold 1, classifier # 9, matthews_corrcoef: 0.1173\n",
            "Fold 1, classifier # 10, matthews_corrcoef: 0.1226\n",
            "Evaluating #2 fold...\n",
            "Fold 2, classifier # 1, matthews_corrcoef: 0.1211\n",
            "Fold 2, classifier # 2, matthews_corrcoef: 0.1213\n",
            "Fold 2, classifier # 3, matthews_corrcoef: 0.1277\n",
            "Fold 2, classifier # 4, matthews_corrcoef: 0.1242\n",
            "Fold 2, classifier # 5, matthews_corrcoef: 0.1269\n",
            "Fold 2, classifier # 6, matthews_corrcoef: 0.1174\n",
            "Fold 2, classifier # 7, matthews_corrcoef: 0.1184\n",
            "Fold 2, classifier # 8, matthews_corrcoef: 0.1253\n",
            "Fold 2, classifier # 9, matthews_corrcoef: 0.1290\n",
            "Fold 2, classifier # 10, matthews_corrcoef: 0.1299\n",
            "Evaluating #3 fold...\n",
            "Fold 3, classifier # 1, matthews_corrcoef: 0.1192\n",
            "Fold 3, classifier # 2, matthews_corrcoef: 0.1215\n",
            "Fold 3, classifier # 3, matthews_corrcoef: 0.1262\n",
            "Fold 3, classifier # 4, matthews_corrcoef: 0.1166\n",
            "Fold 3, classifier # 5, matthews_corrcoef: 0.1159\n",
            "Fold 3, classifier # 6, matthews_corrcoef: 0.1230\n",
            "Fold 3, classifier # 7, matthews_corrcoef: 0.1232\n",
            "Fold 3, classifier # 8, matthews_corrcoef: 0.1243\n",
            "Fold 3, classifier # 9, matthews_corrcoef: 0.1207\n",
            "Fold 3, classifier # 10, matthews_corrcoef: 0.1234\n",
            "Evaluating #4 fold...\n",
            "Fold 4, classifier # 1, matthews_corrcoef: 0.1174\n",
            "Fold 4, classifier # 2, matthews_corrcoef: 0.1182\n",
            "Fold 4, classifier # 3, matthews_corrcoef: 0.1130\n",
            "Fold 4, classifier # 4, matthews_corrcoef: 0.1154\n",
            "Fold 4, classifier # 5, matthews_corrcoef: 0.1169\n",
            "Fold 4, classifier # 6, matthews_corrcoef: 0.1210\n",
            "Fold 4, classifier # 7, matthews_corrcoef: 0.1256\n",
            "Fold 4, classifier # 8, matthews_corrcoef: 0.1164\n",
            "Fold 4, classifier # 9, matthews_corrcoef: 0.1182\n",
            "Fold 4, classifier # 10, matthews_corrcoef: 0.1210\n",
            "Evaluating #5 fold...\n",
            "Fold 5, classifier # 1, matthews_corrcoef: 0.1080\n",
            "Fold 5, classifier # 2, matthews_corrcoef: 0.1110\n",
            "Fold 5, classifier # 3, matthews_corrcoef: 0.1048\n",
            "Fold 5, classifier # 4, matthews_corrcoef: 0.1101\n",
            "Fold 5, classifier # 5, matthews_corrcoef: 0.1167\n",
            "Fold 5, classifier # 6, matthews_corrcoef: 0.0942\n",
            "Fold 5, classifier # 7, matthews_corrcoef: 0.1022\n",
            "Fold 5, classifier # 8, matthews_corrcoef: 0.1101\n",
            "Fold 5, classifier # 9, matthews_corrcoef: 0.1052\n",
            "Fold 5, classifier # 10, matthews_corrcoef: 0.1067\n",
            "Evaluating #6 fold...\n",
            "Fold 6, classifier # 1, matthews_corrcoef: 0.1216\n",
            "Fold 6, classifier # 2, matthews_corrcoef: 0.1229\n",
            "Fold 6, classifier # 3, matthews_corrcoef: 0.1287\n",
            "Fold 6, classifier # 4, matthews_corrcoef: 0.1139\n",
            "Fold 6, classifier # 5, matthews_corrcoef: 0.1173\n",
            "Fold 6, classifier # 6, matthews_corrcoef: 0.1239\n",
            "Fold 6, classifier # 7, matthews_corrcoef: 0.1198\n",
            "Fold 6, classifier # 8, matthews_corrcoef: 0.1238\n",
            "Fold 6, classifier # 9, matthews_corrcoef: 0.1259\n",
            "Fold 6, classifier # 10, matthews_corrcoef: 0.1221\n",
            "Evaluating #7 fold...\n",
            "Fold 7, classifier # 1, matthews_corrcoef: 0.1165\n",
            "Fold 7, classifier # 2, matthews_corrcoef: 0.1242\n",
            "Fold 7, classifier # 3, matthews_corrcoef: 0.1143\n",
            "Fold 7, classifier # 4, matthews_corrcoef: 0.1159\n",
            "Fold 7, classifier # 5, matthews_corrcoef: 0.1234\n",
            "Fold 7, classifier # 6, matthews_corrcoef: 0.1124\n",
            "Fold 7, classifier # 7, matthews_corrcoef: 0.1170\n",
            "Fold 7, classifier # 8, matthews_corrcoef: 0.1118\n",
            "Fold 7, classifier # 9, matthews_corrcoef: 0.1254\n",
            "Fold 7, classifier # 10, matthews_corrcoef: 0.1205\n",
            "Evaluating #8 fold...\n",
            "Fold 8, classifier # 1, matthews_corrcoef: 0.1289\n",
            "Fold 8, classifier # 2, matthews_corrcoef: 0.1270\n",
            "Fold 8, classifier # 3, matthews_corrcoef: 0.1163\n",
            "Fold 8, classifier # 4, matthews_corrcoef: 0.1280\n",
            "Fold 8, classifier # 5, matthews_corrcoef: 0.1267\n",
            "Fold 8, classifier # 6, matthews_corrcoef: 0.1303\n",
            "Fold 8, classifier # 7, matthews_corrcoef: 0.1253\n",
            "Fold 8, classifier # 8, matthews_corrcoef: 0.1297\n",
            "Fold 8, classifier # 9, matthews_corrcoef: 0.1261\n",
            "Fold 8, classifier # 10, matthews_corrcoef: 0.1243\n",
            "Evaluating #9 fold...\n",
            "Fold 9, classifier # 1, matthews_corrcoef: 0.1271\n",
            "Fold 9, classifier # 2, matthews_corrcoef: 0.1258\n",
            "Fold 9, classifier # 3, matthews_corrcoef: 0.1241\n",
            "Fold 9, classifier # 4, matthews_corrcoef: 0.1217\n",
            "Fold 9, classifier # 5, matthews_corrcoef: 0.1237\n",
            "Fold 9, classifier # 6, matthews_corrcoef: 0.1202\n",
            "Fold 9, classifier # 7, matthews_corrcoef: 0.1253\n",
            "Fold 9, classifier # 8, matthews_corrcoef: 0.1216\n",
            "Fold 9, classifier # 9, matthews_corrcoef: 0.1278\n",
            "Fold 9, classifier # 10, matthews_corrcoef: 0.1276\n",
            "Evaluating #10 fold...\n",
            "Fold 10, classifier # 1, matthews_corrcoef: 0.1147\n",
            "Fold 10, classifier # 2, matthews_corrcoef: 0.1107\n",
            "Fold 10, classifier # 3, matthews_corrcoef: 0.1180\n",
            "Fold 10, classifier # 4, matthews_corrcoef: 0.1208\n",
            "Fold 10, classifier # 5, matthews_corrcoef: 0.1233\n",
            "Fold 10, classifier # 6, matthews_corrcoef: 0.1184\n",
            "Fold 10, classifier # 7, matthews_corrcoef: 0.1293\n",
            "Fold 10, classifier # 8, matthews_corrcoef: 0.1211\n",
            "Fold 10, classifier # 9, matthews_corrcoef: 0.1137\n",
            "Fold 10, classifier # 10, matthews_corrcoef: 0.1160\n",
            "\n",
            "MCC mean is: 0.1197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bFE4MffDrmP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzAoSjPJCdwi",
        "outputId": "c170318d-3413-4280-a449-ba0b51039bda"
      },
      "source": [
        "score_accuracy_list[8]['test_score'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.614932305263797"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJtSZ5SNCxeB"
      },
      "source": [
        "predict_labels = score_accuracy_list[0]['estimator'][0].predict(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zWXt8xfDXnT",
        "outputId": "8e7fd9a4-62d7-4ad1-9baa-9edad80386be"
      },
      "source": [
        "mcc = metrics.matthews_corrcoef(test_label_df, predict_labels)\n",
        "mcc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11273251475330465"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V7nz13H-xHP"
      },
      "source": [
        "clf.predict()\n",
        "\n",
        "# calculate MCC\n",
        "mcc_score = simple_matthews_corrcoef())\n",
        "scores_mcc_list.append(mcc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVczoNnFnnqB"
      },
      "source": [
        "# Program to calculate model performance from two label files: Precision, Recall, MCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgq9pUAMn065"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tOujpNPnzES"
      },
      "source": [
        "label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "label_df = pd.read_csv(label_csv)\n",
        "predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "\n",
        "true_np = np.array(label_df)\n",
        "predict_np = np.array(predict_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UpvkGmX-Zck"
      },
      "source": [
        "## Define metrics class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrINqCKqo2_7",
        "outputId": "0999ba8f-70fb-4224-fd06-515c1dc97711"
      },
      "source": [
        "class simple_metrics():\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_data(true_csv, predict_csv):\n",
        "        true_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "        predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "        true_df = pd.read_csv(true_csv)\n",
        "        predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "        true_np = np.array(true_df)\n",
        "        predict_np = np.array(predict_df)\n",
        "\n",
        "        return true_np, predict_np\n",
        "\n",
        "    @staticmethod\n",
        "    def get_confusion_matrix(true_np, predict_np): # inputs: should be integer numpy array (1D), using the same class index schema.\n",
        "        true_unique = np.unique(true_np)\n",
        "        predict_unique = np.unique(predict_np)\n",
        "\n",
        "        cm = np.zeros((len(true_unique), len(true_unique)), dtype=int)   # cm: confusion_matrix, row is actual, column is predicted\n",
        "\n",
        "        for true_, pred in zip(true_np[:].flatten(), predict_np[:].flatten()):\n",
        "            cm[true_, pred] += 1\n",
        "            # print(true_, pred)\n",
        "        return cm\n",
        "\n",
        "    @staticmethod\n",
        "    def precision_recall_score(true_csv, predict_csv):  # CSV file has one column only withoud header.\n",
        "        true_np, predict_np = simple_metrics._load_data(true_csv, predict_csv)\n",
        "        confusion_matrix = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        class_cnt = confusion_matrix.shape[0]\n",
        "        precisions = np.zeros((class_cnt))\n",
        "        recalls = np.zeros((class_cnt))\n",
        "\n",
        " \n",
        "\n",
        "        # compute recall, precision\n",
        "        for c in range(class_cnt):\n",
        "            TP = confusion_matrix[c, c]\n",
        "            TP_FP = confusion_matrix[c, :].sum()\n",
        "            TP_FN = confusion_matrix[:, c].sum()\n",
        "            recalls[c] = TP / TP_FP\n",
        "            precisions[c] = TP / TP_FN\n",
        "\n",
        "        return precisions, recalls\n",
        "\n",
        "    @staticmethod\n",
        "    def matthews_corrcoef(true_csv, predict_csv): # CSV file has one column only withoud header.\n",
        "        MCC = 0\n",
        "        # compute MCC, current for binary classification only\n",
        "        \n",
        "        cm = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "        TP = cm[1, 1]\n",
        "        TN = cm[0, 0]\n",
        "        FP = cm[0, 1]\n",
        "        FN = cm[1, 0]\n",
        "\n",
        "        MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "        # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient\n",
        "        return MCC\n",
        "\n",
        "class_precision, class_recall = simple_metrics.precision_recall_score(label_csv, predict_csv)\n",
        "MCC =  simple_metrics.matthews_corrcoef(label_csv, predict_csv)\n",
        "\n",
        "print(\"My results:\")\n",
        "print('class_precision:', class_precision.round(4))\n",
        "print('class_recall：', class_recall.round(4))\n",
        "print('Matthews_corrcoef: %.4f' % MCC)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"sklearn results:\")\n",
        "rpt = metrics.classification_report(true_np, predict_np, digits=4)\n",
        "print(rpt)\n",
        "print()\n",
        "print(\"sklearn matthews_corrcoef: %.4f\" % metrics.matthews_corrcoef(true_np, predict_np))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My results:\n",
            "class_precision: [0.9392 0.1409]\n",
            "class_recall： [0.6082 0.6198]\n",
            "Matthews_corrcoef: 0.1351\n",
            "\n",
            "sklearn results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9392    0.6082    0.7383      9060\n",
            "           1     0.1409    0.6198    0.2295       939\n",
            "\n",
            "    accuracy                         0.6093      9999\n",
            "   macro avg     0.5400    0.6140    0.4839      9999\n",
            "weighted avg     0.8642    0.6093    0.6905      9999\n",
            "\n",
            "\n",
            "sklearn matthews_corrcoef: 0.1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRkS-ej04VAP"
      },
      "source": [
        "# DNN for thermal regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa0pMq25AV8"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfJreLSO5IIz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h12DftNw4cNQ"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2PU5z2iwGkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03aef3af-d705-4df7-f785-5f54f548b656"
      },
      "source": [
        "data_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/themal_dataset.csv'\n",
        "\n",
        "data_df = pd.read_csv(data_csv)\n",
        "data_df = data_df[data_df['y-exp'] < 500]   # remove two outliers\n",
        "features_df = data_df.iloc[:, 1:21]\n",
        "y_label = data_df.iloc[:, 21]\n",
        "y_theory = data_df.iloc[:, 22]\n",
        "y_label = np.array(y_label)\n",
        "print(\"features_df.shape: \", features_df.shape)\n",
        "print(\"y_label.shape: \", y_label.shape)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features_df.shape:  (368, 20)\n",
            "y_label.shape:  (368,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb4N5NY38_kM"
      },
      "source": [
        "## Standardize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RVhn-tp5ivh",
        "outputId": "bc5f28f9-f1be-43b2-9156-648d1d310864"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "input_features = preprocessing.StandardScaler().fit_transform(features_df)\n",
        "\n",
        "print(\"Feature shape:\", input_features.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (368, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18ZhhehdOiqk"
      },
      "source": [
        "## Customize a Pytorch dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYDwPgF9ikfY"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features_np, labels_np):\n",
        "        features_np = preprocessing.StandardScaler().fit_transform(features_np)\n",
        "        self.features = torch.from_numpy(features_np)\n",
        "        self.labels = torch.from_numpy(labels_np)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.features[index, :]        \n",
        "        label = self.labels[index]\n",
        "        \n",
        "        return features, label\n",
        "\n",
        "# list(train_dataloader)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA4bsEz9RTq_"
      },
      "source": [
        "## Define a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00274HwaRS0i",
        "outputId": "e3172c21-5394-46ad-98e1-cd46bf7cee92"
      },
      "source": [
        "\n",
        "INPUT_SIZE = input_features.shape[1] # 20\n",
        "OUTPUT_SIZE = 1\n",
        "HIDDEN_SIZE = 256\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE)\n",
        "        self.fc2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc3 = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "\n",
        "    def forward(self, x):     \n",
        "        x = self.fc1(x)        \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = Net().to('cuda')\n",
        "print(net)\n",
        " \n",
        "\n",
        "my_nn = torch.nn.Sequential(    \n",
        "    torch.nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),    \n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        ").to('cuda')  #  better, do not understand\n",
        "\n",
        "print(my_nn)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ZnKVuotcDs",
        "outputId": "5596b772-5665-4fdc-efd6-466000d8d7ff"
      },
      "source": [
        "input_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MrSjzCVoCaLv"
      },
      "source": [
        "## Train the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHasAnOpQdMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 892
        },
        "outputId": "d4c4ae11-7c7b-4451-e49c-229ed078c694"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from IPython.display import clear_output\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "fold_k = 10\n",
        "BATCH_SIZE = 8\n",
        "epoch_cnt = 20000\n",
        "\n",
        "input_features = preprocessing.StandardScaler().fit_transform(features_df)\n",
        "\n",
        "\n",
        "feature_dataset = FeatureDataset(features_np=input_features, labels_np=y_label)\n",
        "train_dataloader = DataLoader(feature_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "k_fold_spliter = KFold(n_splits=fold_k, random_state=None, shuffle=True)\n",
        "\n",
        "\n",
        "cost = torch.nn.MSELoss(reduction='mean')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "def draw_loss(losses):\n",
        "    clear_output()\n",
        "    print(step, np.mean(batch_loss[-1]))\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def train_a_model(net, train_dataloader, epoch_cnt = 10, fold=0):\n",
        "    step = 0 \n",
        "    losses = []\n",
        "\n",
        "    \n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5000, 10000, 15000],gamma = 0.2)\n",
        "\n",
        "    # print(f\"Processing {fold} fold.\")\n",
        "    \n",
        "    for epoch in range(epoch_cnt):\n",
        "\n",
        "        batch_losses = []\n",
        "        for x, y in train_dataloader:  # each batch\n",
        "\n",
        "\n",
        "\n",
        "            x = torch.tensor(x, requires_grad = True).float().to('cuda')\n",
        "            y = torch.tensor(y, requires_grad = True).float().to('cuda')\n",
        "\n",
        "             \n",
        "            # print(y)\n",
        "            prediction = net(x)\n",
        "            # print(prediction)\n",
        "\n",
        "           \n",
        "            loss = cost(prediction, y)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss.backward(retain_graph=True)\n",
        "            # loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses.append(loss.cpu().data.numpy())\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        scheduler.step()\n",
        "        \n",
        "        if epoch % 50 == 0:\n",
        "            losses.append(np.mean(batch_losses))\n",
        "            \n",
        "            clear_output(wait=True)\n",
        "            fig = plt.figure(figsize=(20, 8))\n",
        "            plt.plot(losses)\n",
        "            plt.show()\n",
        "            loss_t = np.mean(batch_losses)\n",
        "            print(f'Fold: {fold}, epoch: {epoch}, current loss: {loss_t:.4f}'  )\n",
        "        \n",
        "\n",
        "    return net\n",
        "\n",
        "    \n",
        "\n",
        "def eval_model(trained_net, X_test, y_true):\n",
        "    trained_net.eval().to('cuda')\n",
        "    y_predict = trained_net(torch.tensor(X_test).float().to('cuda')).cpu().data.numpy()\n",
        "\n",
        "    mse = metrics.mean_squared_error(y_true, y_predict)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(y_true, y_predict))\n",
        "    mae = metrics.mean_absolute_error(y_true, y_predict)\n",
        "    r_squared = metrics.r2_score(y_true, y_predict)\n",
        "\n",
        "    return y_predict, mse, rmse, mae, r_squared      \n",
        "\n",
        "# Cross validation\n",
        "results_df = pd.DataFrame(columns=['fold', 'mse', 'rmse', 'mae', 'r_squared'])\n",
        "for  idx, (train_index, test_index) in enumerate(k_fold_spliter.split(input_features)):\n",
        "\n",
        "    my_nn = torch.nn.Sequential(    \n",
        "    torch.nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),    \n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        "    ).to('cuda') \n",
        "     \n",
        "\n",
        "    df_row_cnt = len(results_df)\n",
        "    print(f\"Processing {idx} fold.\")\n",
        "    X_train, X_test = input_features[train_index], input_features[test_index]\n",
        "    y_train, y_test = y_label[train_index], y_label[test_index]\n",
        "\n",
        "    print(len(X_train))\n",
        "    feature_dataset = FeatureDataset(features_np=X_train, labels_np=y_train)\n",
        "\n",
        "    train_dataloader = DataLoader(feature_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    trained_net = train_a_model(my_nn, train_dataloader, epoch_cnt = epoch_cnt, fold=idx)\n",
        "\n",
        "    torch.save(trained_net, f'trained_model_{idx}.pth')\n",
        "\n",
        "    y_predict, mse, rmse, mae, r_squared = eval_model(trained_net, X_test, y_test)\n",
        "    # results_df.iloc[df_row_cnt, '']\n",
        "    results_df.loc[df_row_cnt] = [idx, mse, rmse, mae, r_squared]\n",
        "    \n",
        "\n",
        "    print(f\"Fold # {idx} Evaluation results:\")\n",
        "    print(f'mse: {mse:.4f}, rmse: {rmse:.4f}, mae: {mae:.4f}, r_squared: {r_squared:.4f}.' )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results_df['fold'] = results_df['fold'].astype(int)\n",
        "results_df.to_csv('10_fold_results.csv')\n",
        "print(\"10 fold results:\")\n",
        "\n",
        "results_df\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 9, epoch: 19950, current loss: 880.6274\n",
            "Fold # 9 Evaluation results:\n",
            "mse: 3611.2044, rmse: 60.0933, mae: 60.0933, r_squared: 60.0933.\n",
            "10 fold results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r_squared</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4059.507176</td>\n",
              "      <td>63.714262</td>\n",
              "      <td>34.300744</td>\n",
              "      <td>0.432008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>110103.658444</td>\n",
              "      <td>331.818713</td>\n",
              "      <td>80.515705</td>\n",
              "      <td>-221.910233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4987.252919</td>\n",
              "      <td>70.620485</td>\n",
              "      <td>36.818258</td>\n",
              "      <td>0.178448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1390.586853</td>\n",
              "      <td>37.290573</td>\n",
              "      <td>27.538641</td>\n",
              "      <td>-0.815726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24114.859463</td>\n",
              "      <td>155.289599</td>\n",
              "      <td>49.977647</td>\n",
              "      <td>-21.217698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>6835.217328</td>\n",
              "      <td>82.675373</td>\n",
              "      <td>44.959411</td>\n",
              "      <td>-4.455545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2484.824721</td>\n",
              "      <td>49.848016</td>\n",
              "      <td>35.672845</td>\n",
              "      <td>0.177432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>5013.012964</td>\n",
              "      <td>70.802634</td>\n",
              "      <td>39.123425</td>\n",
              "      <td>0.087296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17115.607578</td>\n",
              "      <td>130.826632</td>\n",
              "      <td>53.416233</td>\n",
              "      <td>-1.658382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3611.204368</td>\n",
              "      <td>60.093297</td>\n",
              "      <td>32.242146</td>\n",
              "      <td>-9.240084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fold            mse        rmse        mae   r_squared\n",
              "0     0    4059.507176   63.714262  34.300744    0.432008\n",
              "1     1  110103.658444  331.818713  80.515705 -221.910233\n",
              "2     2    4987.252919   70.620485  36.818258    0.178448\n",
              "3     3    1390.586853   37.290573  27.538641   -0.815726\n",
              "4     4   24114.859463  155.289599  49.977647  -21.217698\n",
              "5     5    6835.217328   82.675373  44.959411   -4.455545\n",
              "6     6    2484.824721   49.848016  35.672845    0.177432\n",
              "7     7    5013.012964   70.802634  39.123425    0.087296\n",
              "8     8   17115.607578  130.826632  53.416233   -1.658382\n",
              "9     9    3611.204368   60.093297  32.242146   -9.240084"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT3CqVd5CQfY",
        "outputId": "494c5738-3a53-4844-ec20-82b0495d91f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cn_CM8DpCeun"
      },
      "source": [
        "## Evaluate the best model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 784
        },
        "id": "3kQSa6kR8yQq",
        "outputId": "6fb5023c-5ecd-4d3e-c897-63d8179bea4a"
      },
      "source": [
        "best_model_fold_id = np.argmin(results_df['mae'])\n",
        "\n",
        "best_model = torch.load(f'trained_model_{best_model_fold_id}.pth')\n",
        "\n",
        "y_predict, mse, rmse, mae, r_squared = eval_model(best_model, input_features, y_label)\n",
        "\n",
        "print()\n",
        "print(f'The best model comes from fold # {best_model_fold_id}. The errors between its prediction and the y-exp are:')\n",
        "print(f'mse: {mse:.4f}, rmse: {rmse:.4f}, mae: {mae:.4f}, r_squared: {r_squared:.4f}.' )\n",
        "\n",
        "# evaluate the theoretical prediction and experimental observation\n",
        "mse = metrics.mean_squared_error(y_label, y_theory)\n",
        "rmse = np.sqrt(metrics.mean_squared_error(y_label, y_theory))\n",
        "mae = metrics.mean_absolute_error(y_label, y_theory)\n",
        "r_squared = metrics.r2_score(y_label, y_theory)\n",
        "\n",
        "print()\n",
        "print(f'The errors between theoretical prediction and the y-exp are:')\n",
        "print(f'mse: {mse:.4f}, rmse: {rmse:.4f}, mae: {mae:.4f}, r_squared: {r_squared:.4f}.' )\n",
        "print()\n",
        "\n",
        "\n",
        "def draw_r2_squared(ax2, x_true, y_observed):\n",
        "    x_true = np.array(x_true).reshape((-1, 1))\n",
        "    y_observed = np.array(y_observed).reshape((-1, 1))\n",
        "    reg = LR().fit(x_true, y_observed)\n",
        "    z = np.polyfit(x_true.ravel(), y_observed.ravel(), 1)\n",
        "    p = np.poly1d(z)\n",
        "    y_pred = p(x_true)\n",
        "    R_squared = r2_score(y_observed, y_pred)\n",
        "    # print()\n",
        "    print(\"R squared:\", R_squared)\n",
        "    print(\"reg.coef_:\", reg.coef_)\n",
        "    text = f\"$y={z[0]:0.3f}\\:x{z[1]:+0.3f}$\\n$R^2 = {R_squared:0.3f}$\"\n",
        "    ax2.scatter(x=x_true, y=y_observed, s=2)\n",
        "    ax2.text(0.05, 0.95, text, \n",
        "               transform=plt.gca().transAxes,\n",
        "               fontsize=20,\n",
        "               verticalalignment='top')\n",
        "    \n",
        "    # draw trend line\n",
        "    line_ends = [min(x_true), max(x_true)]\n",
        "    end_preds = p(line_ends)\n",
        "    ax2.plot(line_ends, end_preds, 'r--')\n",
        "\n",
        "\n",
        "# plt.scatter(y_theory, y_predict)\n",
        "fig = plt.subplots(figsize=(10, 10))\n",
        "plt.axis('equal')\n",
        "plt.ylim([0, 300])\n",
        "plt.xlim([0, 350])\n",
        "plt.xlabel(\"y_exp\")\n",
        "plt.ylabel(\"y_predict\")\n",
        "font = {'size': 20}\n",
        "plt.rc('font', **font)\n",
        "draw_r2_squared(plt.gca(), y_label, y_predict)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "The best model comes from fold # 3. The errors between its prediction and the y-exp are:\n",
            "mse: 937.4873, rmse: 30.6184, mae: 9.7966, r_squared: 0.7166.\n",
            "\n",
            "The errors between theorematical prediction and the y-exp are:\n",
            "mse: 2213.2770, rmse: 47.0455, mae: 17.9104, r_squared: 0.3310.\n",
            "\n",
            "R squared: 0.7195021580801667\n",
            "reg.coef_: [[0.76329031]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAApUAAAJfCAYAAAAuIi11AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd3RUZf7H8fdD6KD0KiXsCqir1LhIVQRRsCAKrmuhiKIoUpQVdFVcXbtUUfeHoBRFXNBFLEgJIE3QBBBZEBAhWEApAQVBCfn+/rgTNglpk3ZnJp/XOXPuzHOfe+93Mh7Pl6c6M0NEREREJC+K+R2AiIiIiIQ/JZUiIiIikmdKKkVEREQkz5RUioiIiEieKakUERERkTxTUikiIiIieVbc7wDCUdWqVS06OtrvMERERESyFR8fv9/MqhX0c5RU5kJ0dDRxcXF+hyEiIiKSLedcQmE8R93fIiIiIpJnSipFREREJM+UVIqIiIhInimpFBEREZE8U1IpIiIiInmmpFJERERE8kxJpYiIiIjkmZJKEREREckzJZUiIiIikmdKKkVEREQkz5RUioiIiEieKakUERERkTxTUikiIiIieaakUkRERETyTEmliIiIiOSZkkoRERERyTMllSIiIiKSZ0oqRURERCTPlFSKiIiISJ4pqRQRERGRPFNSKSIiIiJ5pqRSRERERPJMSaWIiIiI5JmSShERERHJs5BJKp1zzzrnYp1z3zrnjjnnDjrn1jvnRjnnqmRyTRvn3EeBuseccxudc0Odc1FZPOcq59wy59xh59wR59xa51yfgvtmIiIiIpEvZJJKYBhQDlgEjAfeBJKAx4CNzrm6qSs757oDy4EOwH+AiUBJYCwwK6MHOOcGAe8D5wNvAK8CtYGpzrkX8v0biYiIiBQRzsz8jgEA51xpMzueQfmTwEPAK2Z2d6DsTOBroALQ1sziUu4BLAFaA381s1mp7hMNfAUcBVqa2a5AeSXgc+CPQBsz+zS7WGNiYiwuLi7X31VERESksDjn4s0spqCfEzItlRkllAH/DhwbpirrCVQDZqUklKnu8XDg48B097kNKAVMTEkoA9ckAk8FPt6Vq+CLuO+++47bbruN2rVrU6pUKaKjoxk6dCiJiYk5un7q1Kk457J8RUVlOqKB2NhYevToQc2aNSlVqhS1a9fm8ssv56OPPkpTb8SIEXTq1Im6detSpkwZKleuTPPmzfnHP/7BgQMH8vQ38Ete/3bZeeONN07dZ/LkyVnWzcnvcODAASZPnkyPHj04++yzKVOmDBUqVKBdu3ZMmTKF5OTkXMcqIiL+Ku53ADlwdeC4MVXZpYHjxxnUXw78CrRxzpUys99ycM38dHUkh3bs2EGbNm346aef6N69O+eccw6fffYZ48eP5+OPP2bVqlVUqZLhkNhTmjVrxqhRozI8t2LFCpYsWULXrl0zPP/AAw/w/PPPU6dOHa655hqqVq3Kvn37iI+PZ9myZXTr1u1U3bFjx9KiRQsuu+wyqlevztGjR1mzZg2PPfYYkyZNYs2aNdStWzfD54SqvPztsvPtt98yaNAgypcvz5EjR7Ksm9PfYfbs2QwcOJBatWrRsWNH6tWrx48//si7777L7bffzvz585k9ezbOuVzFLCIiPjKzkHoBw/HGUY4FVgAGfAFUS1Xn80B5y0zusSlw/txUZfsCZVUyueZI4HzZ7GJs2bKliadLly4G2IQJE9KUDxs2zAC7884783T/iy66yAB77733Tjs3adIkA6xPnz7222+/nXb+999/T/P52LFjGT7joYceMsAGDhyYp1hz6/XXXzfAli5dmq/3zepvl53k5GTr1KmT/eEPf7Dhw4cbYK+++mqGdYP5HWJjY23evHl28uTJNHX27NljdevWNcDmzJkTdLwiIpI5IM4KI4crjIcEFRDsDSR3Ka/5QI10dbYFzp2dyT1WBc63TlX2e6CseCbXfB84Xyu7GP1KKkePHm2AvfDCCxme/+qrr6xkyZLWvn37Qonn66+/NsCio6NPSxJ+/vlnK1eunJUtW9aOHDmSq/tv3LjRADvrrLMsKSkpzbnjx49btWrVrF69ehkmMsHYsGGDAda5c+ds61522WUZJj7JycnWp08fA2zEiBFBPb8gksqs/nY5MW7cOHPO2SeffGKjRo3KNKnMz9/hySefNMAGDRqUp/uIiEhahZVUhsyYyhRmVtPMHFATuA74A7DeOdfCz7iccwOcc3HOubh9+/b5EkPbtm0BWLNmTYbn7733Xk6ePMnEiRMLJZ6lS5cC0KVLF4oVS/uf0hlnnEHbtm359ddfM403O5MmTQKgf//+p40LXLRoEfv27eO6666jWLFifPjhhzz77LOMHz+eTz/Ndq5VGu+//z4ATZo0ybbu888/T7FixXjkkUc4efLkqfLhw4czbdo0BgwYwDPPPBPU8wtCVn+77GzZsoWRI0cyZMgQOnTokGXd/PwdSpQoAUDx4uEwKkdERNIL2f97m9mPwH+cc+vwWian4y0FBHA4cKyQyeUp5YdSlR0GqgbOZTQro0KqehnFMwmYBN7s7xx8hXzXokULypQpw9q1a087N3v2bBYtWsTgwYOzTI7GjRvHoUOHMj2fXrNmzbj22mszPLd161YAGjVqlOH5hg0bsnDhQrZt20anTp1y/EyAY8eO8cYbbxAVFcXtt99+2vnPP/8cgNKlS9O8eXM2bdqU5nyHDh2YM2cO1apVO+3aF154gSNHjnD48GHi4uJYuXIlTZo0YeTIkdnG1bRpU2699VamTZvGjBkz6Nu3L0899RRjxozhhhtu4JVXXgnqexaE7P52WUlKSuLWW2+lXr16PPXUU9nWz8vvkP6506dPB+CKK64IKmYREQkRhdEcmtcXsB6va7pq4PMbgc9/zaBucbxlg04ApVKVryRdl3iqc7UC577NSTx+jqns0KGDAfbDDz+cKjty5IjVqVPHqlevbocOHcry+vr166ceWpDtq0+fPpne64477shyrF3KWMWnnnoq6O85depUA+zKK6/M8Pxdd91lgEVFRdkFF1xgK1assF9++cU2btx4apznxRdfnOG1NWrUSPMdr7jiCtu7d2+OY9u9e7eVLl3aoqOj7cUXXzTALr/88lx3/+Z393d2f7usPPLII1asWDFbvXr1qbKsur/z8jukdv/99xtg3bp1CzpmERHJGkW1+zsTtQPHlP7GJYFjRk0aHYCywGr738zv7K7pmq5OyErpAk/dtfj444/z3Xff8eyzz1KhQmaNt55du3YF9R/I1KlTC/LrZCql+/bOO+/M8HzK0jPFixdn3rx5tGvXjvLly3PBBRfwn//8hzp16vDJJ59k2AW7d+9ezIy9e/fy7rvv8s0339C8eXPWrVuXo9jq1q3L0KFD2bVrF/feey9t2rTh3XffpWTJktleGx0dfdqSP/369QOgY8eOp53r27dvjmJKLbu/XWbWrl3LU089xf3330/r1q1zdE1efocUEyZMYPTo0ZxzzjnMmDEjqJhFRCR0hET3t3OuEfCjmR1OV14MeAKojpckpix8OAd4FrjROfeipV38/J+BOun7IV8HHgAGOedet7SLnz8UqPOvfP1iBSAlqVy7di3XXXcdX331FWPHjqV169b06VO4u02mJLCHD2c4YuBUecWKFYO673//+19Wr15NnTp10iwJlFrKPZs3b050dHSac2XLluXyyy9nypQpfPbZZ5kmSDVq1KBHjx60aNGCRo0a0bt379O6bzOTujt3ypQplC1bNkfXDR069LThBxs2bOC9996jT58+p32XZs2a5ei+KXLyt8tIUlISvXv3plGjRjzxxBM5vi6vv8PEiRMZMmQI5513HrGxsVSuXDnHzxYRkdASEkkl0A142jm3EtiJN+axBnAx3kSdvcAdKZXN7Gfn3B14yeUy59ws4CBwDdA4UP526geY2U7n3N+ACUCcc+5tvBnhPYE6wGjLwW46fmvTpg3OuVOTXwYNGsTJkyd56aWXcrS2X36OqWzcuDEA27Zty/D89u3bgczHXGYmJ5NMUp6dWcJaqVIlwBtfmJ369etz3nnnsWHDBvbv30/VqlWzrD9z5kyGDx9OzZo12bt3L+PHj8/xWMqhQ4eeVjZ16lTee+89+vbtyyWXXJKj+2QmtxN0jhw5cup3LF26dIZ17rjjDu644w6GDBnCuHHjgLz9DuPGjWPYsGGcf/75xMbGUr169RzHKyIioSdUksrFwNlAO6A5UBFvXOQ2YAYwwcwOpr7AzOY65y4G/g5cD5TG27rxvkD90ybTmNmLzrldeGth9sbbUWgz8LCZTSuYr5a/KlWqxLnnnkt8fDwzZ84kNjaWgQMH0rx58xxdP27cOBISEnL8vD59+mSaVHbs2BGAhQsXkpycnGYG+C+//MKqVasoW7YsF110UY6fd/z4cWbMmEFUVBT9+/fPtF6nTp1wzrF58+bTng2canFs0KBBjp77ww8/AGSbiH300Uf07dv3VCLUvn17Jk+ezNChQ08lWH7J6d8uI6VKlcr0mnXr1rF+/XratWtH48aN07Q45vZ3ePbZZxk5ciTNmjVj0aJF2SbyIiISBgpj4Gakvfxe/HzAgAEGWPny5a1q1ap28OBB32LJzeLnX3/9tW3ZsuW0xcnNzKZPn26AXXXVVdk++5prrjHAxowZk6Z8wYIF5pyzihUrnpq4tHXr1gwnMZ08efLUhKI2bdpk+bwVK1ZYmTJlrEGDBqcmSs2ePdsA6969e7bxZia/JuoE87fL6jdIL6uJOmbB/Q5mZo8//rgB1rJlSztw4EC2zxcRkbyhkCbqhEpLpQShbdu2TJo0iSNHjjB27NhTXYx+ePnll2nTpg2DBw8mNjaWc889l7Vr17J06VIaNWrEk08+edo1nTp1IiEhgZ07d542Di+l+3bAgAHZPvull15i/fr13HfffXz44Yc0b96cnTt3MnfuXKKiopg8efKpcZ8fffQRDz74IO3ataNBgwZUqVKFH3/8kU8++YRvvvmGmjVr8uqrr2b6rA0bNnDVVVdRoUIFFi1aRK1atQDo2bMnMTExvPfee6xYsYL27dvn9E+X74L522X1GwQrmN9h2rRpPProo0RFRdG+fXsmTJhw2v2io6NzNUFJRER8VhiZa6S9/G6pXL58uQF24YUXWnJysq+xmHlL7PTt29dq1qxpJUqUsHr16tmQIUMybUFNWdZo586daco3b95sgNWpUyfHu8D89NNPNmjQIKtXr56VKFHCqlSpYtdee62tXbs2Tb0vv/zS7rnnHmvatKlVqVLFoqKi7Mwzz7SYmBgbNWpUli1m27dvtxo1aljFihXtiy++OO38okWLDLBWrVrlKOb08qOlMti/XWa/QUaya6k0y/nvkHKvrF45WYJIRERyjkJqqXTesyQYMTExFhcX59vzr7nmGj788EPWrFnDhRde6FscIiIiEvqcc/FmFlPQzwmXdSolYObMmbz//vsMHDhQCaWIiIiEDI2pDAO7d+9m5syZ7Nixg+nTp/OnP/2J5557zu+wRERERE5RUhkGPv74Yx588EEqVqxI9+7dGTduXI4X2xYREREpDBpTmQt+j6kUERERySmNqRQRERGRsKGkUkRERETyTEmliIiIiOSZkkoRERERyTMllSIiIiKSZ0oqi4inn36aCy+8kDPPPJNq1apx9dVXs2nTJr/DEhERkQihpLKIWLZsGXfffTerV69myZIlFC9enM6dO3Pw4EG/QxMREZEIoMXPi4gFCxak+TxjxgwqVKjAqlWruPrqq32KSkRERCKFWirDUJcuXXDOpXlVr16ddu3aMXv27Bzd45dffiE5OZlKlSoVcLQZ++6777jtttuoXbs2pUqVIjo6mqFDh5KYmJjttVOnTj3t+6d/RUVFpbnmwIEDTJ48mR49enD22WdTpkwZKlSoQLt27ZgyZQrJyckFEquIiEhRoR11csHvHXWqVKlCYmIijzzyCM45kpKS+Oqrr5g7dy4nT55kzJgxDBs2LMt73HDDDWzfvp24uLjTErCCtmPHDtq0acNPP/1E9+7dOeecc/jss89YunQpjRs3ZtWqVVSpUiXT6zds2MDcuXMzPLdixQqWLFnClVdeyQcffHCq/F//+hcDBw6kVq1adOzYkXr16vHjjz/y7rvvcvjwYa6//npmz56Ncy5fYxUREfFbYe2og5npFeSrZcuW5pcdO3YYYI0bNz7t3CuvvGKA1a9fP8t7DBs2zGrVqmU7duwooCiz1qVLFwNswoQJp8UF2J133pnre1900UUG2HvvvZemPDY21ubNm2cnT55MU75nzx6rW7euATZnzpxCjVVERKQwAHFWCPmR7wlaOL78TCrffvttA+ymm2467dzOnTsNsDJlymR6/dChQ61mzZq2ZcuWggwzU19//bUBFh0dfVqC9/PPP1u5cuWsbNmyduTIkaDvvXHjRgPsrLPOsqSkpBxf9+STTxpggwYNKrRYRURECkthJZUaUxlmUrrdW7Zsedq5r7/+GoBzzz03w2uHDBnCW2+9xZIlSzjnnHMKLsgsLF26FPDGhRYrlvY/vzPOOIO2bdvy66+/smbNmqDvPWnSJAD69+8fVJd+iRIlAChePO28tYKMVUREJNJo9neYSUkqY2LSDo3Yv38/w4cPB2DkyJGnXXfPPfcwY8YM5s6dS6VKldi7dy8A5cuXp3z58pk+b9y4cRw6dCjH8TVr1oxrr7020/Nbt24FoFGjRhmeb9iwIQsXLmTbtm106tQpx889duwYb7zxBlFRUdx+++05vi4pKYnp06cDcMUVVxRKrCIiIpFISWUYMTPWrVsHwLx581iyZAknT54kISGBefPmkZyczMsvv0yvXr1Ou/bll18GOC35GTVqFI899limzxw3bhwJCQk5jrFPnz5ZJpWHDx8GoEKFChmeTykPJpEF+Pe//82hQ4e48sorqVu3bo6vGzlyJJs2baJbt25cfvnlhRKriIhIJFJSGUa2b99+KtEZPXp0mnPlypVjzpw5p7W2pfCGVARv165dubqusKV0fd955505vmbChAmMHj2ac845hxkzZhRUaCIiIkWCxlSGkZSu7379+p0aFHvgwAHGjBnD0aNH+etf/xryrWYprXspyXF6KeUVK1bM8T3/+9//snr1aurUqUO3bt1ydM3EiRMZMmQI5513HkuXLqVy5cqFEquIiEikUktlGMloPGXlypUZNmwYn376KbNnz2bGjBnce++9+fbM/B5T2bhxYwC2bduW4fnt27cDmY9jzEiwE3TGjRvHsGHDOP/884mNjaV69eqFFquIiEjEKowp5pH28mtJofbt2xtga9asOe3cggULDLDWrVvn6zPr169vQI5fffr0yfJ++b1Mz7Fjx6xSpUoWFRVlu3fvzrb+M888Y4A1a9bM9u3bV6ixioiI+AEtKSSpJScns379eooXL07Tpk1PO9+xY0cqVqzImjVr+OGHH/Ltubt27QrqP6ipU6dmeb8//vGPdOnShV27dvHSSy+lOTdq1CiOHj3KrbfeSrly5U6V79ixg6+++ooTJ06cdr/Zs2eTmJhI165ds52g88QTTzBy5EhatmxJbGwsVatWzfdYRUREiipt05gLfmzTuHnzZv70pz/RtGlTNmzYkGGdm2++mZkzZzJx4kTuueeeQo0vGOm3Pjz33HNZu3YtS5cupVGjRqxevTrN1ofR0dEkJCSwc+dOoqOj09yrffv2rFy5knnz5nH11Vdn+sxp06bRt29foqKiuPfeezOc0R0dHU3fvn3zFKuIiEio0TaNIfzyo/t72rRpBthtt92WaZ3Zs2cbYB07dizEyHJn9+7d1rdvX6tZs6aVKFHC6tWrZ0OGDLGDBw+eVjelC37nzp1pyjdv3myA1alTJ9sddEaNGpVt1/3FF1+c51hFRERCDYXU/a2Wylzwo6VSREREJDcKq6VSYypFREREJM+0pJCIiIhIJEpOhuefL7THKakUERERiTSJidC7N3zwQaE9Ut3fIiIiIpHmm29g2TKYMKHQHqmkUkRERCQSmMHKld77li1h1y7Ix132sqOkUkRERCTcHTkCN98M7dt7LZQAhbyOssZUioiIiISzzZuhZ0/YuhWefBI6dPAlDCWVIiIiIuFq1izo3x/Kl4fFi6FjR99CUfe3iIiISLg6cQJiYmD9el8TSlBSKSIiIhJeduyAuXO997feCkuXQu3a/saEkkoRERGR8DF3rjez+5574Ngxr6xYaKRzoRGFiIiIiGTuxAkYPhx69ICzz/aWDipTxu+o0tBEHREREZFQ9vvv0KmTl0jefTeMGQOlSvkd1WmUVIqIiIiEspIl4ZJLYOBAuOkmv6PJlJJKERERkVCTnAxPPeW1ULZuDU884XdE2VJSKSIiIhJK9u+HW26BBQvg8GEvqQwDSipFREREQsWnn8INN8BPP8H//R/ccYffEeWYkkoRERGRULBmjbfFYt26XnLZooXfEQVFSwqJiIiI+MnMO154ITz6KMTHh11CCUoqRURERPzzxRfQvj18/z1ERcEjj0ClSn5HlStKKkVERET88NprcNFFsHMn7N3rdzR5pqRSREREpDD9+iv06wf9+0PbtrB+vbf1YphTUikiIiJSmB59FKZN844LFkD16n5HlC80+1tERESkMBw75u3X/fDD0LWrt7B5BFFLpYiIiEhB+v13GDLEm5Bz/DhUrBhxCSUoqRQREREpOLt3e2tPTpjgJZXFIjf1Uve3iIiISEGYP9/bbvHECZgzB66/3u+ICpSSShEREZH8dvIkjBgBdep4CWXDhn5HVOCUVIqIiIjklx9/hHLloHx5+OADqFbNm5xTBERux76IiIhIYVq+HJo39yblANSrV2QSSlBSKSIiIpI3ZvDcc3DppV4L5dChfkfkC3V/i4iIiORWYiL07Qvz5kGvXjB5Mpx5pt9R+UItlSIiIiK59fPPsHYtjB8Pb79dZBNKUEuliIiISHDM4KOPoFs3qF8fduzwJucUcWqpFBEREcmpI0e8tSevugpmz/bKlFACIZJUOueqOOdud879xzn3tXPumHPusHNupXOuv3OuWLr60c45y+I1K4tn9XHOfeacOxJ4xjLn3FUF/y1FREQkrG3eDH/+M8yaBf/8J/Ts6XdEISVUur97Aa8Ae4ClwG6gBnAdMBno6pzrZWaW7rovgLkZ3G9TRg9xzr0A3A98B7wKlARuBN53zt1rZhPz4buIiIhIpHnnHejd25vdvWiRN9Nb0giVpHIbcA3woZklpxQ65x4CPgOux0sw30l33QYzeywnD3DOtcFLKHcAF5pZYqD8eSAeeME594GZ7crbVxEREZGIU6WK10r55ptQu7bf0YSkkOj+NrMlZvZ+6oQyUL4X+Ffg4yV5fMxdgeOTKQll4Bm7gJeAUkC/PD5DREREIsU338CkSd77Sy6BJUuUUGYhJJLKbJwIHJMyOFfbOXenc+6hwLFJFvdJaaf+OINz89PVERHJVHxCIr2nrCU+ITH7yiISnt57D1q0gAcfhAMHvDLn/I0pxIVK93eGnHPFgd6Bjxklg5cFXqmvWQb0MbPdqcrKAWcBR8xsTwb32R44NsprzCIS+cYv3sby7fsBmN6/lc/RiEi+OnEC/v53eP55L6mcM8fr+pZshXRSCTwDnA98ZGYLUpX/CjyBN0nnm0BZE+AxoCMQ65xrZmZHA+cqBI6HM3lOSnnFfIpbRCLYkM6N0hxFJEIkJ0PXrhAbC3fdBWPHQunSfkcVNtzpE6pDg3NuMDAe+Apoa2YHc3BNcWAl0AoYambjA+W1ge+B782sTgbXlQB+B343s1KZ3HsAMACgXr16LRMSEnL1vURERCSETZrkrTt5881+R5JvnHPxZhZT0M8JyTGVzrlBeAnlZqBjThJKADNLwluCCKBDqlMpLZEVyFhK+aEs7j3JzGLMLKZatWo5CUdERERCXXKyt+bknDne5wEDIiqhLEwhl1Q654YCL+KtNdkxMAM8GPsCx1PL2we6wb8HyjvnamVwTcPAcVuQzxIREZFwtX8/XHklPPIILF7sdzRhL6SSSufcCGAssAEvofwpF7e5KHD8Jl35ksDxigyu6ZqujoiIiESyNWu8iThLlsArr3gvyZOQSSqdc4/gTcyJBzqZ2f4s6rZIv3VjoLwTMCzw8Y10p1PWu/y7c65SqmuigXuA34DXcxu/iIiIhImtW6FDB4iKgtWrvUk5Wi4oz0Ji9rdzrg/wOHASWAEMdqf/uLvMbGrg/RigoXNuNd6Wi+DN/k5ZZ/IRM1ud+mIzW+2cGwPcB2x0zs3B26bxL0Bl4F7tpiMiIhLBkpOhWDFo3BjGj4cbb4RKlbK/TnIkJJJKoEHgGAUMzaTOJ8DUwPsZQA/gQryu6xLAj8C/gYlmtiKjG5jZ/c65L/FaJgcAycA64Hkz+yDvX0NERERC0saN3t7d06dDkyYwcKDfEUWckEgqA/t3PxZE/SnAlFw+ayr/S05FREQk0r3+Otx9t9cqefRo9vUlV0JmTKWIiIhIvjp2DPr3h9tugzZtYP16aN3a76gilpJKERERiUwTJ8Jrr3lLBi1cCDVq+B1RoYtPSKR45bMaZl8z75RUiohIgYtPSKT3lLXEJyT6HYoUBYcCe5kMHQrLl8Pjj3szvYug8Yu3UaxkmTML41lKKkVEpMCNX7yN5dv3M36x9pjwU8Qn97//7iWSTZvCgQNQogS0b+93VL664vxaWHJyUmE8KyQm6oiISGQb0rlRmqP4IyW5B5jev5XP0eSz3bvhL3/xFjUfMgTOOMPviELCx5v24IoVK5R8T0mliIgUuJb1K0VeEhOGIja5//hjuOUWr6Vy9mzo2dPviELGkM6NeOuBYz8XxrOcmRXGcyJKTEyMxcXF+R2GiEim4hMSGb94G0M6N6JlfS3uLBHMDLp2hT17vISyUYQlzPnAORdvZjEF/Ry1VIqIRKCI7uYUAfjpJ2+HnJo1YeZMKF0aypb1O6oiTUmliEgEithuThGAlSu98ZPnnw8LFkDlyn5HJGj2t4hISMrrLN2UMYyF2fUd8TOLxX9m8PzzcMklXqvkc8/5HZGkoqRSRFiJBh4AACAASURBVCQEheMSPOEYs4SRQ4egRw944AG49lqIi/OWDpKQoe5vEZEQFI7d1+EYs4SZrVth3DgYPBic8zsaSUezv3NBs79FREQKgZk3o/uaa7yJOL//DiVL+h1V2Cms2d/q/hYREZHQc/Qo9O7tTciZPNkrU0IZ0tT9LSIiIqFlyxZvAfMtW7x9u+++2++IJAeUVIqIiEjo+OADuPFGb3b3woXQubPfEUkOqftbREREQscf/wjt28P69Uoow4ySShEREfHXzp3wxBPexJxzz4X58+Gss/yOSoKkpFJERET88/770KIFjB4NCQl+RyN5oKRSRERECl9SEowc6S0X1KABrFsH0dF+RyV5oIk6IiIiUvh69YK5c+HOO70FzUuX9jsiySMllSIiIlL4br8drr8ebrnF70gknyipFBERkYKXnAxPPw1lysB998GVV/odkeQzjakUERGRgnXgAFx1FTz8MHzxhTfLWyKOkkoREREpOGvXQvPmEBsLL78MU6eCc35HJQVA3d8iIiJSMPbuhUsugZo1YdUqiInxOyIpQEoqRUREJH8lJUHx4l4yOWMGXHopVK7sd1RSwNT9LSIiIvnnyy/hggtgwQLvc8+eSiiLCCWVIiIikj+mToVWreDwYShb1u9opJApqRQREZG8OXYM+veHfv2gdWtYvx7at/c7KilkSipFREQkb+bMgdde85YMWrgQatTwOyLxgSbqiIiISO7s3etNxrnlFjjvPGjZ0u+IxEdqqRQREZHg/P47DBsGjRvDN994604qoSzy1FIpIiIiOfftt/CXv8Cnn8K990KdOn5HJCFCSaWIiIjkzIIFcPPN8Ntv8PbbcMMNfkckIURJpYiIiOTM7NlQu7Y3MadRI7+jkRCjpFJEREQy99NPkJjojZ988UUw0xqUkiFN1BEREZGMrVoFzZt7YyiTk6FMGSWUkikllSIiIpKWGYweDRdf7CWSU6dCMaUMkjV1f4uIiMj//PIL9O4Nc+fCddd5i5pXqOB3VBIG9M8OERER+Z9SpeDgQRg71puQo4RSckgtlSIiIkWdGcyYAVdeCVWqwNKl6u6WoOm/GBERkaLs6FHo08d7TZzolSmhlFxQS6WIiEhR9dVX0LMnbN4M//gH/P3vfkckYUxJpYiISFEUGwvdu3uzuxcsgMsu8zsiCXNq3xYRESmKLrgAunaF9euVUEq+UFIpIiJSVOzaBffeC0lJUL26t+1inTp+R1Vo4hMS6T1lLfEJiX6HEpGUVIqIiBQFH3wALVp4s7y3bPE7Gl+MX7yN5dv3M37xNr9DiUhKKkVERCJZUhI8+CBcfTVER0N8vNf1XQQN6dyIDg2rMqRzI79DiUhKKuWU1N0C6iIQEYkQt98OzzwDAwbA6tXwxz/6HZFvWtavxPT+rWhZv5LfoUQkzf6WU1K6BVKkvJ/ev5VfIYmISG6ZgXMweDBceqm39aJIAVJSKaekdAekHH8+doKfjycRn5Cof9WJiISL5GR49lnYuxfGj/fGUbZo4XdUUgSo+1tOSd0t0LJ+Jc4sU4IN3x7SgGYRkXBx4IA3dvKhh+DHH73xlCKFRC2Vkqn0LZciIhLCPvsMevWCPXu87Rbvvtvr/hYpJEoqJVMpLZciIhLifvkFrrgCzjwTVq6EP//Z74ikCFJSKSIiEq6OHYPSpeGMM+Cdd6BpU6hc2e+opIjSmEoREZFwtGkTNG8Or77qfe7YUQml+EpJpYiISLiZNs3r4j58GBo39jsaEUBJpYiISPg4dsxbzLxvX2jVCtavh4sv9jsqEUBJpYiISPhYuRJee81bMmjRIqhZ0++IRE7RRB0REZFQ98038Ic/wGWXwZYt6vKWkKSWShERkVB14gTcf7+XRMbFeWVKKCVEKakU38QnJNJ7ylriExL9DkVEJPR89x1ccgmMGQMDB0KTJn5HJJIldX+Lb8Yv3sby7fsBtMi6iEhqixbBTTfB8eMwaxb85S9+RySSLSWV4httAykikonPPoMaNbwFzdXdLWEiJLq/nXNVnHO3O+f+45z72jl3zDl32Dm30jnX3zmXYZzOuTbOuY+ccwcD12x0zg11zkVl8ayrnHPLAvc/4pxb65zrU3DfTjKTsg1ky/qV/A5FRMR/+/bB2rXe+wcf9BJLJZQSRkKlpbIX8AqwB1gK7AZqANcBk4GuzrleZmYpFzjnugPvAMeBt4GDwNXAWKBt4J5pOOcGAS8CB4A3gN+BnsBU59wFZja8oL6giIhIplat8rq4nYMdO6BkSShb1u+oRILiUuVp/gXh3KVAOeBDM0tOVV4T+AyoC/Q0s3cC5WcCXwMVgLZmFhcoLw0sAVoDfzWzWanuFQ18BRwFWprZrkB5JeBz4I9AGzP7NLt4Y2JiLC5lFp6IiEhumcHYsTBiBNSvD7Nne1sviuQj51y8mcUU9HNCovvbzJaY2fupE8pA+V7gX4GPl6Q61ROoBsxKSSgD9Y8DDwc+Dkz3mNuAUsDElIQycE0i8FTg4115+yYiIiI5dPw4XH+9t2TQ1VdDfLwSSglrIZFUZuNE4JiUquzSwPHjDOovB34F2jjnSuXwmvnp6oiIiBSsUqWgTBkYPdqbkFOhgt8RieRJqIypzJBzrjjQO/AxdTKYMnJ5W/przCzJObcT+BPwB2BLDq7Z45w7CtRxzpU1s1/zI34REZE0zLxtFi++GM4+G954wxtHKRIBQr2l8hngfOAjM1uQqjzln3OHM7kupbxiLq7J8J+KzrkBzrk451zcvn37so5aREQkvaNHoW9fuP12ePFFr0wJpUSQkE0qnXODgfvxJtfc6nM4mNkkM4sxs5hq1ar5HY6IiISTrVuhVSuYMQMee8zbJUckwoRk93dg6Z/xwGagk5kdTFcly1bFVOWH0l1TNXDuQBbXZNaSKSIiErw1a+Cyy6B0aViwwHsvEoFCrqXSOTcUby3JTUDHwAzw9LYGjqdtxRIYh9kAb2LPNzm8phbekkbfaTyliIjkqyZNvDUo169XQikRLaSSSufcCLzFyzfgJZQ/ZVJ1SeB4RQbnOgBlgdVm9lsOr+maro6IiEjuJSR4e3f/8ou3iPnkyVCnjt9RiRSokEkqnXOP4E3Micfr8t6fRfU5wH7gRufcqcU8A4uf/zPw8ZV017wO/AYMCiyEnnJNJeChwMd/ISIikhcffuitN/nhh7Bpk9/RiBSakBhTGdh7+3HgJLACGOxOnxG3y8ymApjZz865O/CSy2XOuVl42zReg7d00By8rRtPMbOdzrm/AROAOOfc2/xvm8Y6wOic7KYjIiKSoaQkePRRePppaNbM2x3n7LP9jkqk0IREUok3BhIgChiaSZ1PgKkpH8xsrnPuYuDvwPVAabytG+8DJqTeJzzVNS8653YBw/HWvyyGNxnoYTObli/fREREiqa//Q3GjfOWDJowwVvYXKQICYm9v8ON9v4WEZFTkpOhWDHYvRuWL4dbbvE7IpE0itTe3yIiImEnOdnr6u7Rw3tfr54SSinSlFSKiIgE6+BBuOYaeOghb/3J337L/hqRCKekUkREJBiffw4tWsDChTBxIsyapfGTIoTORB0REZHQd+IE3HADmMHKlfDnP/sdkUjIUFIpIiKSnSNHvG7uEiXg3Xe98ZNVqvgdlUhIUfe3iIhIVjZtgpgYbw1K8BY2V0IpchollSIiIpmZMcPr4j50CLp08TsakZCmpFJERCS948dhwADo3dtLKtevh0su8TsqkZCmpFJERCS9bdu8VsoHH4TFi6FWLb8jEgl5SipFIlB8QiK9p6wlPiHR71BEwsvGjd6xSRPYvh2eegqKa06rSE4oqRSJQOMXb2P59v2MX7zN71BEwsOJEzB8ODRtCh995JXVqeNvTCJhRv/8EolAQzo3SnMUkSx8/z385S+wahXccw906uR3RCJhSUmlSARqWb8S0/u38jsMkdC3eDHcdBP8+iu89RbceKPfEYmELSWVIiJSdP34I1SvDnPmwDnn+B2NSFjTmEoRESla9u+H+fO99zffDOvWKaEUyQdqqRQRkaLj00+9vbt/+QUSEqBCBShZ0u+oRCKCWipFRCTymcHYsdChg5dELlniJZQikm/UUikiIpHt5Elvdvc778C118Lrr0PFin5HJRJx1FIpIiKRLSoKGjWCF16Ad99VQilSQNRSKSIikem117wJOG3aeDvjiEiBUkuliIhEll9/hX79oH9/+L//8zsakSJDSaWIiESOrVvhootg2jR49FGvtVJECoW6v0VEJDJs2gStW0OpUvDxx9Cli98RiRQpaqkUEZHIcN55cPfdsH69EkoRHyipFBGR8LV7N1x9NXz3HRQrBs8+C3Xr+h2VSJGkpFJERMLT/PnQvDksX+6NpRQRXympFBGR8HLyJDz8MHTrBnXqQFwcdOrkd1QiRV5QSaVz7jXn3DXZ1LnKOafpdiIiUjCefhqefNJbMmjNGmjY0O+IRITgWyr7As2yqdMU6JOraERERDKTlOQdBw+GWbNg8mQoU8bfmETklILo/i4FnCyA+4qISFGUnOxNwGnTBo4fhzPP9PbyFpGQkpuk0jI74ZwrBXQA9uY6IhERkRQHD0L37jByJERH/6+1UkRCTraLnzvnvklXNMw51y+DqlFANbyWyn/lQ2wiIlKUxcVBz57www8wYQIMGgTO+R2ViGQiJzvqFON/rZMGuMArvRPAl0As8M98iU5ERIomMxg40Ov6XrECWrXyOyIRyUa2SaWZRae8d84lA2PN7PGCDEpERIqoI0e8Y/ny8O9/e+Mnq1TxNyYRyZFgx1R2BKYVRCAiIlLE/fe/cOGFcNdd3ucGDZRQioSRoJJKM/vEzBIKKhgRESmi3ngD/vxnSEz01p8UkbAT7OLnDzvnTjjnamdy/izn3O/OuRH5E56IiES048fhzjvh1lshJgbWr4eOHf2OSkRyIdju76uBZWb2Q0Ynzex7YClwbV4DExGRImDfPnjnHRgxAmJjoVYtvyMSkVwKNqk8G9icTZ3NgXoiIiIZW7XKm9ldty5s3QrPPAPFc7IgiYiEqmCTyjLAr9nUOQ6ckbtwREQkop04AX/7G7RrB6+/7pVpMo5IRAj2n4XfARdlU+ci4PvchSMiIhHr++/hxhth5Uq4+2645Ra/IxKRfBRsS+XHQAfnXIabrjrnbgQuBubnNTAREYkgy5ZB8+beRJw334SXXoJSpfyOSkTyUbAtlc8CNwMzA4nlx3itkmcBXYFrgIPAM/kZpIiIhLlixbxJOLNmwbnn+h2NiBSAoJJKM/veOXc5MBtvhnf3VKcdsAvoZWbf5VuEIiISnvbvh/nzveWCOnTwWimLBdtBJiLhIuipdmYW55xrhLe80EVAReAQsAZ438xO5G+IIiISdj79FG64wUssL70UzjpLCaVIhMvV+g2BxPHdwEtERMRjBhMmwPDh3nJBq1Z5CaWIRDwtCiYiIvnDzOvqfvNN6N7dWzKoUiW/oxKRQpJlUumc6x14+x8z+yXV52yZ2fQ8RSYiIuHFOWjfHpo1g/vv9z6LSJHhzCzzk84lAwaca2bbUn3O8p6AmVlU/oUZWmJiYiwuLs7vMEREQsNrr8GZZ0LPnn5HIiIZcM7Fm1lMQT8nu+7v2/CSyD2Bz/0KNhwREQkbv/4KgwZ53dzXXqukUqSIyzKpNLOp6T5PK9BoREQkPGzf7iWRX34JjzwCo0b5HZGI+EwTdUREJDjffgstW0LJkvDRR3DFFX5HJCIhQEmliIgEp25deOwx6NXLey8iQvazv7/J5X3NzP6Yy2tFRCTU7N4NffvC2LHQtCncd5/fEYlIiMmupbIYp8/2LgnUCrw/CewHqgIps733AL/nV4AiIuKzjz+Gm2+GEyfg+++9pFJEJJ0s98wys2gza5DyApoC3+NtydgRKG1mtYDSwKXAWuA7oEnBhi0iIgXu5ElvEk63blCnDsTHe+9FRDIQ7EasT+Lt9X2JmX1iZicBzOykmS3DSzQrB+qJiEg4e/VV+Oc/oV8/WLMGGjb0OyIRCWHBTtTpAbxlZhl2b5vZcefce8CNwOC8BiciIj44dgzKlIH+/aFWLW/LRRGRbATbUlkFKJFNnRKBeiIiEk6Sk+G55+C882D/fihRQgmliORYsEnlDqCnc65CRiedc5WAnkBuZ42LiIgfEhO9XXFGjICYGG8NShGRIASbVP4LqA185pzr7ZyLds6VCRz74E3UqQm8lN+BiohIAYmPhxYtvFne48fDv//t7eUtIhKEoMZUmtlE51xD4F7g9QyqOOBFM3s5P4ITEZFC8Pjj3kzv5cvhoov8jkZEwlTQO+qY2RDn3CzgNqA5UAE4DKwDpprZ6vwNUURE8t2RI3D0KNSoAVOmeGVVq/obk4iEtVxt02hmnwKf5nMsIiJSGDZvhp49oVo1WLZMyaSI5Itgx1SKiEg4e/NNuPBCOHAARo0C5/yOSEQiRK6SSufc1c65Wc65L5xzX6cqP9c594Bz7qxc3LOnc+5F59wK59zPzjlzzr2RSd3owPnMXrOyeE4f59xnzrkjzrnDzrllzrmrgo1XRCSsHD8Od90Ft9wCLVvC+vVw6aV+RyUiESSo7m/nnAOmArcEio4BZVJVSQSewpuw82yQsTyMtw3kEbytHs/JwTVfAHMzKN+UUWXn3AvA/YH7v4q3j/mNwPvOuXvNbGKQMYuIhIfffoPYWHjgAXjySSieq9FPIiKZCvb/KncDtwKv4SVnw4BHUk6a2V7n3CrgSoJPKofhJXtfAxcDS3NwzQYzeywnN3fOtQnEvAO40MwSA+XPA/HAC865D8xsV5Bxi4iErsWLoV07qFDBa50sX97viEQkQgXb/d0fr3XwDjM7DFgGdbYDDYINxMyWmtl2M8vonvnhrsDxyZSEMvDcXXjrapYC+hXQs0VECldSkreQ+WWXwZgxXpkSShEpQMEmlY2Bpdkkfj8B1XIfUlBqO+fudM49FDg2yaJuyuChjzM4Nz9dHRGR8PXDD954yeee88ZR3nef3xGJSBEQbPd3ElA6mzpn4Y2LLAyXBV6nOOeWAX3MbHeqsnIpcZnZngzusz1wbFRAcYqIFI5Vq+C667x1KN98E266ye+IRKSICLalcjNwSWDCzmmcc6XxWvvW5zWwbPwKPAG0BCoFXinjMC8BYgOJZIqUvcoPZ3K/lPKKmT3QOTfAORfnnIvbt29fHkIXESlAVatCgwbw+edKKEWkUAWbVM7Am5U91jmX5lrnXBQwBm9v8Kn5El0mzOwnM3vUzNaZ2aHAaznQBW//8bOB2/P5mZPMLMbMYqpVK6zefRGRHDhwAEaPBjNo3Bg+/RTOO8/vqESkiAk2qfw/YCEwGPgW+CuAc24OkIA3GWaemb2Zn0HmlJklAZMDHzukOpXSElmBjKWUHyqIuERECsyaNdC8OTz0EGzZ4pVpQXMR8UFQSaWZnQSuAh7Hmy3dCG9NyuuAsnhd0r3yOcZgpfRNn+r+NrOjwPdAeedcrQyuaRg4bivg2ERE8ocZTJgAHTp4a06uXq3WSRHxVdA76phZUmBtyGrAuUA74AKgmpmNCrQW+umiwPGbdOVLAscrMrima7o6IpIH8QmJ9J6ylviExOwrS+4MHAhDhkDXrhAf7+2SIyLio6CSSufcSefcmwDm2Wpmq83sv4FWzELhnGuRfkxnoLwT3iLqAOm3ePxX4Ph351ylVNdEA/cAvwGv53uwIkXQ+MXbWL59P+MXq/G/wFxzjbdk0Ny5UKlS9vVFRApYsEsK/QLszrZWLjjnrgWuDXysGTi2ds5NDbzfb2bDA+/HAA2dc6vxduEBaML/1pl8xMxWp76/ma12zo0B7gM2BsaBlgT+AlQG7tVuOiL5Y0jnRmmOkk9efx0OH4ahQ6FbN+8lIhIiXDAb2DjnlgI/m1n3fA/EuceAUVlUSTCz6EDd/kAP4HygKlAC+BH4FJhoZiuyeE5fvJbJ84BkYB3wvJl9kNNYY2JiLC4uLqfVRUTy5tgxGDQIXnsNunSB+fOhWNCjl0SkiHLOxZtZTIE/J8ik8grgfaCbmS0qsKhCnJJKkZyLT0hk/OJtDOnciJb1C6eb1o9nFpjt26FnT9i4ER5+GB57DKKi/I5KRMJIYSWVwXZ/V8fb5nC+c24u8Dmwlwz2ADez6XkPT0TCXcr4SoDp/VsV2HNSJ5KF9cwCd+gQtGrlLRH00UfepBwRkRAVbFI5FS+BTFlG6LpAeeqk0gU+K6kUkUIbX5k6kQz7MZ1mXiJZseL/lg2qV8/vqEREshRs93efnNY1s2m5iigMqPtbJPRETJf3t9/CjTd6Xd1qmRSRfBCS3d+RnCiKSHhrWb9Srrq6QyoZXbAAbr4Zfv8djh/3NxYRkSBp+qCIRITcLrgeEmtqnjwJjz7qtUzWrg1xcdCjh3/xiIjkQrBjKgFwzpXHW9KnOd6+2YeB9cB/zOxI/oUnIkVBfrQW5nZyTkiMv3zvPXjiCejXDyZOhLJl/YtFRCSXgk4qnXO98HanqYg3KSeFAeOcc3ea2Zx8ik9EioD8mK2d2+Qwt93m+eLQIW8yTo8eEBsLl16a/TUiIiEq2G0aLwPeAs7Am93dD2/f7H7AjED5W865zvkcp4hEsCGdG9GhYdVTCWFuurJTkkPfx0XmhBk8/zz84Q+wbZs301sJpYiEuWBbKh/F2yO7vZmtS3dumnNuIrA8UG9xPsQnIkVA+tbCiFlnMiOJidC3L8ybB9dfDzVq+B2RiEi+CDapbA68nUFCCYCZxTnn/g30zHNkIlJkhcQ4x4IQHw+9ennLBo0bB4MHe62UIiIRINik8jdgTzZ1fgjUExHJFV/HORakKVPgxAlYvhxat/Y7GhGRfBXskkIrgLbZ1GmL1wUuIiJHj8KOHd770aNh/XollCISkYJNKkcATZxzzzjnyqU+4Zwr55x7DjgfGJlfAYqIhK0tW+DPf4Yrr4SkJChTBqpW9TsqEZECEWz39whgI/A3YIBzbh3wI1ADaIG3ZuVyYIRLO07IzKx/3sMVEQkTM2fCgAHempMzZ0LxXC0LLCISNoL9v1zfVO8rAhmtgXFx4JWaAUoqRSTy/fYbDBsGr7wC7drBrFlw1ll+RyUiUuCCTSobFEgUIiKRolgx+PJLGD4cnnoKSpTwOyIRkUIRVFJpZgm5eYhz7kznXD0z252b60VEQt78+XDhhd6YydhYKFnS74hERApVsBN1cmsYsLOQniUiUniSkmDECOjWDZ580itTQikiRZBGjouI5NaePXDjjd66k3feCU8/7XdEIiK+UVIpIpIbcXFw1VXwyy8wYwbccovfEYmI+Kqwur9FRCJL/frQpAl8/rkSShERlFSKiOTcgQPw0EPeOMpq1WDhQjjvPL+jEhEJCUoqRURyYu1aaNHC22rx88/9jkZEJOQoqRQRyYoZvPgitG/vrUG5apX27hYRyYCSShGRrPztbzB4MFxxBaxbBzExfkckIhKSNPtbRCQrN98M1at7O+QU07/DRUQyE1RS6ZyrYWY/5uI5LvASEQl906bBF1/AmDHQvLn3EhGRLAX7z+7dzrm3nXOXBnnd60DHIK8RESlcx47B7bdD376wfj0cP+53RCIiYSPYpHIb0AtY5Jzb5py73zlXJbuLzCzBzD7JVYQiIoVh+3ZvAs6UKd6yQYsWQenSfkclIhI2gkoqzewCoB0wAzgLeB74zjn3pnOuQwHEJyJS8H77DTp2hG+/hQ8/9PbwLq4h5yIiwQh61LmZrTazvkBtYAjwNfBXYKlzbrNzbohzrlL+hikiUgCSkrwlg0qV8loo162Dbt38jkpEJCzleiqjmR02sxdTtV5OB+oDY/BaL6c657T2hoiEpu++g4svhkmTvM+XX+5tvSgiIrmSX+tj7AcSgeN4s7xLAb2Btc65uc65yvn0HBGRvFu40JvRvXEjVNb/nkRE8kOuk0rnXAnn3I3OuaXAFmAosA+4D6gKXAosAK4BXsqHWEVE8ubkSXjsMW8h85o1IS4OevXyOyoRkYgQ9Eh059zZwACgL1AFSAbmAi+bWWyqqsuAZc65OcAVeY5URCSv1qyBf/wD+vSBl1+GsmX9jkhEJGIEu/h5LHAJXhf3HuAJYJKZ/ZDFZfFAj9wGKCKSZ3v3ei2TbdvC559Dy5bgtB+DiEh+Crb7uyNeC2QvoJ6ZPZZNQgnwPnBbLmITEckbMxg9Gho0gNWrvbKYGCWUIiIFINju73PNbGswF5jZJmBTkM8REcmbQ4egXz+YOxeuuw7+9Ce/IxIRiWjBLn4eVEIpIuKLdeu8Lu4PPvD2754zBypU8DsqEZGIpi0jRCTyLFzo7ZLzySfQpo3f0YiIFAn5tU6liIi/jh6F9eu99w884K1BqYRSRKTQKKkUkRyJT0ik95S1xCck+h3K6b76Clq18nbFOXoUihXTouYiIoVMSaWI5Mj4xdtYvn0/4xdv8zuUtN56y5vR/dNPMHMmlCvnd0QiIkWSkkqRMONXi+GQzo3o0LAqQzo3KtTnZiopCe65B266CZo187q+O3f2OyoRkSJLSaVImPGrxbBl/UpM79+KlvUrZXi+0JPdqCg4cADuvx+WLoWzziqc54qISIY0+1skzKS0FIZMi2FASrILML1/q4J70IcfQsOG8P/t3XmclWXZwPHfxSIIIoxhgrmgBrigqYziFm68SOWapubrklpaWmJZVppZ2evSqxWl+apZLi1aalamZrjhljiIpZmCyeICKjLsiyz3+8dzBodhhlnOOXPmzPl9P5/5PJxnO9e552HmmnsdMgR+/essuZQklZxJpVRm6moMO5qiJ7srV8JFF8Hll8OJJ8Ktt5pQSlIHYlIpqSCKmuzOmgWf/nQ27+QZZ8C4ccV5H0lSm5lUSurY/vUvOPhgWLgQbrkFTjqp1BFJkhrhQB1JHdu228L++8PEiSaUktSBmVRK6njmuhq8DAAAIABJREFUzoWzzoIFC2DDDeH222GnnUodlSRpPUwqJXUsEyfC7rvDz38OTz5Z6mgkSS1kUimpY0gJrr4a9tsve/3EEzBmTGljkiS1mEmlpI7h+9+HL30JRo+GZ5+FPfYodUSSpFZw9LekjuEzn8nW7T73XOji37uSVG78yS2pdG65BY45Blavhi23hK98xYRSksqUP71VNtp9bekOoNN+5mXLsknMTzklW7974cJSRyRJypNJpcpG3drS48ZPKXUo7aZTfub//Af23htuuAEuuAD+9jfo27fUUUmS8mSfSpWNoq8t3QF1us+8ejUcfni27OI998AnPlHqiCRJBRIppVLHUHaqq6tTTU1NqcOQyseKFRAB3bpBTQ307w+DBpU6KkmqCBExKaVUXez3sflbqhAl65/5+utw4IHwrW9lr6urTSglqRMyqZQqREn6Z/7tb7DbbvCPf2RbSVKnZVIplVB71h6OHTWEkYP7t0//zFWr4LvfhUMOgc02y5q8jzuu+O8rSSoZB+pIJVRXewhwy+kjivpew7euKvp7rDF1Klx2GZx4Ilx7bTapuSSpU+sQNZURcUxE/DQiHouIBRGRIuJXzVyzT0TcGxFzI2JpRPwzIs6NiK7ruebQiHgkIuZHxKKIeDoiTin8J5Japrnaw7Kbp/LVV7Pt9ttnTd4332xCKUkVokMklcC3gC8CuwJvNHdyRBwBTABGAn8ArgY2AH4E3NbENV8E/gwMA34F3ABsDtwUEVfm/xGk1qurPRy+dVWjx+v3g+zQCWZKcNVVMHQo3Hlntm/o0GzEtySpInSU5u8vA68DrwD7Aw83dWJEbEyWEK4CDkgp1eT2XwQ8BBwTEcenlG6rd80g4EpgLlCdUpqe2/894BngvIi4M6X0VME/mZSH+vNUtmdTeavMmwennQZ/+AMceSQcfHCpI5IklUCHqKlMKT2cUpqaWjZp5jHApsBtdQll7h7LyGo8Ab7Q4JrTgB7A1XUJZe6aWuDS3MvPtzF8qWjq12S260Cblpo8GYYPhz//OaupvOsu6Nev1FFJkkqgo9RUtsZBue39jRybACwB9omIHiml5S245r4G50gdUrsOtGmpl16C5cvhkUdg331LHY0kqYQ6RE1lKw3NbdeZbC+ltBKYRpYsb9vCa2YBi4EtIqJXYUOVOqHFi+Ghh7J/f/rTWWJpQilJFa8ck8q+ue38Jo7X7a/fBtfSa/o2cVwSwMsvw4gRcOih8NZb2b6NNiptTJKkDqEck8qSiIgzIqImImreeeedUocjtb/bb8+WWHzrLbj77mxSc0mScsoxqWyuVrFu/7w2XNNUTSYppetTStUppepNN920RYFKnUJKcM45cPzxsPPO2eCc0aNLHZUkqYMpx6Ty5dx2nSGwEdEN2AZYCbzawmsGAr2B11NKSwobqtQJRECvXvDlL8Ojj8IWW5Q6IklSB1SOSWVuhABjGjk2EugFPFlv5Hdz13yswTmSAP7yF3j88ezfl10GP/whdO9e2pgkSR1WOSaVdwBzgOMjorpuZ0T0BL6fe3ltg2t+CSwHvpibCL3umirggtzL/ytSvFJ5WbkSLrggG4xz2WXZPlfGkSQ1o0PMUxkRRwJH5l4OyG33joibcv+ek1L6KkBKaUFEfI4suXwkIm4jWynncLKpg+4Abq9//5TStIj4GvAToCYibgfeI5tIfQvgKlfTkYDZs7Npgh55BD73ORg3rtQRSZLKRIdIKsnW/D6lwb5teX+uyRnAV+sOpJTujoj9gQuBo4GeZEs8fgX4SWMr86SUfhoR03P3OZmslvZF4FsppZsL+mmkcjRtGuyzD8yfDzffDCefXOqIJEllJFq2MqLqq66uTjU1Nc2fKJWT1ath7Fg480wYNqzU0UiSCiQiJqWUqps/Mz/l2KdSUqHMnZvVSL72GnTpAj/9qQmlJKlNTCqlSvXMM7D77nDbbTBxYqmjkSSVOZNKqdKkBD/7Gey3X/bvxx+Ho48udVSSpDJnUilVmp/9DM4+G0aNgmefhT33LHVEkqROoKOM/pZUbCll802edFL2+gtfyPpRSpJUAP5GkSrBrbdmzd1Ll8LGG2c1lSaUkqQC8reK1JktW5ZNEXTyydCtGyxeXOqIJEmdlEml1Fn95z/ZZObXXw/f+AY8+CD071/qqCRJnZR9KqXO6vTTYfp0+POfs3W8JUkqIpNKqTNZsQLeew9694Ybb4SuXWHQoFJHJUmqADZ/d2KTZtRy8o1PM2lGbalDUXt44w046CA47bRspPd225lQSpLajUllJzZu/BQmTJ3DuPFTSh2Kim38eNhtN5g8GY48Mps6SJKkdmRS2YmNGTaQql7dGTNsYKlDUbGsXg3f+x6MHg2bbpotvfjpT5c6KklSBTKp7MTuf2EWtUtWcP8Ls0odiorlrbfgJz+BE0/M1u/eYYdSRyRJqlAO1OnExo4astZWncgLL8COO8LAgfDcc/ChD9nkLUkqKWsqO7HhW1dxy+kjGL51ValDUaGkBD/+cdZ/8uqrs31bbGFCKUkqOWsqpXIxf3429+Sdd2aDcU4+udQRSZK0hjWVUjn4xz+guhruvhuuvBLuugv69St1VJIkrWFNpVQOFizIJjV/5BHYb79SRyNJ0jqsqZQ6qiVLsqZugI9+FKZONaGUJHVYJpVSR/Tyy7DXXnDssVkyCbDBBqWNSZKk9TCpVMG5PGSefve7rP/km2/CvffC4MGljkiSpGaZVKrgXB4yD+efD8cdB8OGZUsuHnJIqSOSJKlFHKijgnPS9Tx8+MNw7rlwxRU2d0uSykqklEodQ9mprq5ONTU1pQ5DncV992WDco4+utSRSJI6oYiYlFKqLvb72PwtlcrKlXDhhfDxj2er5PgHniSpjJlUSqUwezaMHg2XXpqtkvPAAy61KEkqa/aplNrbnDmw++4wbx7cdBOcckqpI5IkKW8mlVJ7698fzj4bDj8cdt651NFIklQQNn9L7aG2NpvIfPLk7PWFF5pQSpI6FZNKqdhqarLm7rvvhhdeKHU0kiQVhUmlVCwpwbXXwr77wurV8NhjcNJJpY5KkqSiMKmUiuW22+Css+Dgg+HZZ2HEiFJHJElS0ThQRyq0lSuhWzf41Kdg+XI4+WTo4t9vkqTOzd90UiH9+tew007w9ttZYvmZz5hQSpIqgr/tpEJYtgw+/3k48UTYbLOsD6UkSRXEpFLK16uvZoNxrrsOvv51eOghGDCg1FFJktSuTCrbYNqcxUyaUVvqMNRRXHBBllj+6U9w+eVZs7ckSRXGpLINFi1fybjxU0odhkppxQp4993s31dfnY3uPuyw0sYkSVIJWaXSBhv16MbYUUNKHYZK5c034bjjYNWqbO7J/v2zL0mSKphJZRts0783w7euKnUYKoUHH4QTToDFi+H666Fr11JHJElSh2Dzt9QSq1fDJZfAf/1XViv5zDNZcilJkgCTSqllFi+GW2/NEsmJE2GHHUodkSRJHYrN39L6TJoEO+4IffrAU0/BJptARKmjkiSpw7GmUmpMSjBuHOy1F3zve9m+D3wgr4Ry0oxaTr7xaaejkiR1SiaVUkMLFmTrdp97Lnz843D++QW57bjxU5gwdY7TUUmSOiWbv6X6/vUvOOqobDLzH/wAvvrVgjV3101D5XRUkqTOyKRSZW3SjFrGjZ/C2FFDCjPNU/fu0KULPPwwfPSj+d+vnuFbV3HL6SMKek9JkjoKm79V1grSpLxkSbZud0owZEhWW1nghFKSpM7OmkqVtbyblKdMgWOOgeefh113hREjnNBckqQ2MKlUWcurSfn3v4fTT4cNNoD77ssSSkmS1CY2f6ukSjbNzsUXw7HHwk47weTJMGZM+76/JEmdjEmlSqolfSKLknjuvTeMHQuPPgpbblm4+0qSVKFs/lZJtaRPZF3iCeQ3evq+++CVV+BLX8pqJq2dlCSpYKypLBBXS2mbuj6R65sOaOyoIYwc3L/tg3FWrYKLLsomMr/pJia98rbfK0mSCsykskBcLaVwGiboLUk8m/TWWzB6NHz/+9mgnMcfZ9yj0/xeSZJUYDZ/F4irpRROU83drZ7ofMkS2HNPePtt+MUv4NRTAb9XkiQVg0llgbhaSuE0lfS1um9lr17ZKO/qathllzW7/V5JklR4Nn+rw6hr9gYabe5uUd/K2tps7e577slen3baWgmlJEkqDpNKdRjN9Utttm/lpEkwfHiWUL75ZhEjlSRJDdn8rQ6jzX0dU8rW7h47FjbbDB57DPbaqwgRSpKkpphUqsNoc1/H8ePhC1/I5p289Vbo37/wwUmSpPUyqVT5WroUNtwQRo2CO++EI4+ELvbokCSpFPwNrPL0m9/AttvCyy9DBHzykyaUkiSVkL+FVV6WL4ezzoL//m8YPBj69Cl1RJIkiTJPKiNiekSkJr5mN3HNPhFxb0TMjYilEfHPiDg3IroWM1aXcSyAadNg333h2mvh/PPhoYdg881LHZUkSaJz9KmcD/y4kf2LGu6IiCOAO4FlwO3AXOAw4EfAvsCnihVkqyfu1rquvhpeeQX++Ec4/PBSRyNJkuqJlFKpY2iziJgOkFIa1IJzNwZeAfoC+6aUanL7ewIPAXsDn04p3dbcvaqrq1NNTU2rYm31EoPKrFyZzTm51VawbBnMng2DBpU6KkmSykZETEopVRf7fcq6+buVjgE2BW6rSygBUkrLgG/lXn6hWG/e7MTdWtebb8JBB2VfS5dCz54mlJIkdVCdofm7R0ScCGwFLAb+CUxIKa1qcN5Bue39jdxjArAE2CcieqSUlhctWrXMQw/Bpz8NixbB9ddnUwdJkqQOqzMklQOAWxvsmxYRp6aUHq23b2huu84agCmllRExDdgJ2Bb4d1EiVfNWr4bLLoNvfxuGDoWHH4Yddyx1VJIkqRnl3vz9S+BgssSyN7AzcB0wCLgvIj5S79y+ue38Ju5Vt79fYwcj4oyIqImImnfeeSffuDu1vEa6r1oF998Pxx8PEyeaUEqSVCbKuqYypfTdBrteAD4fEYuA84DvAEcV6L2uB66HbKBOIe7ZWbVppPvEibDNNrDppnDffdC7dzapuSRJKgvlXlPZlP/LbUfW21dXE9mXxtXtn1eUiCrImGEDqerVnTHDBjZ/ckrwk5/AfvvBN76R7dtoIxNKSZLKTGdNKuvap3vX2/dybjuk4ckR0Q3YBlgJvFrc0Dqvumbv3z0zk9olK7j/hVnrv2DBAjjuOBg7FsaMgSuvbJ9AJUlSwXXWpHKv3LZ+gvhQbjumkfNHAr2AJx353XZrmr0jGDm4P2NHrZO/v2/KFKiuhrvugiuugLvvhiqnW5IkqVyVbZ/KiNgBmJlSWtxg/yDg6tzLX9U7dAdwBXB8RPy0weTn38+dc20xY+7s6pLIFk3wvskmWRL50EMwcuT6z5UkSR1e2a6oExHfIRuMMwGYASwEtgM+AfQE7gWOSim9V++aI8mSy2XAbWTLNB5ONt3QHcCxqQUF0pYVdTqrVq0UtHQpjBsH550H3btn/SntOylJUlG5ok7zHgbuIUskTwC+AuwPPA6cAhxaP6EESCndnTtnAnA08CVgRe7a41uSUDYmryl0ylxdk/e48VPWXw5Tp8Jee8E3vwnjx2fn/mJiRZaZJEmdUdk2f+cmNn+02RPXve4J4OOFjKVNU+iUuboayroR3mNHDWm6HO68E049Naud/Mtf4GMfY9yNT1dcmUmS1JmVbVLZkdTvS1gpGksgGy2HH/wAvv512HNP+P3vYautmj5XkiSVrbLtU1lK9qlsRV/Kf/wDbr4ZLr8cNtig/QKUJEmAfSo7lc7Y53L41lVrmrwbfq6pt9zBPR87Kdv/kY/AD39oQilJUidnUtkO6g9m6UzW+VyrVsG3v812nzmW7SY9znX3TC5tgJIkqd3Yp7IddNb+g2t9rrffhhNOgAcfZO6nTuCqA87gC5/YpcQRSpKk9mKfyjawT2UDq1bBTjvBjBlwzTVw2mmljkiSJOW0V59KayrVdnV/kHTtClddBVtskfWhlCRJFcc+lRWmYIOG5s2DT34Srs2tbPmJT5hQSpJUwUwqK0xBBg09+ywMHw733AOrVxcuOEmSVLZs/q4weQ0aSgluuAHOOQc23RQmTIC99y5whJIkqRxZU9nOSj1n5fCtq7jl9BHrn7C8CS/e9xiceSbzR+wLkyevSShL/ZkkSVLpWVPZzspynfD586FvXy6f1YMVx1/KBgcdwM39+685XJafSZIkFZQ1le1s7KghjBzcv3zmrPztb2HrrWHCBMYMG8hLOwznkF0+tNYpZfeZJElSwZlUtrN8mp8Lqdkm6+XL4ayzsgnNd94ZttuO+1+YRe2SFdz/wqy1Tu0on0mSJJWOzd8VqmGT9aQZtYwbP4Wxo4YwPM1n8RGfpPc/JzP7jC8y4OofQvfujB3VC+h8KwNJkqT8mVRWqIajwNdKMuc/AVOncsZRF7Jsz8O4pXt34P0aSUmSpIZMKitUwwRx7AHbsvmb09hl2M4cNXEPenztlyzbdAAXWSspSZJawKRSMGsWw087nuEvvMAXNv4tk2etADakau6SUkcmSZLKhAN1Kt3DD8Nuu0FNDYwbx2eP3INdt+xHnx5dqV2yIr+VdyRJUsUwqezkmhzlnRJceimMGgVVVTBxIpx4IsO3ruLus/flptNGsOuW/ViwdIWTmkuSpGaZVHZyDdf6rksyf/P0TJ764yPMPfQoJt/5ACf/fdFayePwravYuGc3nnt9vrWVkiSpWfap7OQajvK+7ae/57UFcNnMWpaNPIu9hw6Ap95sdEWcvNYJlyRJFSVSSqWOoexUV1enmpqaUofROinBNdew4twv8+ig3bjirP9lYN+ea00pNHbUECcwlySpk4mISSml6mK/jzWV7WytScbbK4FbuBA++1n43e94e9+DuWS/z3Pmvttwwoit1pzi/JOSJCkf9qlsZw37OBbDWoNzpk+HPfaAO+6Ayy7jglMuYQYbrrPUoiRJUj6sqWxn7dFPca3Vcf77I7DddnDddUwatAvz73mRXbfoaz9JSZJUUNZUtrO6lWyK2fR97n5b8pPnf8+X9xwAPXvCX/4C++/PuPFTeO61eWy8YXf7TkqSpIIyqexspk5l+6MO4fB7b6bvI39b69DYUUMYObi/tZRqVpPzm0qS1ASTyiJq91/Md94Jw4ezesZMTj3mYr7Ta2cAfvP0THb73gO8PHth0WtJ1Tm0R99fSVLnYlJZRO35i3nG96+CY45h8baDGf/r+3hu530YM2wgv3l6Jhf84Xlql6zgf//6UtHjUOdgrbYkqbUcqFNE7Tl5+A97DmHoXsfwzGfGUvv6amqXrOB3z8xkxtwla8752iHbFz0OdQ51fX8lSWopayqLqJiDcibNqOU7X/wRj+wxmt8+OY0ZG27CA/89li+O2YnF760CYPF7q/jaIdtT1as7lx6181rzUkqSJBWSNZXlaNUqZn7pa3z7z79gSv+t+N7dz/Bql95U9eoOQO8e3dZsTxixlcmkJEkqOmsqO7h1Bvu8/TaMGcNRf76RR0aM4dvf/DmfPXovqnp1p3bJCsaNn8JFh+7IyMH9uejQHUsbvCRJqhjWVHZwa01kftqecMQR8Nxz8POfc9Bpp3FQBABDB/RZa/lH+8NJkqT2ZFLZwY0dNQRSYuyB20EEjBvHi3OWcfmsHoyZ+Br3vzDLRFKSJJWcSWUHN7xvcMtfroApg5l09jcZ93xi1vzE1LfnUDO9liUrVjFr/jIG9u25JrmUJElqb/ap7MgmT4bhw+Gee2Dzzdc0hc+evzR3QgLg1XcWOVG1JEkqKZPKAirYCjopwfXXw957w3vvwaOPwrnnMnbUEHbdsh8D+m7I4A9uxIeqetGnR1dWJajq1Z2xo4a4vJ4kSSoJk8oCKtgKOjNnwjnnwP77w7PPwj77ANm8lxv37MbUtxcxbc5ipr69iO0+2Iddt+zH1pv0anMMJqKSJClf9qksoLxX0HnrLdhsM9h6a3jySfjIR5j0+gLG3fg0Y4YN5JdPTOON2qX06t6FJStWU9WrOxcduuNaiWRbYlhrhLmDfSRJUhtESqnUMZSd6urqVFNTU9ib3nYbfO5zcN11cMIJTJpRy7jxU5g1bylT31m8JpEE6NW9K9WDqtYMzKk7t60DdfK9XpIkdVwRMSmlVF3s97GmstSWL4fzzoNrrmHR8D258I0+nJxL8iZMnUOf3Oo4S3MJJcCyFasYM2zgmgQw3+mEnI5IkiTly6SylKZPh2OPhWeeYfbnzuawgR/nnXcTM+55EYAtqjZkVm6kd/365NXA//71JZdflCRJHYZJZSk98wxMmQJ33cXn39iUd16fT58eXSElnnt9fqOX9OjWhQ26Bl87ZPt2DlaSJKlpjv5ubytXwt//DsCkPUdx1nd/x282H85/3lkMwHYf7MOxe2xF11j30i4By1euZrtNN7KWUpIkdSjWVLZRmwa3zJ4Nxx8PTz0FL7/MJX95g+dmreCxe19k4fJVBPCP1+bx7zfnsyrX3r1l1YbMW7KCARv3gAimvr0oW65RkiSpA7Gmso1aPR/kI4/AbrvBxIlwww0waBCLl60AoG+vDajq1Z1E1ndy+apE14DBm/YmpcTC5SsBuPzoXRg5uD8XHbpjUT6TJElSW5lUttHYUUMYObh/y+aDvOIKOPhg6NuXf939N05eMZRJM2rp3bM7APOXvMdx1VvSrcv7NZCrEgzstyHzl2YJ5ewFy9eM0nbaH0mS1NGYVLZRcwneWqvUzJ+/ZpT3Fa91Y8LUOVySG+Hdp0dXFi5fxQ2PvcrK1WvPGbrjwI355sd3oKpXd7758R2K/pkkSZLayj6VRfKnG+5m8fQ5XLJsJX23OYxzzhgKc1eyYNlKqnp157nX5gGw65b9mDJ7wZqJzYP3pw+65anpvHjJxxyUI0mSOjxrKgstJbjmGi7+wZlc8dQtsHo1j/5nLuMenMq48VN47rV51C5Zseb0OYuWr0koAc4cuS29unfNvQrX5ZYkSWXBpLJAJs2o5YxrHmLuEcfAF79Il9Gj+fAzj3LR4cPYdct+zJq/jJdmL1jnutdrl671+vaa1/jWoTtS1as732qwrrckSVJHZfN3gfzyzqf4+v+cSb/aN+Gyy+D886FLF4ZvAhv37Lamubsxm/bZgAVLVtK1C3ztkO05YcRWa5q8hw7oA9CyAUGSJEklYlKZh/pzVZ561Ahe/8NurDz7Zww9/rC1zhszbCCTZ84DEguXr1rnPh/q14sdBnRrdM5L1+WWJEnlwKQyDz+795/s/4sf8at3T+VH5x8Bj/1pnXMmzajlstzk5nW6Buz8ob4cu8dW/PKJaTz/+rw1k52bQEqSpHJkUtlGz094lgsv/Rzbvj6VGZ/cn0kzarNpglLiosN2WlPjOG78lLUSygAuOXLnNc3b//vXl1iVoFuXsIlbkiSVLZPKtpg3j20PGckKgu+feTnf+uaXuejGp9f0m6xrEj/3tsm80WAgTgJmvruYI695AlLiuOot+fXTM7NlGCVJkspUpJSaP0trqY5Iv9l6B0772FfpP2wod5+9L5Nm1PKNO//JG7VL2WSjDZi76D2WrFi3/yRkzd91zd27btGXjTfszoSpcxg5uL/N35IkqaAiYlJKqbrY7+OUQm2x+eYseuAhtq3eaa11uLM5J1fxeu3StRLKrrnVF7t3Dfr06MrAvj3fv1fEWks+tmZeSuewlCRJHYXN320xcCC7DxnALUMGrEnsFixdQe2SFfTp0Y2+vbrzzoLlrE6JlavTmlrJnt26cNNpWU3kmv6Xh+641gjvk298mglT5wDND9qpm8OyJedWmvoj810rXZKk4jOpzNMl97zIc6/N44N9etCtS7DbVv148j/vrrOON8DC5av47M3P8PNT9uDus/dt9H51g3VaMminNedWGhNuSZLal30q26C6ujrV1NQwaUYtJ9zwd5avXN3oeRv16Mrq1QCJJStW061LsHJ1su9kO7CmUpKkTHv1qbSmso0mzajlM7+Y2GRCCbB4+Sq6dgkO3WUgcxe/x44DN+b2mtcYM2xgO0ZamZw0XpKk9uVAnTaYNmcxY2+bzMLlK9d7XgJWrk7c889Z3HL6CF6ctYDaJSu4/4VZ7ROoJElSO6m4pDIitoiIX0TEmxGxPCKmR8SPI6LFbaSLlq/k9QbzTzame9ega8Bn99sGYK1R3pIkSZ1JRSWVEbEdMAk4FZgI/Ah4FRgLPBURHyjUe3UNWLEqse+H+/ONj+8AvN8kO3zrKqcDkiRJnUpFJZXAz4APAueklI5MKX0jpXQQWXI5FPifQrxJ3VKM66uVrBudPG78lEK8pSRJUklVzECdXC3laGA6cE2DwxcDZwAnRcR5KaXFbXmPHt260DWCD/XrydABfdas790YpwOSJEmdSSXVVB6Y2z6QUlpryHZKaSHwBNAL2Kutb3DxYTtRPaiKqe8sbrYGsn5TuCRJUrmrpKRyaG7bVLY3Nbdtc9Xh/S/McjCOJEmqSBXT/A30zW3nN3G8bn+/xg5GxBlkTeR023jTdY53DRgzbKDzI0qSpIpUSTWVeUkpXZ9Sqk4pVXfp1Xed46sSnXb+SUeqS5Kk5lRSUllXE7luRrj2/nmtvXG/Xt06dZO3I9UlSVJzKqn5++XctqnMb3Bu2+LMqWtkNZSDPrBRp27ydqS6JElqTiXVVD6c246OiLU+d0T0AfYFlgB/b8nNunUJPvfRbanq1Z1jq7csbKQdjCPVJUlScyomqUwp/Qd4ABgEnN3g8HeB3sCtLZmjsmuX4HtHDHMtb0mSpJxKav4GOAt4EvhJRBwM/BsYQTaH5RTgwpbcZMeBG3PCiK0YOqAPC5atZMHSFUyaUWtNniRJqlgVU1MJa2orq4GbyJLJ84DtgHHAXimld1tzv+FbV7Fxz24cCK9eAAAN4klEQVQ89/p8B7FIkqSKVmk1laSUXgNOLdT9HMQiSZJUgUlloTnZuSRJUoU1f0uSJKk4TCqLxFVoJElSJTGpLBJXoZEkSZXEPpVF4gAeSZJUSUwqi8QBPJIkqZLY/C1JkqS8mVRKkiQpbyaVkiRJyptJpSRJkvJmUilJkqS8mVRKkiQpbyaVkiRJyptJpSRJkvJmUilJkqS8mVRKkiQpbyaVkiRJyptJpSRJkvJmUilJkqS8mVRKkiQpbyaVkiRJyptJpSRJkvJmUilJkqS8mVRKkiQpb5FSKnUMZSciFgIvlzqOMtUfmFPqIMqY5Zcfyy8/ll/bWXb5sfzyMzSl1KfYb9Kt2G/QSb2cUqoudRDlKCJqLLu2s/zyY/nlx/JrO8suP5ZffiKipj3ex+ZvSZIk5c2kUpIkSXkzqWyb60sdQBmz7PJj+eXH8suP5dd2ll1+LL/8tEv5OVBHkiRJebOmUpIkSXkzqZQkSVLeTCpbKCK2iIhfRMSbEbE8IqZHxI8joqrUsXUEufJITXzNbuKafSLi3oiYGxFLI+KfEXFuRHRt7/jbQ0QcExE/jYjHImJBrmx+1cw1rS6jiDg0Ih6JiPkRsSgino6IUwr/idpXa8ovIgat53lMEXHbet7nlIiYmCu7+bmyPLR4n6z4IuIDEfHZiPhDRLySe5bmR8TjEXF6RDT6u8DnL9Pa8vP5W1tEXBERD0bEa7mymxsRkyPi4oj4QBPX+OzltKb8Sv3s2aeyBSJiO+BJ4IPAH4GXgD2BA8kmQd83pfRu6SIsvYiYDvQDftzI4UUppSsbnH8EcCewDLgdmAscBgwF7kgpfaqoAZdARDwHfARYBLwObA/8OqV0YhPnt7qMIuKLwE+Bd3PXvAccA2wBXJVS+mqBP1a7aU35RcQgYBrwD+DuRm73QkrpjkauuxI4L3f/O4ANgOOBTYAvpZSuLsRnaW8R8XngWmAW8DAwE9gM+CTQl+w5+1Sq9wvB5+99rS0/n7+1RcR7wLPAi8DbQG9gL6AaeBPYK6X0Wr3zffbqaU35lfzZSyn51cwX8Fcg5Qq2/v4f5vb/X6ljLPUXMB2Y3sJzN879x1gOVNfb35MseU/A8aX+TEUoowOBwUAAB+Q+568KVUbAILIfwu8Cg+rtrwJeyV2zd6nLoZ3Kb1Du+E2tuP8+uWteAaoa3OvdXNkOyuczlLDsDiL7pdylwf4BZAlSAo72+StY+fn8rf3Zejax/39yn/lnPnsFK7+SPns2fzcjV0s5mixpuqbB4YuBxcBJEdG7nUMrZ8cAmwK3pZTWzPKfUloGfCv38gulCKyYUkoPp5Smptz/1ma0pYxOA3oAV6eUpte7pha4NPfy820Mv+RaWX5tUVc2/5Mrs7r3nU72f78HcGqR3ruoUkoPpZT+nFJa3WD/bOD/ci8PqHfI56+eNpRfW3Tm529ZE4d+l9sOrrfPZ6+BVpZfWxTs2TOpbN6Bue0DjfxAWQg8AfQiq4qudD0i4sSIuCAixkbEgU30fzkot72/kWMTgCXAPhHRo2iRdnxtKaP1XXNfg3MqxeYRcWbumTwzInZZz7mVWn4rctuV9fb5/LVcY+VXx+dv/Q7Lbf9Zb5/PXss1Vn51SvLsufZ384bmtlOaOD6VrCZzCPBgu0TUcQ0Abm2wb1pEnJpSerTevibLNKW0MiKmATsB2wL/LkqkHV9bymh918yKiMXAFhHRK6W0pAgxd0T/lftaIyIeAU5JKc2st6838CGy/r+zGrnP1Nx2SJHiLImI6AacnHtZ/xeKz18LrKf86vj81RMRXwU2IuuHWg3sR5YQXV7vNJ+9JrSw/OqU5NmzprJ5fXPb+U0cr9vfrx1i6ch+CRxMllj2BnYGriPrk3FfRHyk3rmWafPaUkYtvaZvE8c7kyXAJcBwsn5VVcD+ZIMsDgAebNBlpVKfycuBYcC9KaW/1tvv89cyTZWfz1/jvkrWbexcsoTofmB0Sumdeuf47DWtJeVX0mfPpFIFkVL6bq7f0VsppSUppRdSSp8nG8y0IfCd0kaoSpJSejul9O2U0rMppXm5rwlkrQpPAx8GPlvaKEsrIs4hG+35EnBSicMpO+srP5+/xqWUBqSUgqzy4ZNktY2TI2L30kZWHlpSfqV+9kwqm9fcXzh1++e1QyzlqK4T+8h6+yzT5rWljFp6TVN/kXZ6KaWVwM9zLyv2mcxNvzKObIqSA1NKcxuc4vO3Hi0ov0b5/GVylQ9/IEt0PgDcUu+wz14zmim/pq5pl2fPpLJ5L+e2TfUnqBt11VSfy0pXVy1fv7q9yTLN9VHahqzT+6vFDa1Da0sZre+agWTfg9fLuU9RgazzTKaUFgNvABvlyqqhTvP/PCLOJZvP7wWyhKixxQl8/prQwvJbn4p+/upLKc0gS8x3ioj+ud0+ey3URPmtT9GfPZPK5j2c246OdVdN6APsS9aH4e/tHViZqBsVX/8HwEO57ZhGzh9JNpr+yZTS8mIG1sG1pYzWd83HGpxTyRp7JqECyi8ivg78CHiOLCF6u4lTff4a0YryW5+Kff6asHluuyq39dlrnYbltz7Ff/ZaMpllpX/h5OfNlc8OQO9G9g8iGzmWgAvq7d+Y7C+mipr8vEHZHEDzk5+3qozI/oLvtBMAt7L8dqfBRNW5/QfnyigB+zQ41mknn859jotyn68G2KSZc33+8is/n7/34x8C9G1kfxfen7z7CZ+9gpVfSZ89l2lsgUaWafw3MIJsDsspZN+gil2mMSK+Q9ZhfQIwA1gIbAd8guwHwb3AUSml9+pdcyTZUlDLgNvIluE6nNwyXMCxqZM9nLnPfGTu5QDgELK/GB/L7ZuT6i0l1pYyiogvAT+hcy5V1uLyy02dMZjs/+3rueO78P5caxellL7fyHtcBXyFtZcqO46s31I5L5N3CnATWW3GT2m8b9n0lNJN9a7x+ctpbfn5/L0v113gMuBxsuUD3yVb4nJ/soEms4GDU0ov1rvGZy+nteVX8mev1Fl4uXwBW5JNmzOL7GGdQbbOdVWpYyv1V+7h/i3ZKMh5ZJMBvwP8jWwOt2jiun3JEs5aYCnwPPBloGupP1ORyuk7ZH8NNvU1vRBlRDYh7qNkyf1i4BmyuclKXgbtVX7A6cA9ZCthLSKr9ZhJ9svmo828z2dyZbY4V4aPAoeW+vMXuewS8IjPX2HKz+dvrc8zDLiarMvAHLL+kPNzn/E7NFHr67PXtvIr9bNnTaUkSZLy5kAdSZIk5c2kUpIkSXkzqZQkSVLeTColSZKUN5NKSZIk5c2kUpIkSXkzqZQkSVLeTColSZKUN5NKSZIk5c2kUpIkSXkzqZSkRkTE9hGRIuLh9ZzzfESsiIiBbbj/iIi4IyJmR8R7EfFaRFwXEZs3OO/uXBznNHKPS3LHbqy374Dcvu9ExN4RMT4i5kfEwoj4a0RUtzZWSWoJ1/6WpCZExEPAgcDQlNKUBsf2AZ4A7kwpHdPK+54GXA8sB/4EvAYMBg4H3gL2SinNzJ27CTAZ2AzYO6U0Obf/YOAB4CVgj5TSktz+A4CHgfuBg4DxwD+ADwOfBFYAo1NKj7UmZklqjkmlJDUhIo4Bfg9clVL6aoNjNwGnkCVof2vFPYcALwAzgf1TSm/UO1aXKP4ppXRUvf37AI8C04Ddgd7Ac0BfsoTyX/XOPYAsqQT4Ukrp6nrHjgDuBl4hS5RXtzRuSWqOSaUkNSEiupElfxsAH0opLc/t7we8mfsanFrxgzQifgScCxyaUvpLI8f/ABwGVKWUFtbb/w3gMuA3wKbAfwGfSyn9vMH1B5AllY0mjhHxCLA/cEBK6dGWxi1JzelW6gAkqaNKKa2MiBuAbwNHkyV0ACcBGwLXtyahzNk7t90/IvZo5PgHga7AEGBSvf1XkDXFn5B7/duGCWUDjzVRE/kIWVK5G1ntpyQVhEmlJK3f9cCFwJm8n1SeAbwH/LIN9/tAbvu1Zs7bqP6LlFKKiLuA0bldP27m+rea2D87t+3bzPWS1ComlZK0HimlNyLiT8BREbE9sAkwDLg9pfROG245P7ftm1Ja0NKLImIwcCVQS5YQ/jwi9kwpLWviks2a2D+gQRySVBBOKSRJzftZbnsmWS0lwHVtvNffc9uPtvSCiOgB3E42QOc4sr6VO7P+2sr9IqKxn/EH5LaTW/r+ktQSJpWS1LwHgSlko72PBV5OKTU5f2Uzriab1udHuZHga4mIDSKiYcJ5JVkfyB/kRppfTDad0ZkR8akm3mcwcFaDex9B1p/yFcAphSQVlKO/JakFIuLLwA9zL89LKf1wfec3c68TgV8AQTaf5BSgO7AVWQ3mOyml7XPnHgXcBTwN7JdSWpnbvyXZtELdgN1SSq/m9h+A81RKKgGTSklqgYioAuaQDdDZIqX0bp732xk4j2xE9wBgMdkURU+Q9dd8KCK2IkscuwC7ppSmN7hH3byTz5AlnO/VSyq/C/wVuATYkyyBfQq4MKX0TD6xS1JjHKgjSS3zEbLk7o58E0qAlNLzwGeaOWcm2cCgpo7/kSxZbOr4U8CoNoYoSa1in0pJapnzc9ur13uWJFUoayolqQm5JupDgeHAx4B7UkpPlzYqSeqYTColqWnDgUuBBWRrgJ/V8ISIGEQzzdj1/DilNK9AsUlSh+JAHUnKQ72BMS2xTcPBNpLUWZhUSpIkKW8O1JEkSVLeTColSZKUN5NKSZIk5c2kUpIkSXkzqZQkSVLeTColSZKUt/8H2QYMn3f0EMAAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U7DQ-cx9M0P"
      },
      "source": [
        "# Problem 1 validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMy7y98N9C7C",
        "outputId": "62b6d717-c81d-47e3-9bb2-05869e6ca9b7"
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        " \n",
        "\n",
        "classes = ['politics', 'business', 'tech', 'entertainment', 'sport']\n",
        "\n",
        "y_true = [0] * 141 + [1] * 167 + [2] * 133 + [3] * 128 + [4] * 166\n",
        "\n",
        "\n",
        "# row: actual, col: predict\n",
        "confusion_matrix = np.array([[140, 1, 0, 0, 0],\n",
        "                             [4, 160, 2, 0, 1],\n",
        "                             [1, 3, 128, 0, 1],\n",
        "                             [0, 0, 1, 127, 0],\n",
        "                             [0, 1, 0, 0, 165],])\n",
        "\n",
        "row_cnt, col_cnt = confusion_matrix.shape\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for row in range(row_cnt):\n",
        "    y_true += [row] *  confusion_matrix[row, :].sum()\n",
        "    for col in range(col_cnt):\n",
        "        y_pred += [col] *  confusion_matrix[row, col] \n",
        "\n",
        "print(\"Confusion matix:\")\n",
        "print(metrics.confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(metrics.classification_report(y_true, y_pred, digits=4))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matix:\n",
            "[[140   1   0   0   0]\n",
            " [  4 160   2   0   1]\n",
            " [  1   3 128   0   1]\n",
            " [  0   0   1 127   0]\n",
            " [  0   1   0   0 165]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9655    0.9929    0.9790       141\n",
            "           1     0.9697    0.9581    0.9639       167\n",
            "           2     0.9771    0.9624    0.9697       133\n",
            "           3     1.0000    0.9922    0.9961       128\n",
            "           4     0.9880    0.9940    0.9910       166\n",
            "\n",
            "    accuracy                         0.9796       735\n",
            "   macro avg     0.9801    0.9799    0.9799       735\n",
            "weighted avg     0.9797    0.9796    0.9796       735\n",
            "\n"
          ]
        }
      ]
    }
  ]
}