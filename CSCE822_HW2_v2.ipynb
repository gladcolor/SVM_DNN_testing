{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE822_HW2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "mount_file_id": "1jS19KitmzfFJ7EHKaibSYIn9UnBMQbrl",
      "authorship_tag": "ABX9TyO/ETITFIEJxmvSFGYpxAm5",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gladcolor/SVM_DNN_testing/blob/master/CSCE822_HW2_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8PEaZ-2GOFjp"
      },
      "source": [
        "# Classification using SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIBmefr5003e"
      },
      "source": [
        "## Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWb6nL5k31q"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "# import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import cross_validate\n",
        "\n",
        "from sklearn.linear_model import LinearRegression as LR\n",
        "from sklearn.metrics import r2_score"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2v7rzRQdFVpI",
        "outputId": "5bf180f3-4731-49c7-c153-310f4b9cd09f"
      },
      "source": [
        "cwd = r'/content/drive/MyDrive/USC_courses/CSCE822'\n",
        "if not os.path.exists(cwd):\n",
        "    os.makedirs(cwd)\n",
        "% cd $cwd"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/USC_courses/CSCE822\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZDU1PIxnTs"
      },
      "source": [
        "## Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICR2HJwxq37"
      },
      "source": [
        "def print_str_unique(df):\n",
        "    for col in df.columns:\n",
        "        if original_data.dtypes[col] == np.object:            \n",
        "            unique_cnt = len(df[col].unique())\n",
        "            print(f'Column {col.rjust(13)} has {unique_cnt:5} unique values.')\n",
        "\n",
        "def count_column_nan(df):\n",
        "    row_cnt = len(df)\n",
        "    for col in df.columns:\n",
        "        nan_cnt = df[col].isna().sum()\n",
        "        percent_str = f'({(nan_cnt / row_cnt * 100):3.1f}%)'.rjust(7)\n",
        "        print(f'Column {str(col).rjust(13)} has {nan_cnt:4} {percent_str} nan values.')       \n",
        "\n",
        "def impute_df(df, strategy=\"most_frequent\"):\n",
        "    \n",
        "    numeric_cols = ['BuildingArea', 'YearBuilt', 'Car']\n",
        "    nominal_cols = ['CouncilArea']\n",
        "\n",
        "    my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "    council_area_with_imputed_values = my_imputer.fit_transform(df[nominal_cols])\n",
        "    imputed_df = df.copy()\n",
        "    imputed_df.loc[:, nominal_cols] = council_area_with_imputed_values\n",
        "\n",
        "\n",
        "    if strategy == \"most_frequent\":\n",
        "        my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "        data_with_imputed_values = my_imputer.fit_transform(df)        \n",
        "        imputed_df.loc[:, :] = data_with_imputed_values\n",
        "\n",
        "    if strategy == \"mean\":\n",
        "        my_imputer = SimpleImputer(strategy=\"mean\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    if strategy == \"median\":\n",
        "        my_imputer = SimpleImputer(strategy=\"median\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    return imputed_df\n",
        "\n",
        "def encode_dates(imputed_df):\n",
        "    imputed_df['Date'] = pd.to_datetime(imputed_df['Date']) \n",
        "    imputed_df['Ori_Date'] = pd.to_datetime('1970-01-01', format='YY-m-d', errors='ignore')\n",
        "    imputed_df['Ori_Date'] = pd.to_datetime(imputed_df['Ori_Date'])\n",
        "    imputed_df['delta_days'] = imputed_df['Date'] - imputed_df['Ori_Date']\n",
        "    imputed_df['delta_days'] = imputed_df['delta_days'].dt.days\n",
        "    imputed_df = imputed_df.drop(columns=['Date', 'Ori_Date'])\n",
        "     \n",
        "    return imputed_df\n",
        "\n",
        "\n",
        "\n",
        "def encoder_nominals(imputed_df, encode_method='one_hot'):\n",
        "    # print(f'Encode methods: {ENCODING_METHODS_DICT.keys()} \\n')\n",
        "    \n",
        "    ce_encoder = ENCODING_METHODS_DICT[encode_method](cols = ENCODING_COLUMNS)\n",
        "\n",
        "    y = imputed_df['Price_class'].copy()\n",
        "    \n",
        "    for drop_column in DROPPED_COLUMNS:\n",
        "        try:\n",
        "            imputed_df = imputed_df.drop(columns=drop_column).copy()\n",
        "        except:\n",
        "            pass\n",
        "            # print(f'Columns: {drop_column} have already dropped before.')\n",
        "\n",
        "    encoded_df = ce_encoder.fit_transform(imputed_df, y=y) \n",
        "\n",
        "    return encoded_df\n",
        "\n",
        "def assign_price_class(imputed_df):\n",
        "    row_cnt = len(imputed_df)\n",
        "    price_class_cnt = 5\n",
        "    class_step = int(row_cnt / price_class_cnt)\n",
        "    price_bins = list(range(class_step, row_cnt,  class_step))\n",
        "\n",
        "    imputed_df.loc[0:price_bins[0], 'Price_class'] = '0' # 'bottom_value'\n",
        "    imputed_df.loc[price_bins[0]:price_bins[1], 'Price_class'] = '1' # 'low_value'\n",
        "    imputed_df.loc[price_bins[1]:price_bins[2], 'Price_class'] = '2' # 'medium_value'\n",
        "    imputed_df.loc[price_bins[2]:price_bins[3], 'Price_class'] = '3' # 'high_value'\n",
        "    imputed_df.loc[price_bins[3]:row_cnt, 'Price_class'] = '4'  #  'top_value'\n",
        "\n",
        "    imputed_df['Price_class'] = imputed_df['Price_class'].astype(int)\n",
        "\n",
        "    # gb = imputed_df.groupby('Price_class')['Price_class'].count().to_frame()\n",
        "    # gb.columns = ['Count']\n",
        "    # custom_dict = {'bottom_value': 0, 'low_value': 1, 'medium_value': 2, 'high_value': 3, 'top_value': 4}\n",
        "    # gb.sort_index(key=lambda x: x.map(custom_dict))\n",
        "    # print(\"Price class counts:\")\n",
        "    return imputed_df    \n",
        "\n",
        "\n",
        "def split_data(encoded_df):\n",
        "    X = encoded_df.drop(columns=['Price_class'])\n",
        "    y = encoded_df['Price_class']\n",
        "\n",
        "    train_ratio = 0.75\n",
        "    validation_ratio = 0.10\n",
        "    test_ratio = 0.15\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size= (1 - train_ratio), random_state = 0)\n",
        "\n",
        "    xVal, xTest, yVal, yTest = train_test_split(xTest, yTest, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 0) \n",
        "\n",
        "    \n",
        "    return xTrain, yTrain, xVal, yVal, xTest, yTest   \n",
        "\n",
        "def standardize_data(encoded_df, class_col='Price_class'):\n",
        "    labels = encoded_df[class_col].copy()\n",
        "    data_df = encoded_df.drop(columns=[class_col])\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    scaler.fit(data_df) \n",
        "    data_df.iloc[:, :] = scaler.transform(data_df)\n",
        "    data_df.loc[:, class_col] = labels\n",
        "    return data_df\n",
        "           \n",
        "\n",
        "\n"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIMZpvts08nT"
      },
      "source": [
        "## Load and understand the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-o6yMjxeL4am",
        "outputId": "48fa9490-3949-4928-fd01-7869882f56d4"
      },
      "source": [
        "test_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000.zip'\n",
        "test_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "train_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000.zip'\n",
        "train_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000_Label.zip'\n",
        "\n",
        "train_df = pd.read_csv(train_csv, header=None)\n",
        "train_label_df = pd.read_csv(train_label_csv, header=None)\n",
        "test_df = pd.read_csv(test_csv, header=None)\n",
        "test_label_df = pd.read_csv(test_label_csv, header=None)\n",
        "\n",
        "print(\"Training sets samples:\")\n",
        "train_df.sample(4)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets samples:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>300</th>\n",
              "      <th>301</th>\n",
              "      <th>302</th>\n",
              "      <th>303</th>\n",
              "      <th>304</th>\n",
              "      <th>305</th>\n",
              "      <th>306</th>\n",
              "      <th>307</th>\n",
              "      <th>308</th>\n",
              "      <th>309</th>\n",
              "      <th>310</th>\n",
              "      <th>311</th>\n",
              "      <th>312</th>\n",
              "      <th>313</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>939</th>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>1.0</td>\n",
              "      <td>40</td>\n",
              "      <td>197000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>91</td>\n",
              "      <td>1</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "      <td>170</td>\n",
              "      <td>419</td>\n",
              "      <td>447</td>\n",
              "      <td>315</td>\n",
              "      <td>7</td>\n",
              "      <td>911</td>\n",
              "      <td>350</td>\n",
              "      <td>854</td>\n",
              "      <td>310</td>\n",
              "      <td>2114</td>\n",
              "      <td>5</td>\n",
              "      <td>62</td>\n",
              "      <td>6006.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>31</td>\n",
              "      <td>23</td>\n",
              "      <td>1696</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>1980</td>\n",
              "      <td>1978</td>\n",
              "      <td>332</td>\n",
              "      <td>...</td>\n",
              "      <td>90</td>\n",
              "      <td>87</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>53</td>\n",
              "      <td>8</td>\n",
              "      <td>3</td>\n",
              "      <td>14</td>\n",
              "      <td>13</td>\n",
              "      <td>8</td>\n",
              "      <td>7</td>\n",
              "      <td>83</td>\n",
              "      <td>64</td>\n",
              "      <td>20</td>\n",
              "      <td>5</td>\n",
              "      <td>66</td>\n",
              "      <td>10</td>\n",
              "      <td>50</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>42</td>\n",
              "      <td>4</td>\n",
              "      <td>80</td>\n",
              "      <td>51</td>\n",
              "      <td>8</td>\n",
              "      <td>85</td>\n",
              "      <td>20</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>30</td>\n",
              "      <td>18</td>\n",
              "      <td>346</td>\n",
              "      <td>132</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6532</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>48</td>\n",
              "      <td>1</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>96</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>458</td>\n",
              "      <td>481</td>\n",
              "      <td>381</td>\n",
              "      <td>7</td>\n",
              "      <td>871</td>\n",
              "      <td>310</td>\n",
              "      <td>745</td>\n",
              "      <td>250</td>\n",
              "      <td>2463</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>705.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>27</td>\n",
              "      <td>36</td>\n",
              "      <td>2380</td>\n",
              "      <td>17</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>21</td>\n",
              "      <td>12</td>\n",
              "      <td>1965</td>\n",
              "      <td>1965</td>\n",
              "      <td>389</td>\n",
              "      <td>...</td>\n",
              "      <td>91</td>\n",
              "      <td>89</td>\n",
              "      <td>47</td>\n",
              "      <td>12</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>23</td>\n",
              "      <td>17</td>\n",
              "      <td>8</td>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>47</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>65</td>\n",
              "      <td>8</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>29</td>\n",
              "      <td>3</td>\n",
              "      <td>71</td>\n",
              "      <td>45</td>\n",
              "      <td>15</td>\n",
              "      <td>76</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>39</td>\n",
              "      <td>23</td>\n",
              "      <td>290</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3792</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>11</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>410</td>\n",
              "      <td>442</td>\n",
              "      <td>301</td>\n",
              "      <td>6</td>\n",
              "      <td>513</td>\n",
              "      <td>330</td>\n",
              "      <td>509</td>\n",
              "      <td>300</td>\n",
              "      <td>1216</td>\n",
              "      <td>5</td>\n",
              "      <td>54</td>\n",
              "      <td>2078.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>36</td>\n",
              "      <td>32</td>\n",
              "      <td>1128</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>16</td>\n",
              "      <td>10</td>\n",
              "      <td>1965</td>\n",
              "      <td>1968</td>\n",
              "      <td>308</td>\n",
              "      <td>...</td>\n",
              "      <td>78</td>\n",
              "      <td>74</td>\n",
              "      <td>49</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>24</td>\n",
              "      <td>15</td>\n",
              "      <td>36</td>\n",
              "      <td>23</td>\n",
              "      <td>66</td>\n",
              "      <td>47</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>75</td>\n",
              "      <td>13</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>19</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>30</td>\n",
              "      <td>24</td>\n",
              "      <td>18</td>\n",
              "      <td>11</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>7</td>\n",
              "      <td>169</td>\n",
              "      <td>117</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3687</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>7.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>51</td>\n",
              "      <td>2</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>21</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>483</td>\n",
              "      <td>512</td>\n",
              "      <td>393</td>\n",
              "      <td>7</td>\n",
              "      <td>746</td>\n",
              "      <td>290</td>\n",
              "      <td>651</td>\n",
              "      <td>250</td>\n",
              "      <td>1857</td>\n",
              "      <td>4</td>\n",
              "      <td>62</td>\n",
              "      <td>2318.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>25</td>\n",
              "      <td>14</td>\n",
              "      <td>1522</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>1988</td>\n",
              "      <td>1986</td>\n",
              "      <td>408</td>\n",
              "      <td>...</td>\n",
              "      <td>84</td>\n",
              "      <td>65</td>\n",
              "      <td>28</td>\n",
              "      <td>12</td>\n",
              "      <td>45</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>20</td>\n",
              "      <td>12</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>77</td>\n",
              "      <td>63</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>57</td>\n",
              "      <td>7</td>\n",
              "      <td>49</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>13</td>\n",
              "      <td>34</td>\n",
              "      <td>5</td>\n",
              "      <td>80</td>\n",
              "      <td>48</td>\n",
              "      <td>18</td>\n",
              "      <td>83</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>4</td>\n",
              "      <td>58</td>\n",
              "      <td>18</td>\n",
              "      <td>339</td>\n",
              "      <td>149</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows Ã— 334 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1         2    3         4    ...  329  330  331  332  333\n",
              "939        1.0   40       1.0   40  197000.0  ...    3   30   18  346  132\n",
              "6532  999000.0   46       1.0   46  196000.0  ...    2   39   23  290  205\n",
              "3792  999000.0   46  999000.0   46  196000.0  ...    2   12    7  169  117\n",
              "3687  999000.0   46       1.0   46  196000.0  ...    4   58   18  339  149\n",
              "\n",
              "[4 rows x 334 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 256
        },
        "id": "ESJ1v2ctmXMn",
        "outputId": "22c73e20-f11f-4e85-c40f-5a7c762f66d5"
      },
      "source": [
        "print(\"County nan data:\")\n",
        "\n",
        "print(f\"Train data have {train_df.isna().sum().sum()} nan values.\")\n",
        "print(f\"Test data have {test_df.isna().sum().sum()} nan values.\")\n",
        "\n",
        "train_1 = train_df[train_label_df[0] == 1]\n",
        "train_0 = train_df[train_label_df[0] == 0]\n",
        "\n",
        "def sample_train_dataset(positive_count=len(train_1), negative_count=len(train_1)):\n",
        "    positive_count = len(train_1)\n",
        "    negative_count = len(train_1)\n",
        "\n",
        "    balanced_train = np.concatenate((train_1.sample(positive_count, replace=True), train_0.sample(negative_count, replace=True)), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    print(f\"Positive sample counts in the training set: {positive_count}\")\n",
        "    print(f\"Negative sample counts in the training set: {negative_count}\")\n",
        "\n",
        "    return balanced_train, balanced_train_label\n",
        "\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Positive sample counts: {len(train_1)}\")\n",
        "print(f\"Negative sample counts: {len(train_0)}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "County nan data:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-503c67d49420>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"County nan data:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Train data have {train_df.isna().sum().sum()} nan values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Test data have {test_df.isna().sum().sum()} nan values.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_df' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIJ1ofkC2EWC"
      },
      "source": [
        "## Train 10 SVM models in an ensemble learning manner\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBFsjulHaEzl"
      },
      "source": [
        "### Train 10 models witouth cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SPV2nT8aFWq",
        "outputId": "c5d5f43d-761d-44a5-8f96-3e79ce5f94c9"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "trained_model_list = []\n",
        "\n",
        "score_roc_auc_list = []\n",
        "score_precision_list = []\n",
        "score_recall_list = []\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "     # create a balancd training set\n",
        "    train_1 = train_df[train_label_df[0] == 1].sample(frac=1)  # shuffle\n",
        "\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    # Use SVM\n",
        "    # clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "    #                                           kernel='rbf',\n",
        "    #                                           verbose=True, probability=True))\n",
        "    \n",
        "    # Use random forest\n",
        "    clf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=500))\n",
        "\n",
        "    clf.fit(balanced_train, balanced_train_label)\n",
        "\n",
        "    trained_model_list.append(clf)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "Training # 2 model...\n",
            "Training # 3 model...\n",
            "Training # 4 model...\n",
            "Training # 5 model...\n",
            "Training # 6 model...\n",
            "Training # 7 model...\n",
            "Training # 8 model...\n",
            "Training # 9 model...\n",
            "Training # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boerEWK9mXbH"
      },
      "source": [
        "### Evaluate the trained 10 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtWI6u3bQrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245d8be4-0f9c-4b22-995a-b7bed8c5a7df"
      },
      "source": [
        "print(\"Evaluating...\")\n",
        "test_pred_list = []\n",
        "for idx, clf in enumerate(trained_model_list):\n",
        "    print(f\"Testing # {idx + 1} model...\")\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n",
            "Testing # 1 model...\n",
            "Testing # 2 model...\n",
            "Testing # 3 model...\n",
            "Testing # 4 model...\n",
            "Testing # 5 model...\n",
            "Testing # 6 model...\n",
            "Testing # 7 model...\n",
            "Testing # 8 model...\n",
            "Testing # 9 model...\n",
            "Testing # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggjXh9sZkvZw"
      },
      "source": [
        "### Print out assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ8Uu_LWktVA",
        "outputId": "f6ed9cbd-d17a-4401-f84d-b2af22b17053"
      },
      "source": [
        "test_pred_all = np.array(test_pred_list)\n",
        "\n",
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "\n",
        "recall_score = metrics.recall_score(np.array(test_label_df), pred_label, average='macro')\n",
        "mcc_score = metrics.matthews_corrcoef(np.array(test_label_df), pred_label)\n",
        "roc_auc_score = metrics.roc_auc_score(test_label_df, test_pred_all[:, :, 1].mean(axis=0), average=None)\n",
        "\n",
        "print(\"precision_score:\", precision_score)\n",
        "print(\"recall_score:\", recall_score)\n",
        "print(\"mcc_score:\", mcc_score)\n",
        "print(\"roc_auc_score:\", roc_auc_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_score: 0.5383174018953414\n",
            "recall_score: 0.6096338049093124\n",
            "mcc_score: 0.12962843151138675\n",
            "roc_auc_score: 0.6366664750885578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4z2zIzAie9p"
      },
      "source": [
        "### Save the predicted label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2yYSrHbiejk"
      },
      "source": [
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "np.savetxt('predict.csv', pred_label, fmt='%d' )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCMeGlv0xCxn"
      },
      "source": [
        "## Train 10 models with cross validation (validating scores: precision, recall, and ROC area)\n",
        "Will take about 30 min to train 300 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjcBiDkexMev",
        "outputId": "e8cf3a93-5049-4fa1-9081-edf8d6b35429"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "score_accuracy_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "def simple_matthews_corrcoef(true_np, predict_np):\n",
        "    cm = metrics.confusion_matrix(true_np, predict_np)\n",
        "    assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "\n",
        "    return MCC\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # # calcuate precision, recall, AUC. actually train the model 300 times.\n",
        "    score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    trained_model_list.append(clf)\n",
        "    scores_list.append(scores)\n",
        "\n",
        "    scores_precision_list.append(score_precision)\n",
        "    scores_recall_list.append(score_recall)\n",
        "    # scores_roc_auc_list.append(score_roc_auc)\n",
        "\n",
        "    # To calculate MCC only, actally train 100 models.\n",
        "    # score_accuracy = cross_validate(clf, balanced_train, balanced_train_label, cv=10, return_estimator=True)\n",
        "    # score_accuracy_list.append(score_accuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 2 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 3 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 4 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 5 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 6 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 7 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 8 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 9 model...\n",
            "[LibSVM][LibSVM][LibSVM]Training # 10 model...\n",
            "[LibSVM][LibSVM][LibSVM]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7DzfmynGXm1"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VPNIsc_BGlJk"
      },
      "source": [
        "## Train 10 models with cross validation (validating scores:  Matthew coefficient)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KnN9j0L_Gfyr",
        "outputId": "8e6d402c-502c-4c34-e3f0-14af94d835e4"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "score_accuracy_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "def simple_matthews_corrcoef(true_np, predict_np):\n",
        "    cm = metrics.confusion_matrix(true_np, predict_np)\n",
        "    assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "\n",
        "    return MCC\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # calcuate precision, recall, AUC. actually train the model 300 times.\n",
        "    # score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    # score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    # score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    # print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    # print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    # print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    # trained_model_list.append(clf)\n",
        "    # scores_list.append(scores)\n",
        "\n",
        "    # scores_precision_list.append(score_precision)\n",
        "    # scores_recall_list.append(score_recall)\n",
        "    # scores_roc_auc_list.append(score_roc_auc)\n",
        "\n",
        "    # To calculate MCC only, actally train 100 models.\n",
        "    score_accuracy = cross_validate(clf, balanced_train, balanced_train_label, cv=10, return_estimator=True)\n",
        "    score_accuracy_list.append(score_accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 2 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 3 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 4 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 5 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 6 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 7 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 8 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 9 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 10 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tpKVvB2mDsHS",
        "outputId": "6d557517-1a89-4892-fb21-41947e1d800d"
      },
      "source": [
        "# Evaluate models (100 models in total)\n",
        "def test_mcc_from_cross_validation(score_accuracy_list):\n",
        "    mcc_list = []\n",
        "    for idx, fold in enumerate(score_accuracy_list):\n",
        "        print(f\"Evaluating #{idx + 1} fold...\")\n",
        "        clfs = fold['estimator']\n",
        "        for idx2, clf in enumerate(clfs):\n",
        "            predict_labels = clf.predict(test_df)\n",
        "            mcc = metrics.matthews_corrcoef(test_label_df, predict_labels)\n",
        "            mcc_list.append(mcc)\n",
        "            print(f'Fold {idx + 1}, classifier # {idx2 + 1}, matthews_corrcoef: {mcc:0.4f}')\n",
        "    mcc_np = np.array(mcc_list)\n",
        "    return mcc_np.mean()\n",
        "\n",
        "mcc_mean = test_mcc_from_cross_validation(score_accuracy_list)\n",
        "print()\n",
        "print(\"MCC mean is: %0.4f\" % mcc_mean)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating #1 fold...\n",
            "Fold 1, classifier # 1, matthews_corrcoef: 0.1127\n",
            "Fold 1, classifier # 2, matthews_corrcoef: 0.1097\n",
            "Fold 1, classifier # 3, matthews_corrcoef: 0.1204\n",
            "Fold 1, classifier # 4, matthews_corrcoef: 0.1191\n",
            "Fold 1, classifier # 5, matthews_corrcoef: 0.1175\n",
            "Fold 1, classifier # 6, matthews_corrcoef: 0.1200\n",
            "Fold 1, classifier # 7, matthews_corrcoef: 0.1165\n",
            "Fold 1, classifier # 8, matthews_corrcoef: 0.1136\n",
            "Fold 1, classifier # 9, matthews_corrcoef: 0.1173\n",
            "Fold 1, classifier # 10, matthews_corrcoef: 0.1226\n",
            "Evaluating #2 fold...\n",
            "Fold 2, classifier # 1, matthews_corrcoef: 0.1211\n",
            "Fold 2, classifier # 2, matthews_corrcoef: 0.1213\n",
            "Fold 2, classifier # 3, matthews_corrcoef: 0.1277\n",
            "Fold 2, classifier # 4, matthews_corrcoef: 0.1242\n",
            "Fold 2, classifier # 5, matthews_corrcoef: 0.1269\n",
            "Fold 2, classifier # 6, matthews_corrcoef: 0.1174\n",
            "Fold 2, classifier # 7, matthews_corrcoef: 0.1184\n",
            "Fold 2, classifier # 8, matthews_corrcoef: 0.1253\n",
            "Fold 2, classifier # 9, matthews_corrcoef: 0.1290\n",
            "Fold 2, classifier # 10, matthews_corrcoef: 0.1299\n",
            "Evaluating #3 fold...\n",
            "Fold 3, classifier # 1, matthews_corrcoef: 0.1192\n",
            "Fold 3, classifier # 2, matthews_corrcoef: 0.1215\n",
            "Fold 3, classifier # 3, matthews_corrcoef: 0.1262\n",
            "Fold 3, classifier # 4, matthews_corrcoef: 0.1166\n",
            "Fold 3, classifier # 5, matthews_corrcoef: 0.1159\n",
            "Fold 3, classifier # 6, matthews_corrcoef: 0.1230\n",
            "Fold 3, classifier # 7, matthews_corrcoef: 0.1232\n",
            "Fold 3, classifier # 8, matthews_corrcoef: 0.1243\n",
            "Fold 3, classifier # 9, matthews_corrcoef: 0.1207\n",
            "Fold 3, classifier # 10, matthews_corrcoef: 0.1234\n",
            "Evaluating #4 fold...\n",
            "Fold 4, classifier # 1, matthews_corrcoef: 0.1174\n",
            "Fold 4, classifier # 2, matthews_corrcoef: 0.1182\n",
            "Fold 4, classifier # 3, matthews_corrcoef: 0.1130\n",
            "Fold 4, classifier # 4, matthews_corrcoef: 0.1154\n",
            "Fold 4, classifier # 5, matthews_corrcoef: 0.1169\n",
            "Fold 4, classifier # 6, matthews_corrcoef: 0.1210\n",
            "Fold 4, classifier # 7, matthews_corrcoef: 0.1256\n",
            "Fold 4, classifier # 8, matthews_corrcoef: 0.1164\n",
            "Fold 4, classifier # 9, matthews_corrcoef: 0.1182\n",
            "Fold 4, classifier # 10, matthews_corrcoef: 0.1210\n",
            "Evaluating #5 fold...\n",
            "Fold 5, classifier # 1, matthews_corrcoef: 0.1080\n",
            "Fold 5, classifier # 2, matthews_corrcoef: 0.1110\n",
            "Fold 5, classifier # 3, matthews_corrcoef: 0.1048\n",
            "Fold 5, classifier # 4, matthews_corrcoef: 0.1101\n",
            "Fold 5, classifier # 5, matthews_corrcoef: 0.1167\n",
            "Fold 5, classifier # 6, matthews_corrcoef: 0.0942\n",
            "Fold 5, classifier # 7, matthews_corrcoef: 0.1022\n",
            "Fold 5, classifier # 8, matthews_corrcoef: 0.1101\n",
            "Fold 5, classifier # 9, matthews_corrcoef: 0.1052\n",
            "Fold 5, classifier # 10, matthews_corrcoef: 0.1067\n",
            "Evaluating #6 fold...\n",
            "Fold 6, classifier # 1, matthews_corrcoef: 0.1216\n",
            "Fold 6, classifier # 2, matthews_corrcoef: 0.1229\n",
            "Fold 6, classifier # 3, matthews_corrcoef: 0.1287\n",
            "Fold 6, classifier # 4, matthews_corrcoef: 0.1139\n",
            "Fold 6, classifier # 5, matthews_corrcoef: 0.1173\n",
            "Fold 6, classifier # 6, matthews_corrcoef: 0.1239\n",
            "Fold 6, classifier # 7, matthews_corrcoef: 0.1198\n",
            "Fold 6, classifier # 8, matthews_corrcoef: 0.1238\n",
            "Fold 6, classifier # 9, matthews_corrcoef: 0.1259\n",
            "Fold 6, classifier # 10, matthews_corrcoef: 0.1221\n",
            "Evaluating #7 fold...\n",
            "Fold 7, classifier # 1, matthews_corrcoef: 0.1165\n",
            "Fold 7, classifier # 2, matthews_corrcoef: 0.1242\n",
            "Fold 7, classifier # 3, matthews_corrcoef: 0.1143\n",
            "Fold 7, classifier # 4, matthews_corrcoef: 0.1159\n",
            "Fold 7, classifier # 5, matthews_corrcoef: 0.1234\n",
            "Fold 7, classifier # 6, matthews_corrcoef: 0.1124\n",
            "Fold 7, classifier # 7, matthews_corrcoef: 0.1170\n",
            "Fold 7, classifier # 8, matthews_corrcoef: 0.1118\n",
            "Fold 7, classifier # 9, matthews_corrcoef: 0.1254\n",
            "Fold 7, classifier # 10, matthews_corrcoef: 0.1205\n",
            "Evaluating #8 fold...\n",
            "Fold 8, classifier # 1, matthews_corrcoef: 0.1289\n",
            "Fold 8, classifier # 2, matthews_corrcoef: 0.1270\n",
            "Fold 8, classifier # 3, matthews_corrcoef: 0.1163\n",
            "Fold 8, classifier # 4, matthews_corrcoef: 0.1280\n",
            "Fold 8, classifier # 5, matthews_corrcoef: 0.1267\n",
            "Fold 8, classifier # 6, matthews_corrcoef: 0.1303\n",
            "Fold 8, classifier # 7, matthews_corrcoef: 0.1253\n",
            "Fold 8, classifier # 8, matthews_corrcoef: 0.1297\n",
            "Fold 8, classifier # 9, matthews_corrcoef: 0.1261\n",
            "Fold 8, classifier # 10, matthews_corrcoef: 0.1243\n",
            "Evaluating #9 fold...\n",
            "Fold 9, classifier # 1, matthews_corrcoef: 0.1271\n",
            "Fold 9, classifier # 2, matthews_corrcoef: 0.1258\n",
            "Fold 9, classifier # 3, matthews_corrcoef: 0.1241\n",
            "Fold 9, classifier # 4, matthews_corrcoef: 0.1217\n",
            "Fold 9, classifier # 5, matthews_corrcoef: 0.1237\n",
            "Fold 9, classifier # 6, matthews_corrcoef: 0.1202\n",
            "Fold 9, classifier # 7, matthews_corrcoef: 0.1253\n",
            "Fold 9, classifier # 8, matthews_corrcoef: 0.1216\n",
            "Fold 9, classifier # 9, matthews_corrcoef: 0.1278\n",
            "Fold 9, classifier # 10, matthews_corrcoef: 0.1276\n",
            "Evaluating #10 fold...\n",
            "Fold 10, classifier # 1, matthews_corrcoef: 0.1147\n",
            "Fold 10, classifier # 2, matthews_corrcoef: 0.1107\n",
            "Fold 10, classifier # 3, matthews_corrcoef: 0.1180\n",
            "Fold 10, classifier # 4, matthews_corrcoef: 0.1208\n",
            "Fold 10, classifier # 5, matthews_corrcoef: 0.1233\n",
            "Fold 10, classifier # 6, matthews_corrcoef: 0.1184\n",
            "Fold 10, classifier # 7, matthews_corrcoef: 0.1293\n",
            "Fold 10, classifier # 8, matthews_corrcoef: 0.1211\n",
            "Fold 10, classifier # 9, matthews_corrcoef: 0.1137\n",
            "Fold 10, classifier # 10, matthews_corrcoef: 0.1160\n",
            "\n",
            "MCC mean is: 0.1197\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1bFE4MffDrmP"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dzAoSjPJCdwi",
        "outputId": "c170318d-3413-4280-a449-ba0b51039bda"
      },
      "source": [
        "score_accuracy_list[8]['test_score'].mean()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.614932305263797"
            ]
          },
          "metadata": {},
          "execution_count": 165
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xJtSZ5SNCxeB"
      },
      "source": [
        "predict_labels = score_accuracy_list[0]['estimator'][0].predict(test_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8zWXt8xfDXnT",
        "outputId": "8e7fd9a4-62d7-4ad1-9baa-9edad80386be"
      },
      "source": [
        "mcc = metrics.matthews_corrcoef(test_label_df, predict_labels)\n",
        "mcc"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.11273251475330465"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V7nz13H-xHP"
      },
      "source": [
        "clf.predict()\n",
        "\n",
        "# calculate MCC\n",
        "mcc_score = simple_matthews_corrcoef())\n",
        "scores_mcc_list.append(mcc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVczoNnFnnqB"
      },
      "source": [
        "# Program to calculate model performance from two label files: Precision, Recall, MCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgq9pUAMn065"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tOujpNPnzES"
      },
      "source": [
        "label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "label_df = pd.read_csv(label_csv)\n",
        "predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "\n",
        "true_np = np.array(label_df)\n",
        "predict_np = np.array(predict_df)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UpvkGmX-Zck"
      },
      "source": [
        "## Define metrics class"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrINqCKqo2_7",
        "outputId": "0999ba8f-70fb-4224-fd06-515c1dc97711"
      },
      "source": [
        "class simple_metrics():\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_data(true_csv, predict_csv):\n",
        "        true_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "        predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "        true_df = pd.read_csv(true_csv)\n",
        "        predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "        true_np = np.array(true_df)\n",
        "        predict_np = np.array(predict_df)\n",
        "\n",
        "        return true_np, predict_np\n",
        "\n",
        "    @staticmethod\n",
        "    def get_confusion_matrix(true_np, predict_np): # inputs: should be integer numpy array (1D), using the same class index schema.\n",
        "        true_unique = np.unique(true_np)\n",
        "        predict_unique = np.unique(predict_np)\n",
        "\n",
        "        cm = np.zeros((len(true_unique), len(true_unique)), dtype=int)   # cm: confusion_matrix, row is actual, column is predicted\n",
        "\n",
        "        for true_, pred in zip(true_np[:].flatten(), predict_np[:].flatten()):\n",
        "            cm[true_, pred] += 1\n",
        "            # print(true_, pred)\n",
        "        return cm\n",
        "\n",
        "    @staticmethod\n",
        "    def precision_recall_score(true_csv, predict_csv):  # CSV file has one column only withoud header.\n",
        "        true_np, predict_np = simple_metrics._load_data(true_csv, predict_csv)\n",
        "        confusion_matrix = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        class_cnt = confusion_matrix.shape[0]\n",
        "        precisions = np.zeros((class_cnt))\n",
        "        recalls = np.zeros((class_cnt))\n",
        "\n",
        " \n",
        "\n",
        "        # compute recall, precision\n",
        "        for c in range(class_cnt):\n",
        "            TP = confusion_matrix[c, c]\n",
        "            TP_FP = confusion_matrix[c, :].sum()\n",
        "            TP_FN = confusion_matrix[:, c].sum()\n",
        "            recalls[c] = TP / TP_FP\n",
        "            precisions[c] = TP / TP_FN\n",
        "\n",
        "        return precisions, recalls\n",
        "\n",
        "    @staticmethod\n",
        "    def matthews_corrcoef(true_csv, predict_csv): # CSV file has one column only withoud header.\n",
        "        MCC = 0\n",
        "        # compute MCC, current for binary classification only\n",
        "        \n",
        "        cm = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "        TP = cm[1, 1]\n",
        "        TN = cm[0, 0]\n",
        "        FP = cm[0, 1]\n",
        "        FN = cm[1, 0]\n",
        "\n",
        "        MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "        # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient\n",
        "        return MCC\n",
        "\n",
        "class_precision, class_recall = simple_metrics.precision_recall_score(label_csv, predict_csv)\n",
        "MCC =  simple_metrics.matthews_corrcoef(label_csv, predict_csv)\n",
        "\n",
        "print(\"My results:\")\n",
        "print('class_precision:', class_precision.round(4))\n",
        "print('class_recallï¼š', class_recall.round(4))\n",
        "print('Matthews_corrcoef: %.4f' % MCC)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"sklearn results:\")\n",
        "rpt = metrics.classification_report(true_np, predict_np, digits=4)\n",
        "print(rpt)\n",
        "print()\n",
        "print(\"sklearn matthews_corrcoef: %.4f\" % metrics.matthews_corrcoef(true_np, predict_np))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My results:\n",
            "class_precision: [0.9392 0.1409]\n",
            "class_recallï¼š [0.6082 0.6198]\n",
            "Matthews_corrcoef: 0.1351\n",
            "\n",
            "sklearn results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9392    0.6082    0.7383      9060\n",
            "           1     0.1409    0.6198    0.2295       939\n",
            "\n",
            "    accuracy                         0.6093      9999\n",
            "   macro avg     0.5400    0.6140    0.4839      9999\n",
            "weighted avg     0.8642    0.6093    0.6905      9999\n",
            "\n",
            "\n",
            "sklearn matthews_corrcoef: 0.1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRkS-ej04VAP"
      },
      "source": [
        "# DNN for thermal regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa0pMq25AV8"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfJreLSO5IIz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h12DftNw4cNQ"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2PU5z2iwGkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03aef3af-d705-4df7-f785-5f54f548b656"
      },
      "source": [
        "data_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/themal_dataset.csv'\n",
        "\n",
        "data_df = pd.read_csv(data_csv)\n",
        "data_df = data_df[data_df['y-exp'] < 500]   # remove two outliers\n",
        "features_df = data_df.iloc[:, 1:21]\n",
        "y_label = data_df.iloc[:, 21]\n",
        "y_theory = data_df.iloc[:, 22]\n",
        "y_label = np.array(y_label)\n",
        "print(\"features_df.shape: \", features_df.shape)\n",
        "print(\"y_label.shape: \", y_label.shape)\n"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "features_df.shape:  (368, 20)\n",
            "y_label.shape:  (368,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb4N5NY38_kM"
      },
      "source": [
        "## Standardize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RVhn-tp5ivh",
        "outputId": "bc5f28f9-f1be-43b2-9156-648d1d310864"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "input_features = preprocessing.StandardScaler().fit_transform(features_df)\n",
        "\n",
        "print(\"Feature shape:\", input_features.shape)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (368, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "18ZhhehdOiqk"
      },
      "source": [
        "## Customize a Pytorch dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYDwPgF9ikfY"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features_np, labels_np):\n",
        "        features_np = preprocessing.StandardScaler().fit_transform(features_np)\n",
        "        self.features = torch.from_numpy(features_np)\n",
        "        self.labels = torch.from_numpy(labels_np)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.features[index, :]        \n",
        "        label = self.labels[index]\n",
        "        \n",
        "        return features, label\n",
        "\n",
        "# list(train_dataloader)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA4bsEz9RTq_"
      },
      "source": [
        "## Define a neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00274HwaRS0i",
        "outputId": "e3172c21-5394-46ad-98e1-cd46bf7cee92"
      },
      "source": [
        "\n",
        "INPUT_SIZE = input_features.shape[1] # 20\n",
        "OUTPUT_SIZE = 1\n",
        "HIDDEN_SIZE = 256\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(INPUT_SIZE, HIDDEN_SIZE)\n",
        "        self.fc2 = nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE)\n",
        "        self.fc3 = nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE)\n",
        "\n",
        "    def forward(self, x):     \n",
        "        x = self.fc1(x)        \n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "net = Net().to('cuda')\n",
        "print(net)\n",
        " \n",
        "\n",
        "my_nn = torch.nn.Sequential(    \n",
        "    torch.nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),    \n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        ").to('cuda')  #  better, do not understand\n",
        "\n",
        "print(my_nn)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (fc2): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n",
            "Sequential(\n",
            "  (0): Linear(in_features=20, out_features=256, bias=True)\n",
            "  (1): Linear(in_features=256, out_features=256, bias=True)\n",
            "  (2): ReLU()\n",
            "  (3): Linear(in_features=256, out_features=1, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_ZnKVuotcDs",
        "outputId": "5596b772-5665-4fdc-efd6-466000d8d7ff"
      },
      "source": [
        "input_features.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(368, 20)"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHasAnOpQdMR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 827
        },
        "outputId": "d4c4ae11-7c7b-4451-e49c-229ed078c694"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "from IPython.display import clear_output\n",
        "import sklearn.metrics as metrics\n",
        "\n",
        "\n",
        "fold_k = 10\n",
        "BATCH_SIZE = 8\n",
        "epoch_cnt = 20000\n",
        "\n",
        "input_features = preprocessing.StandardScaler().fit_transform(features_df)\n",
        "\n",
        "\n",
        "feature_dataset = FeatureDataset(features_np=input_features, labels_np=y_label)\n",
        "train_dataloader = DataLoader(feature_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "k_fold_spliter = KFold(n_splits=fold_k, random_state=None, shuffle=True)\n",
        "\n",
        "\n",
        "cost = torch.nn.MSELoss(reduction='mean')\n",
        "\n",
        "fig, ax = plt.subplots(figsize=(5, 5))\n",
        "\n",
        "def draw_loss(losses):\n",
        "    clear_output()\n",
        "    print(step, np.mean(batch_loss[-1]))\n",
        "    plt.plot(losses)\n",
        "    plt.show()\n",
        "    \n",
        "\n",
        "def train_a_model(net, train_dataloader, epoch_cnt = 10, fold=0):\n",
        "    step = 0 \n",
        "    losses = []\n",
        "\n",
        "    \n",
        "\n",
        "    optimizer = torch.optim.Adam(net.parameters(), lr = 0.001)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer,milestones=[5000, 10000, 15000],gamma = 0.2)\n",
        "\n",
        "    # print(f\"Processing {fold} fold.\")\n",
        "    \n",
        "    for epoch in range(epoch_cnt):\n",
        "\n",
        "        batch_losses = []\n",
        "        for x, y in train_dataloader:  # each batch\n",
        "\n",
        "\n",
        "\n",
        "            x = torch.tensor(x, requires_grad = True).float().to('cuda')\n",
        "            y = torch.tensor(y, requires_grad = True).float().to('cuda')\n",
        "\n",
        "             \n",
        "            # print(y)\n",
        "            prediction = net(x)\n",
        "            # print(prediction)\n",
        "\n",
        "           \n",
        "            loss = cost(prediction, y)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            \n",
        "            loss.backward(retain_graph=True)\n",
        "            # loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "\n",
        "            batch_losses.append(loss.cpu().data.numpy())\n",
        "\n",
        "            step += 1\n",
        "\n",
        "        scheduler.step()\n",
        "        \n",
        "        if epoch % 50 == 0:\n",
        "            losses.append(np.mean(batch_losses))\n",
        "            \n",
        "            clear_output(wait=True)\n",
        "            fig = plt.figure(figsize=(20, 8))\n",
        "            plt.plot(losses)\n",
        "            plt.show()\n",
        "            loss_t = np.mean(batch_losses)\n",
        "            print(f'Fold: {fold}, epoch: {epoch}, current loss: {loss_t:.4f}'  )\n",
        "        \n",
        "\n",
        "    return net\n",
        "\n",
        "    \n",
        "\n",
        "def eval_model(trained_net, X_test, y_true):\n",
        "    trained_net.eval().to('cuda')\n",
        "    y_predict = trained_net(torch.tensor(X_test).float().to('cuda')).cpu().data.numpy()\n",
        "\n",
        "    mse = metrics.mean_squared_error(y_true, y_predict)\n",
        "    rmse = np.sqrt(metrics.mean_squared_error(y_true, y_predict))\n",
        "    mae = metrics.mean_absolute_error(y_true, y_predict)\n",
        "    r_squared = metrics.r2_score(y_true, y_predict)\n",
        "\n",
        "    return y_predict, mse, rmse, mae, r_squared      \n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(columns=['fold', 'mse', 'rmse', 'mae', 'r_squared'])\n",
        "for  idx, (train_index, test_index) in enumerate(k_fold_spliter.split(input_features)):\n",
        "\n",
        "    my_nn = torch.nn.Sequential(    \n",
        "    torch.nn.Linear(INPUT_SIZE, HIDDEN_SIZE),\n",
        "    torch.nn.Linear(HIDDEN_SIZE, HIDDEN_SIZE),    \n",
        "    torch.nn.ReLU(),    \n",
        "    torch.nn.Linear(HIDDEN_SIZE, OUTPUT_SIZE),\n",
        "    ).to('cuda') \n",
        "     \n",
        "\n",
        "    df_row_cnt = len(results_df)\n",
        "    print(f\"Processing {idx} fold.\")\n",
        "    X_train, X_test = input_features[train_index], input_features[test_index]\n",
        "    y_train, y_test = y_label[train_index], y_label[test_index]\n",
        "\n",
        "    print(len(X_train))\n",
        "    feature_dataset = FeatureDataset(features_np=X_train, labels_np=y_train)\n",
        "\n",
        "    train_dataloader = DataLoader(feature_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "    trained_net = train_a_model(my_nn, train_dataloader, epoch_cnt = epoch_cnt, fold=idx)\n",
        "\n",
        "    torch.save(trained_net, f'trained_model_{idx}.pth')\n",
        "\n",
        "    y_predict, mse, rmse, mae, r_squared = eval_model(trained_net, X_test, y_test)\n",
        "    # results_df.iloc[df_row_cnt, '']\n",
        "    results_df.loc[df_row_cnt] = [idx, mse, rmse, mae, r_squared]\n",
        "    \n",
        "\n",
        "    print(f\"Fold # {idx} Evaluation results:\")\n",
        "    print(f'mse: {mse:.4f}, rmse: {rmse:.4f}, mae: {rmse:.4f}, r_squared: {rmse:.4f}.' )\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "results_df['fold'] = results_df['fold'].astype(int)\n",
        "results_df.to_csv('10_fold_results.csv')\n",
        "print(\"10 fold results:\")\n",
        "\n",
        "results_df\n",
        "\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1440x576 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold: 9, epoch: 19950, current loss: 880.6274\n",
            "Fold # 9 Evaluation results:\n",
            "mse: 3611.2044, rmse: 60.0933, mae: 60.0933, r_squared: 60.0933.\n",
            "10 fold results:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fold</th>\n",
              "      <th>mse</th>\n",
              "      <th>rmse</th>\n",
              "      <th>mae</th>\n",
              "      <th>r_squared</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>4059.507176</td>\n",
              "      <td>63.714262</td>\n",
              "      <td>34.300744</td>\n",
              "      <td>0.432008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>110103.658444</td>\n",
              "      <td>331.818713</td>\n",
              "      <td>80.515705</td>\n",
              "      <td>-221.910233</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>4987.252919</td>\n",
              "      <td>70.620485</td>\n",
              "      <td>36.818258</td>\n",
              "      <td>0.178448</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1390.586853</td>\n",
              "      <td>37.290573</td>\n",
              "      <td>27.538641</td>\n",
              "      <td>-0.815726</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>24114.859463</td>\n",
              "      <td>155.289599</td>\n",
              "      <td>49.977647</td>\n",
              "      <td>-21.217698</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>6835.217328</td>\n",
              "      <td>82.675373</td>\n",
              "      <td>44.959411</td>\n",
              "      <td>-4.455545</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>2484.824721</td>\n",
              "      <td>49.848016</td>\n",
              "      <td>35.672845</td>\n",
              "      <td>0.177432</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>5013.012964</td>\n",
              "      <td>70.802634</td>\n",
              "      <td>39.123425</td>\n",
              "      <td>0.087296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>17115.607578</td>\n",
              "      <td>130.826632</td>\n",
              "      <td>53.416233</td>\n",
              "      <td>-1.658382</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>3611.204368</td>\n",
              "      <td>60.093297</td>\n",
              "      <td>32.242146</td>\n",
              "      <td>-9.240084</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   fold            mse        rmse        mae   r_squared\n",
              "0     0    4059.507176   63.714262  34.300744    0.432008\n",
              "1     1  110103.658444  331.818713  80.515705 -221.910233\n",
              "2     2    4987.252919   70.620485  36.818258    0.178448\n",
              "3     3    1390.586853   37.290573  27.538641   -0.815726\n",
              "4     4   24114.859463  155.289599  49.977647  -21.217698\n",
              "5     5    6835.217328   82.675373  44.959411   -4.455545\n",
              "6     6    2484.824721   49.848016  35.672845    0.177432\n",
              "7     7    5013.012964   70.802634  39.123425    0.087296\n",
              "8     8   17115.607578  130.826632  53.416233   -1.658382\n",
              "9     9    3611.204368   60.093297  32.242146   -9.240084"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KT3CqVd5CQfY",
        "outputId": "494c5738-3a53-4844-ec20-82b0495d91f8"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        },
        "id": "3kQSa6kR8yQq",
        "outputId": "1a56492e-d040-4622-8801-0c803757f506"
      },
      "source": [
        "best_model_fold_id = np.argmin(results_df['mae'])\n",
        "\n",
        "best_model = torch.load(f'trained_model_{best_model_fold_id}.pth')\n",
        "\n",
        "y_predict, mse, rmse, mae, r_squared = eval_model(best_model, input_features, y_theory)\n",
        "\n",
        "\n",
        "def draw_r2_squared(ax2, x_true, y_observed):\n",
        "    x_true = np.array(x_true).reshape((-1, 1))\n",
        "    y_observed = np.array(y_observed).reshape((-1, 1))\n",
        "    reg = LR().fit(x_true, y_observed)\n",
        "    z = np.polyfit(x_true.ravel(), y_observed.ravel(), 1)\n",
        "    p = np.poly1d(z)\n",
        "    y_pred = p(x_true)\n",
        "    R_squared = r2_score(y_observed, y_pred)\n",
        "    # print()\n",
        "    print(\"R squared:\", R_squared)\n",
        "    print(\"reg.coef_:\", reg.coef_)\n",
        "    text = f\"$y={z[0]:0.3f}\\:x{z[1]:+0.3f}$\\n$R^2 = {R_squared:0.3f}$\"\n",
        "    ax2.scatter(x=x_true, y=y_observed, s=2)\n",
        "    ax2.text(0.05, 0.95, text, \n",
        "               transform=plt.gca().transAxes,\n",
        "               fontsize=20,\n",
        "               verticalalignment='top')\n",
        "    \n",
        "    # draw trend line\n",
        "    line_ends = [min(x_true), max(x_true)]\n",
        "    end_preds = p(line_ends)\n",
        "    ax2.plot(line_ends, end_preds, 'r--')\n",
        "    \n",
        "\n",
        "# plt.scatter(y_theory, y_predict)\n",
        "fig = plt.subplots(figsize=(10, 10))\n",
        "plt.axis('equal')\n",
        "plt.ylim([0, 300])\n",
        "plt.xlim([0, 350])\n",
        "plt.xlabel(\"y_theory\")\n",
        "plt.ylabel(\"y_predict\")\n",
        "font = {'size': 20}\n",
        "plt.rc('font', **font)\n",
        "draw_r2_squared(plt.gca(), y_theory, y_predict)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "R squared: 0.4433150208908996\n",
            "reg.coef_: [[0.84429216]]\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8U7DQ-cx9M0P"
      },
      "source": [
        "# Problem 1 validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oMy7y98N9C7C",
        "outputId": "62b6d717-c81d-47e3-9bb2-05869e6ca9b7"
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        " \n",
        "\n",
        "classes = ['politics', 'business', 'tech', 'entertainment', 'sport']\n",
        "\n",
        "y_true = [0] * 141 + [1] * 167 + [2] * 133 + [3] * 128 + [4] * 166\n",
        "\n",
        "\n",
        "# row: actual, col: predict\n",
        "confusion_matrix = np.array([[140, 1, 0, 0, 0],\n",
        "                             [4, 160, 2, 0, 1],\n",
        "                             [1, 3, 128, 0, 1],\n",
        "                             [0, 0, 1, 127, 0],\n",
        "                             [0, 1, 0, 0, 165],])\n",
        "\n",
        "row_cnt, col_cnt = confusion_matrix.shape\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for row in range(row_cnt):\n",
        "    y_true += [row] *  confusion_matrix[row, :].sum()\n",
        "    for col in range(col_cnt):\n",
        "        y_pred += [col] *  confusion_matrix[row, col] \n",
        "\n",
        "print(\"Confusion matix:\")\n",
        "print(metrics.confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(metrics.classification_report(y_true, y_pred, digits=4))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matix:\n",
            "[[140   1   0   0   0]\n",
            " [  4 160   2   0   1]\n",
            " [  1   3 128   0   1]\n",
            " [  0   0   1 127   0]\n",
            " [  0   1   0   0 165]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9655    0.9929    0.9790       141\n",
            "           1     0.9697    0.9581    0.9639       167\n",
            "           2     0.9771    0.9624    0.9697       133\n",
            "           3     1.0000    0.9922    0.9961       128\n",
            "           4     0.9880    0.9940    0.9910       166\n",
            "\n",
            "    accuracy                         0.9796       735\n",
            "   macro avg     0.9801    0.9799    0.9799       735\n",
            "weighted avg     0.9797    0.9796    0.9796       735\n",
            "\n"
          ]
        }
      ]
    }
  ]
}