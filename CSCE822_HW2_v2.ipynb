{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "CSCE822_HW2_v2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "mount_file_id": "1ognRW5heGOl0ympzxjc8Ikb1Pa2kZGl2",
      "authorship_tag": "ABX9TyMeBTJe00EM/dUryuTix/nl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gladcolor/SVM_DNN_testing/blob/master/CSCE822_HW2_v2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OIBmefr5003e"
      },
      "source": [
        "# Import packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xWb6nL5k31q"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.impute import SimpleImputer\n",
        "# import category_encoders as ce\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "import sklearn.metrics as metrics\n",
        "from sklearn.model_selection import cross_validate"
      ],
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJZDU1PIxnTs"
      },
      "source": [
        "# Define functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oICR2HJwxq37"
      },
      "source": [
        "def print_str_unique(df):\n",
        "    for col in df.columns:\n",
        "        if original_data.dtypes[col] == np.object:            \n",
        "            unique_cnt = len(df[col].unique())\n",
        "            print(f'Column {col.rjust(13)} has {unique_cnt:5} unique values.')\n",
        "\n",
        "def count_column_nan(df):\n",
        "    row_cnt = len(df)\n",
        "    for col in df.columns:\n",
        "        nan_cnt = df[col].isna().sum()\n",
        "        percent_str = f'({(nan_cnt / row_cnt * 100):3.1f}%)'.rjust(7)\n",
        "        print(f'Column {str(col).rjust(13)} has {nan_cnt:4} {percent_str} nan values.')       \n",
        "\n",
        "def impute_df(df, strategy=\"most_frequent\"):\n",
        "    \n",
        "    numeric_cols = ['BuildingArea', 'YearBuilt', 'Car']\n",
        "    nominal_cols = ['CouncilArea']\n",
        "\n",
        "    my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "    council_area_with_imputed_values = my_imputer.fit_transform(df[nominal_cols])\n",
        "    imputed_df = df.copy()\n",
        "    imputed_df.loc[:, nominal_cols] = council_area_with_imputed_values\n",
        "\n",
        "\n",
        "    if strategy == \"most_frequent\":\n",
        "        my_imputer = SimpleImputer(strategy=\"most_frequent\")\n",
        "        data_with_imputed_values = my_imputer.fit_transform(df)        \n",
        "        imputed_df.loc[:, :] = data_with_imputed_values\n",
        "\n",
        "    if strategy == \"mean\":\n",
        "        my_imputer = SimpleImputer(strategy=\"mean\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    if strategy == \"median\":\n",
        "        my_imputer = SimpleImputer(strategy=\"median\")\n",
        "        area_year_with_imputed_values = my_imputer.fit_transform(df[numeric_cols])\n",
        "        imputed_df.loc[:, numeric_cols] = area_year_with_imputed_values\n",
        "\n",
        "    return imputed_df\n",
        "\n",
        "def encode_dates(imputed_df):\n",
        "    imputed_df['Date'] = pd.to_datetime(imputed_df['Date']) \n",
        "    imputed_df['Ori_Date'] = pd.to_datetime('1970-01-01', format='YY-m-d', errors='ignore')\n",
        "    imputed_df['Ori_Date'] = pd.to_datetime(imputed_df['Ori_Date'])\n",
        "    imputed_df['delta_days'] = imputed_df['Date'] - imputed_df['Ori_Date']\n",
        "    imputed_df['delta_days'] = imputed_df['delta_days'].dt.days\n",
        "    imputed_df = imputed_df.drop(columns=['Date', 'Ori_Date'])\n",
        "     \n",
        "    return imputed_df\n",
        "\n",
        "\n",
        "\n",
        "def encoder_nominals(imputed_df, encode_method='one_hot'):\n",
        "    # print(f'Encode methods: {ENCODING_METHODS_DICT.keys()} \\n')\n",
        "    \n",
        "    ce_encoder = ENCODING_METHODS_DICT[encode_method](cols = ENCODING_COLUMNS)\n",
        "\n",
        "    y = imputed_df['Price_class'].copy()\n",
        "    \n",
        "    for drop_column in DROPPED_COLUMNS:\n",
        "        try:\n",
        "            imputed_df = imputed_df.drop(columns=drop_column).copy()\n",
        "        except:\n",
        "            pass\n",
        "            # print(f'Columns: {drop_column} have already dropped before.')\n",
        "\n",
        "    encoded_df = ce_encoder.fit_transform(imputed_df, y=y) \n",
        "\n",
        "    return encoded_df\n",
        "\n",
        "def assign_price_class(imputed_df):\n",
        "    row_cnt = len(imputed_df)\n",
        "    price_class_cnt = 5\n",
        "    class_step = int(row_cnt / price_class_cnt)\n",
        "    price_bins = list(range(class_step, row_cnt,  class_step))\n",
        "\n",
        "    imputed_df.loc[0:price_bins[0], 'Price_class'] = '0' # 'bottom_value'\n",
        "    imputed_df.loc[price_bins[0]:price_bins[1], 'Price_class'] = '1' # 'low_value'\n",
        "    imputed_df.loc[price_bins[1]:price_bins[2], 'Price_class'] = '2' # 'medium_value'\n",
        "    imputed_df.loc[price_bins[2]:price_bins[3], 'Price_class'] = '3' # 'high_value'\n",
        "    imputed_df.loc[price_bins[3]:row_cnt, 'Price_class'] = '4'  #  'top_value'\n",
        "\n",
        "    imputed_df['Price_class'] = imputed_df['Price_class'].astype(int)\n",
        "\n",
        "    # gb = imputed_df.groupby('Price_class')['Price_class'].count().to_frame()\n",
        "    # gb.columns = ['Count']\n",
        "    # custom_dict = {'bottom_value': 0, 'low_value': 1, 'medium_value': 2, 'high_value': 3, 'top_value': 4}\n",
        "    # gb.sort_index(key=lambda x: x.map(custom_dict))\n",
        "    # print(\"Price class counts:\")\n",
        "    return imputed_df    \n",
        "\n",
        "\n",
        "def split_data(encoded_df):\n",
        "    X = encoded_df.drop(columns=['Price_class'])\n",
        "    y = encoded_df['Price_class']\n",
        "\n",
        "    train_ratio = 0.75\n",
        "    validation_ratio = 0.10\n",
        "    test_ratio = 0.15\n",
        "\n",
        "    xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size= (1 - train_ratio), random_state = 0)\n",
        "\n",
        "    xVal, xTest, yVal, yTest = train_test_split(xTest, yTest, test_size=test_ratio/(test_ratio + validation_ratio), random_state = 0) \n",
        "\n",
        "    \n",
        "    return xTrain, yTrain, xVal, yVal, xTest, yTest   \n",
        "\n",
        "def standardize_data(encoded_df, class_col='Price_class'):\n",
        "    labels = encoded_df[class_col].copy()\n",
        "    data_df = encoded_df.drop(columns=[class_col])\n",
        "    scaler = preprocessing.StandardScaler()\n",
        "    scaler.fit(data_df) \n",
        "    data_df.iloc[:, :] = scaler.transform(data_df)\n",
        "    data_df.loc[:, class_col] = labels\n",
        "    return data_df\n",
        "           \n",
        "def sample_train_dataset(positive_count=len(train_1), negative_count=len(train_1)):\n",
        "    positive_count = len(train_1)\n",
        "    negative_count = len(train_1)\n",
        "\n",
        "    balanced_train = np.concatenate((train_1.sample(positive_count, replace=True), train_0.sample(negative_count, replace=True)), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    print(f\"Positive sample counts in the training set: {positive_count}\")\n",
        "    print(f\"Negative sample counts in the training set: {negative_count}\")\n",
        "\n",
        "    return balanced_train, balanced_train_label"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lIMZpvts08nT"
      },
      "source": [
        "# Load and understand the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-H0cAJP1j4k"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 237
        },
        "id": "-o6yMjxeL4am",
        "outputId": "8053728d-65d0-4b66-e2f4-099880419941"
      },
      "source": [
        "test_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000.zip'\n",
        "test_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "train_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000.zip'\n",
        "train_label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/train10000_Label.zip'\n",
        "\n",
        "train_df = pd.read_csv(train_csv, header=None)\n",
        "train_label_df = pd.read_csv(train_label_csv, header=None)\n",
        "test_df = pd.read_csv(test_csv, header=None)\n",
        "test_label_df = pd.read_csv(test_label_csv, header=None)\n",
        "\n",
        "print(\"Training sets samples:\")\n",
        "train_df.sample(4)\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training sets samples:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "      <th>300</th>\n",
              "      <th>301</th>\n",
              "      <th>302</th>\n",
              "      <th>303</th>\n",
              "      <th>304</th>\n",
              "      <th>305</th>\n",
              "      <th>306</th>\n",
              "      <th>307</th>\n",
              "      <th>308</th>\n",
              "      <th>309</th>\n",
              "      <th>310</th>\n",
              "      <th>311</th>\n",
              "      <th>312</th>\n",
              "      <th>313</th>\n",
              "      <th>314</th>\n",
              "      <th>315</th>\n",
              "      <th>316</th>\n",
              "      <th>317</th>\n",
              "      <th>318</th>\n",
              "      <th>319</th>\n",
              "      <th>320</th>\n",
              "      <th>321</th>\n",
              "      <th>322</th>\n",
              "      <th>323</th>\n",
              "      <th>324</th>\n",
              "      <th>325</th>\n",
              "      <th>326</th>\n",
              "      <th>327</th>\n",
              "      <th>328</th>\n",
              "      <th>329</th>\n",
              "      <th>330</th>\n",
              "      <th>331</th>\n",
              "      <th>332</th>\n",
              "      <th>333</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1144</th>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>6.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>30</td>\n",
              "      <td>3</td>\n",
              "      <td>10.0</td>\n",
              "      <td>45</td>\n",
              "      <td>0.0</td>\n",
              "      <td>70</td>\n",
              "      <td>449</td>\n",
              "      <td>482</td>\n",
              "      <td>356</td>\n",
              "      <td>6</td>\n",
              "      <td>650</td>\n",
              "      <td>310</td>\n",
              "      <td>580</td>\n",
              "      <td>260</td>\n",
              "      <td>1513</td>\n",
              "      <td>4</td>\n",
              "      <td>55</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>28</td>\n",
              "      <td>27</td>\n",
              "      <td>1379</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>12</td>\n",
              "      <td>1973</td>\n",
              "      <td>1973</td>\n",
              "      <td>364</td>\n",
              "      <td>...</td>\n",
              "      <td>88</td>\n",
              "      <td>68</td>\n",
              "      <td>30</td>\n",
              "      <td>12</td>\n",
              "      <td>52</td>\n",
              "      <td>9</td>\n",
              "      <td>5</td>\n",
              "      <td>21</td>\n",
              "      <td>15</td>\n",
              "      <td>14</td>\n",
              "      <td>8</td>\n",
              "      <td>70</td>\n",
              "      <td>49</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>67</td>\n",
              "      <td>7</td>\n",
              "      <td>46</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>11</td>\n",
              "      <td>32</td>\n",
              "      <td>6</td>\n",
              "      <td>82</td>\n",
              "      <td>51</td>\n",
              "      <td>12</td>\n",
              "      <td>85</td>\n",
              "      <td>15</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>17</td>\n",
              "      <td>20</td>\n",
              "      <td>252</td>\n",
              "      <td>150</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6779</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>4.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>25</td>\n",
              "      <td>1</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>25</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>439</td>\n",
              "      <td>483</td>\n",
              "      <td>349</td>\n",
              "      <td>5</td>\n",
              "      <td>501</td>\n",
              "      <td>300</td>\n",
              "      <td>436</td>\n",
              "      <td>240</td>\n",
              "      <td>1495</td>\n",
              "      <td>5</td>\n",
              "      <td>46</td>\n",
              "      <td>9849.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>27</td>\n",
              "      <td>31</td>\n",
              "      <td>1385</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>19</td>\n",
              "      <td>11</td>\n",
              "      <td>1962</td>\n",
              "      <td>1969</td>\n",
              "      <td>339</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>47</td>\n",
              "      <td>60</td>\n",
              "      <td>11</td>\n",
              "      <td>39</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>24</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>14</td>\n",
              "      <td>42</td>\n",
              "      <td>30</td>\n",
              "      <td>8</td>\n",
              "      <td>8</td>\n",
              "      <td>63</td>\n",
              "      <td>9</td>\n",
              "      <td>29</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>33</td>\n",
              "      <td>38</td>\n",
              "      <td>8</td>\n",
              "      <td>60</td>\n",
              "      <td>37</td>\n",
              "      <td>12</td>\n",
              "      <td>66</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>18</td>\n",
              "      <td>14</td>\n",
              "      <td>184</td>\n",
              "      <td>96</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4812</th>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>50</td>\n",
              "      <td>2</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>115</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>170</td>\n",
              "      <td>402</td>\n",
              "      <td>438</td>\n",
              "      <td>333</td>\n",
              "      <td>7</td>\n",
              "      <td>671</td>\n",
              "      <td>300</td>\n",
              "      <td>575</td>\n",
              "      <td>230</td>\n",
              "      <td>1083</td>\n",
              "      <td>4</td>\n",
              "      <td>47</td>\n",
              "      <td>2077.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>35</td>\n",
              "      <td>30</td>\n",
              "      <td>1179</td>\n",
              "      <td>12</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>1971</td>\n",
              "      <td>1971</td>\n",
              "      <td>335</td>\n",
              "      <td>...</td>\n",
              "      <td>95</td>\n",
              "      <td>93</td>\n",
              "      <td>54</td>\n",
              "      <td>11</td>\n",
              "      <td>35</td>\n",
              "      <td>7</td>\n",
              "      <td>6</td>\n",
              "      <td>32</td>\n",
              "      <td>24</td>\n",
              "      <td>26</td>\n",
              "      <td>11</td>\n",
              "      <td>36</td>\n",
              "      <td>30</td>\n",
              "      <td>6</td>\n",
              "      <td>3</td>\n",
              "      <td>69</td>\n",
              "      <td>13</td>\n",
              "      <td>40</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>14</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>24</td>\n",
              "      <td>31</td>\n",
              "      <td>7</td>\n",
              "      <td>40</td>\n",
              "      <td>28</td>\n",
              "      <td>7</td>\n",
              "      <td>48</td>\n",
              "      <td>5</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>18</td>\n",
              "      <td>15</td>\n",
              "      <td>252</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1510</th>\n",
              "      <td>1.0</td>\n",
              "      <td>72</td>\n",
              "      <td>1.0</td>\n",
              "      <td>46</td>\n",
              "      <td>196000.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>999000.0</td>\n",
              "      <td>8.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>50</td>\n",
              "      <td>4</td>\n",
              "      <td>10.0</td>\n",
              "      <td>14</td>\n",
              "      <td>1.0</td>\n",
              "      <td>240</td>\n",
              "      <td>484</td>\n",
              "      <td>512</td>\n",
              "      <td>383</td>\n",
              "      <td>3</td>\n",
              "      <td>606</td>\n",
              "      <td>310</td>\n",
              "      <td>537</td>\n",
              "      <td>260</td>\n",
              "      <td>1046</td>\n",
              "      <td>4</td>\n",
              "      <td>61</td>\n",
              "      <td>4343.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>25</td>\n",
              "      <td>42</td>\n",
              "      <td>966</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>13</td>\n",
              "      <td>20</td>\n",
              "      <td>14</td>\n",
              "      <td>1958</td>\n",
              "      <td>1958</td>\n",
              "      <td>408</td>\n",
              "      <td>...</td>\n",
              "      <td>81</td>\n",
              "      <td>18</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>69</td>\n",
              "      <td>7</td>\n",
              "      <td>5</td>\n",
              "      <td>19</td>\n",
              "      <td>14</td>\n",
              "      <td>14</td>\n",
              "      <td>7</td>\n",
              "      <td>89</td>\n",
              "      <td>67</td>\n",
              "      <td>4</td>\n",
              "      <td>10</td>\n",
              "      <td>71</td>\n",
              "      <td>2</td>\n",
              "      <td>56</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>10</td>\n",
              "      <td>26</td>\n",
              "      <td>23</td>\n",
              "      <td>95</td>\n",
              "      <td>57</td>\n",
              "      <td>19</td>\n",
              "      <td>96</td>\n",
              "      <td>20</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>65</td>\n",
              "      <td>25</td>\n",
              "      <td>436</td>\n",
              "      <td>275</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>4 rows × 334 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0    1         2    3         4    ...  329  330  331  332  333\n",
              "1144       1.0   46  999000.0   46  196000.0  ...    3   17   20  252  150\n",
              "6779  999000.0   46       4.0   46  196000.0  ...    2   18   14  184   96\n",
              "4812  999000.0   46  999000.0   46  196000.0  ...    3   18   15  252  154\n",
              "1510       1.0   72       1.0   46  196000.0  ...    1   65   25  436  275\n",
              "\n",
              "[4 rows x 334 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESJ1v2ctmXMn",
        "outputId": "bf190952-505a-4739-9f8e-8556d1e86bb1"
      },
      "source": [
        "print(\"County nan data:\")\n",
        "\n",
        "print(f\"Train data have {train_df.isna().sum().sum()} nan values.\")\n",
        "print(f\"Test data have {test_df.isna().sum().sum()} nan values.\")\n",
        "\n",
        "train_1 = train_df[train_label_df[0] == 1]\n",
        "train_0 = train_df[train_label_df[0] == 0]\n",
        "\n",
        "print()\n",
        "\n",
        "print(f\"Positive sample counts: {len(train_1)}\")\n",
        "print(f\"Negative sample counts: {len(train_0)}\")"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "County nan data:\n",
            "Train data have 0 nan values.\n",
            "Test data have 0 nan values.\n",
            "\n",
            "Positive sample counts: 909\n",
            "Negative sample counts: 9091\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIJ1ofkC2EWC"
      },
      "source": [
        "# Train 10 SVM models in an ensemble learning manner\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TOWoWzW7aVEl"
      },
      "source": [
        "*italicized text*## Train 10 models with cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evDaj3dj2BP5"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # actually train the model 200 times.\n",
        "    score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    trained_model_list.append(clf)\n",
        "    scores_list.append(scores)\n",
        "\n",
        "    scores_precision_list.append(score_precision)\n",
        "    scores_recall_list.append(score_recall)\n",
        "    scores_roc_auc_list.append(score_roc_auc)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pBFsjulHaEzl"
      },
      "source": [
        "## Train 10 models witouth cross validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4SPV2nT8aFWq",
        "outputId": "c5d5f43d-761d-44a5-8f96-3e79ce5f94c9"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "trained_model_list = []\n",
        "\n",
        "score_roc_auc_list = []\n",
        "score_precision_list = []\n",
        "score_recall_list = []\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "     # create a balancd training set\n",
        "    train_1 = train_df[train_label_df[0] == 1].sample(frac=1)  # shuffle\n",
        "\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "    # Use SVM\n",
        "    # clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "    #                                           kernel='rbf',\n",
        "    #                                           verbose=True, probability=True))\n",
        "    \n",
        "    # Use random forest\n",
        "    clf = make_pipeline(StandardScaler(), RandomForestClassifier(n_estimators=500))\n",
        "\n",
        "    clf.fit(balanced_train, balanced_train_label)\n",
        "\n",
        "    trained_model_list.append(clf)\n"
      ],
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "Training # 2 model...\n",
            "Training # 3 model...\n",
            "Training # 4 model...\n",
            "Training # 5 model...\n",
            "Training # 6 model...\n",
            "Training # 7 model...\n",
            "Training # 8 model...\n",
            "Training # 9 model...\n",
            "Training # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "boerEWK9mXbH"
      },
      "source": [
        "## Evaluate the trained 10 models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLtWI6u3bQrU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "245d8be4-0f9c-4b22-995a-b7bed8c5a7df"
      },
      "source": [
        "print(\"Evaluating...\")\n",
        "test_pred_list = []\n",
        "for idx, clf in enumerate(trained_model_list):\n",
        "    print(f\"Testing # {idx + 1} model...\")\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)\n"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluating...\n",
            "Testing # 1 model...\n",
            "Testing # 2 model...\n",
            "Testing # 3 model...\n",
            "Testing # 4 model...\n",
            "Testing # 5 model...\n",
            "Testing # 6 model...\n",
            "Testing # 7 model...\n",
            "Testing # 8 model...\n",
            "Testing # 9 model...\n",
            "Testing # 10 model...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ggjXh9sZkvZw"
      },
      "source": [
        "## Print out assessment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQ8Uu_LWktVA",
        "outputId": "f6ed9cbd-d17a-4401-f84d-b2af22b17053"
      },
      "source": [
        "test_pred_all = np.array(test_pred_list)\n",
        "\n",
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "precision_score = metrics.precision_score(np.array(test_label_df), pred_label, average='macro')\n",
        "\n",
        "recall_score = metrics.recall_score(np.array(test_label_df), pred_label, average='macro')\n",
        "mcc_score = metrics.matthews_corrcoef(np.array(test_label_df), pred_label)\n",
        "roc_auc_score = metrics.roc_auc_score(test_label_df, test_pred_all[:, :, 1].mean(axis=0), average=None)\n",
        "\n",
        "print(\"precision_score:\", precision_score)\n",
        "print(\"recall_score:\", recall_score)\n",
        "print(\"mcc_score:\", mcc_score)\n",
        "print(\"roc_auc_score:\", roc_auc_score)"
      ],
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_score: 0.5383174018953414\n",
            "recall_score: 0.6096338049093124\n",
            "mcc_score: 0.12962843151138675\n",
            "roc_auc_score: 0.6366664750885578\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkLyPfYiz7ml"
      },
      "source": [
        ""
      ],
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4z2zIzAie9p"
      },
      "source": [
        "## Save the predicted label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c2yYSrHbiejk"
      },
      "source": [
        "pred_label = np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).astype(int)\n",
        "np.savetxt('predict.csv', pred_label, fmt='%d' )"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Es7GV9yrxDHB"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pCMeGlv0xCxn"
      },
      "source": [
        "##Train 10 models with cross validation\n",
        "Will take about 30 min to train 300 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kjcBiDkexMev",
        "outputId": "95778edd-d2eb-415c-c255-71a962aec04f"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "\n",
        "trained_model_list = []\n",
        "scores_precision_list = []\n",
        "scores_recall_list = []\n",
        "scores_roc_auc_list =[]\n",
        "scores_mcc_list = []\n",
        "score_accuracy_list = []\n",
        "\n",
        "USE_CROSS_VALIDATION = True   # \n",
        "\n",
        "def simple_matthews_corrcoef(true_np, predict_np):\n",
        "    cm = metrics.confusion_matrix(true_np, predict_np)\n",
        "    assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "    TP = cm[1, 1]\n",
        "    TN = cm[0, 0]\n",
        "    FP = cm[0, 1]\n",
        "    FN = cm[1, 0]\n",
        "\n",
        "    MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "\n",
        "    return MCC\n",
        "\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    # print(start_row, end_row)\n",
        "\n",
        "    # create a balancd training set\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "    \n",
        "    \n",
        "\n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "\n",
        "\n",
        "    # calcuate precision, recall, AUC. actually train the model 300 times.\n",
        "    # score_recall = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='recall')\n",
        "    # score_precision = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='precision')\n",
        "    # score_roc_auc = cross_val_score(clf, balanced_train, balanced_train_label, cv=10, scoring='roc_auc')\n",
        "\n",
        "\n",
        "    # print(\"\\n%0.2f precision with a standard deviation of %0.2f\" % (score_precision.mean(), score_precision.std()))\n",
        "    # print(\"\\n%0.2f recall with a standard deviation of %0.2f\" % (score_recall.mean(), score_recall.std()))\n",
        "    # print(\"\\n%0.2f AUC with a standard deviation of %0.2f\" % (score_roc_auc.mean(), score_roc_auc.std()))\n",
        "\n",
        "    # trained_model_list.append(clf)\n",
        "    # scores_list.append(scores)\n",
        "\n",
        "    # scores_precision_list.append(score_precision)\n",
        "    # scores_recall_list.append(score_recall)\n",
        "    # scores_roc_auc_list.append(score_roc_auc)\n",
        "\n",
        "    # To calculate MCC only, actally train 100 models.\n",
        "    score_accuracy = cross_validate(clf, balanced_train, balanced_train_label, cv=10, return_estimator=True)\n",
        "    score_accuracy_list.append(score_accuracy)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model count:  10\n",
            "sample_cnt_per_portion: 909\n",
            "Training # 1 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 2 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 3 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 4 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 5 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 6 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 7 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]Training # 8 model...\n",
            "[LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM][LibSVM]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7V7nz13H-xHP"
      },
      "source": [
        "clf.predict()\n",
        "\n",
        "# calculate MCC\n",
        "mcc_score = simple_matthews_corrcoef())\n",
        "scores_mcc_list.append(mcc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jVczoNnFnnqB"
      },
      "source": [
        "# Program to calculate model performance from two label files: Precision, Recall, MCC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pgq9pUAMn065"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tOujpNPnzES"
      },
      "source": [
        "label_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "label_df = pd.read_csv(label_csv)\n",
        "predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "\n",
        "true_np = np.array(label_df)\n",
        "predict_np = np.array(predict_df)"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrINqCKqo2_7",
        "outputId": "0999ba8f-70fb-4224-fd06-515c1dc97711"
      },
      "source": [
        "class simple_metrics():\n",
        "\n",
        "    @staticmethod\n",
        "    def _load_data(true_csv, predict_csv):\n",
        "        true_csv = r'https://github.com/gladcolor/SVM_DNN_testing/raw/master/test10000_label.zip'\n",
        "        predict_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/predict.csv'\n",
        "\n",
        "        true_df = pd.read_csv(true_csv)\n",
        "        predict_df = pd.read_csv(predict_csv)\n",
        "\n",
        "        true_np = np.array(true_df)\n",
        "        predict_np = np.array(predict_df)\n",
        "\n",
        "        return true_np, predict_np\n",
        "\n",
        "    @staticmethod\n",
        "    def get_confusion_matrix(true_np, predict_np): # inputs: should be integer numpy array (1D), using the same class index schema.\n",
        "        true_unique = np.unique(true_np)\n",
        "        predict_unique = np.unique(predict_np)\n",
        "\n",
        "        cm = np.zeros((len(true_unique), len(true_unique)), dtype=int)   # cm: confusion_matrix, row is actual, column is predicted\n",
        "\n",
        "        for true_, pred in zip(true_np[:].flatten(), predict_np[:].flatten()):\n",
        "            cm[true_, pred] += 1\n",
        "            # print(true_, pred)\n",
        "        return cm\n",
        "\n",
        "    @staticmethod\n",
        "    def precision_recall_score(true_csv, predict_csv):  # CSV file has one column only withoud header.\n",
        "        true_np, predict_np = simple_metrics._load_data(true_csv, predict_csv)\n",
        "        confusion_matrix = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        class_cnt = confusion_matrix.shape[0]\n",
        "        precisions = np.zeros((class_cnt))\n",
        "        recalls = np.zeros((class_cnt))\n",
        "\n",
        " \n",
        "\n",
        "        # compute recall, precision\n",
        "        for c in range(class_cnt):\n",
        "            TP = confusion_matrix[c, c]\n",
        "            TP_FP = confusion_matrix[c, :].sum()\n",
        "            TP_FN = confusion_matrix[:, c].sum()\n",
        "            recalls[c] = TP / TP_FP\n",
        "            precisions[c] = TP / TP_FN\n",
        "\n",
        "        return precisions, recalls\n",
        "\n",
        "    @staticmethod\n",
        "    def matthews_corrcoef(true_csv, predict_csv): # CSV file has one column only withoud header.\n",
        "        MCC = 0\n",
        "        # compute MCC, current for binary classification only\n",
        "        \n",
        "        cm = simple_metrics.get_confusion_matrix(true_np, predict_np)\n",
        "        assert(cm.shape == (2, 2)), 'Support binary classification (2-class) only!'\n",
        "        TP = cm[1, 1]\n",
        "        TN = cm[0, 0]\n",
        "        FP = cm[0, 1]\n",
        "        FN = cm[1, 0]\n",
        "\n",
        "        MCC = (TP * TN - FP * FN) / (np.sqrt((TP + FP) * (TP + FN) * (TN + FP) * (TN + FN)))\n",
        "        # https://en.wikipedia.org/wiki/Matthews_correlation_coefficient\n",
        "        return MCC\n",
        "\n",
        "class_precision, class_recall = simple_metrics.precision_recall_score(label_csv, predict_csv)\n",
        "MCC =  simple_metrics.matthews_corrcoef(label_csv, predict_csv)\n",
        "\n",
        "print(\"My results:\")\n",
        "print('class_precision:', class_precision.round(4))\n",
        "print('class_recall：', class_recall.round(4))\n",
        "print('Matthews_corrcoef: %.4f' % MCC)\n",
        "\n",
        "\n",
        "print()\n",
        "print(\"sklearn results:\")\n",
        "rpt = metrics.classification_report(true_np, predict_np, digits=4)\n",
        "print(rpt)\n",
        "print()\n",
        "print(\"sklearn matthews_corrcoef: %.4f\" % metrics.matthews_corrcoef(true_np, predict_np))"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My results:\n",
            "class_precision: [0.9392 0.1409]\n",
            "class_recall： [0.6082 0.6198]\n",
            "Matthews_corrcoef: 0.1351\n",
            "\n",
            "sklearn results:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9392    0.6082    0.7383      9060\n",
            "           1     0.1409    0.6198    0.2295       939\n",
            "\n",
            "    accuracy                         0.6093      9999\n",
            "   macro avg     0.5400    0.6140    0.4839      9999\n",
            "weighted avg     0.8642    0.6093    0.6905      9999\n",
            "\n",
            "\n",
            "sklearn matthews_corrcoef: 0.1351\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cleuAxCj3Th4"
      },
      "source": [
        "print(\"sklearn results:\")\n",
        "rpt = metrics.classification_report(true_np.flatten(), predict_np.flatten())\n",
        "print(rpt)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_TBai16Qyb3E",
        "outputId": "4a756772-2939-494e-c985-90a14e062b42"
      },
      "source": [
        "\n",
        "metrics.recall_score(true_np.flatten(), predict_np.flatten())"
      ],
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6198083067092651"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hk1DK-7IyuHA",
        "outputId": "cd997458-b681-44dd-bb37-641f6c17ccea"
      },
      "source": [
        "metrics.precision_score(true_np.flatten(), predict_np.flatten())"
      ],
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.14085188770571153"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eQq35LCzcm8"
      },
      "source": [
        "rpt = metrics.classification_report(true_np.flatten(), predict_np.flatten())\n"
      ],
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL-5fFsJzI8d",
        "outputId": "227b6b54-d64f-452c-f15e-08fa0023fbc7"
      },
      "source": [
        ""
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.61      0.74      9060\n",
            "           1       0.14      0.62      0.23       939\n",
            "\n",
            "    accuracy                           0.61      9999\n",
            "   macro avg       0.54      0.61      0.48      9999\n",
            "weighted avg       0.86      0.61      0.69      9999\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e88Lxa1Cmr6w"
      },
      "source": [
        "## Train 10 models with cross validation\n",
        "\n",
        "Will take about 30 min to train 300 models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uzyUG0GqhYJy",
        "outputId": "e4a56eff-72d7-46e0-9db6-0536f3c8e101"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "precision_score: 0.5401121274658705\n",
            "recall_score: 0.6141945392246775\n",
            "mcc_score: 0.13536005191025305\n",
            "roc_auc_score: 0.650464095030264\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSz6UjomffAG",
        "outputId": "b9bb751c-54b1-47f4-842e-4a2cce1e1a94"
      },
      "source": [
        "test_pred_all[:, :, 1].mean(axis=0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.48866811, 0.39856657, 0.48200092, ..., 0.35131929, 0.36412371,\n",
              "       0.56005731])"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZMUXq9XSe4D5",
        "outputId": "e4e72af8-1984-40a6-927d-1d72364de170"
      },
      "source": [
        "np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4118"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWtahXXEeUiC",
        "outputId": "6b644a70-dfd7-4f9a-affc-b40976cbf398"
      },
      "source": [
        "np.argmax(test_pred_all, axis=1)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[3370, 7993],\n",
              "       [3370, 1967],\n",
              "       [6781, 9864],\n",
              "       [3370, 8516],\n",
              "       [2204, 7993],\n",
              "       [5448, 5553],\n",
              "       [1300, 8105],\n",
              "       [   4, 7510],\n",
              "       [4460, 5553],\n",
              "       [8481, 9035]])"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3Oidqx7djR5",
        "outputId": "f8a7feb0-bb51-4063-e4f4-3441c5f8a99a"
      },
      "source": [
        "recall_score = metrics.recall_score(test_label_df, np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0), average=None)\n",
        "recall_score"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.60964573, 0.61874334])"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yxf0vt3bgOwS",
        "outputId": "7daa5097-eca0-4d7c-bcdb-bd3d23b739d7"
      },
      "source": [
        " metrics.recall_score(np.array(test_label_df), np.where(test_pred_all[:, :, 1].mean(axis=0)>0.5, 1, 0), average='macro')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6141945392246775"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ap2wj-ffglml",
        "outputId": "c141454f-d62e-4f7a-c523-78c2add1fbff"
      },
      "source": [
        "np.array(test_label_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0],\n",
              "       [0],\n",
              "       [0],\n",
              "       ...,\n",
              "       [0],\n",
              "       [0],\n",
              "       [0]])"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JMdxXE-HVOix",
        "outputId": "c6dfc5cd-cd9a-44cc-ef61-8ccaec7605fc"
      },
      "source": [
        "scores_precision_np = np.array(scores_precision_list)\n",
        "scores_recall_np = np.array(scores_recall_list)\n",
        "scores_roc_auc_np = np.array(scores_roc_auc_list)\n",
        "\n",
        "print(\"mean of precision %.4f, recall: %.4f, roc_auc: %.4f\" % (scores_precision_np.mean(), scores_recall_np.mean(), scores_roc_auc_np.mean()))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mean of precision nan, recall: nan, roc_auc: 0.6182\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: RuntimeWarning: Mean of empty slice.\n",
            "  \"\"\"\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_methods.py:170: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  ret = ret.dtype.type(ret / rcount)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PHKcS_AHP5aB",
        "outputId": "da0ea3c7-c5f9-4be0-895d-691ad75b27af"
      },
      "source": [
        "sorted(metrics.SCORERS.keys())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['accuracy',\n",
              " 'adjusted_mutual_info_score',\n",
              " 'adjusted_rand_score',\n",
              " 'average_precision',\n",
              " 'balanced_accuracy',\n",
              " 'completeness_score',\n",
              " 'explained_variance',\n",
              " 'f1',\n",
              " 'f1_macro',\n",
              " 'f1_micro',\n",
              " 'f1_samples',\n",
              " 'f1_weighted',\n",
              " 'fowlkes_mallows_score',\n",
              " 'homogeneity_score',\n",
              " 'jaccard',\n",
              " 'jaccard_macro',\n",
              " 'jaccard_micro',\n",
              " 'jaccard_samples',\n",
              " 'jaccard_weighted',\n",
              " 'max_error',\n",
              " 'mutual_info_score',\n",
              " 'neg_brier_score',\n",
              " 'neg_log_loss',\n",
              " 'neg_mean_absolute_error',\n",
              " 'neg_mean_gamma_deviance',\n",
              " 'neg_mean_poisson_deviance',\n",
              " 'neg_mean_squared_error',\n",
              " 'neg_mean_squared_log_error',\n",
              " 'neg_median_absolute_error',\n",
              " 'neg_root_mean_squared_error',\n",
              " 'normalized_mutual_info_score',\n",
              " 'precision',\n",
              " 'precision_macro',\n",
              " 'precision_micro',\n",
              " 'precision_samples',\n",
              " 'precision_weighted',\n",
              " 'r2',\n",
              " 'recall',\n",
              " 'recall_macro',\n",
              " 'recall_micro',\n",
              " 'recall_samples',\n",
              " 'recall_weighted',\n",
              " 'roc_auc',\n",
              " 'roc_auc_ovo',\n",
              " 'roc_auc_ovo_weighted',\n",
              " 'roc_auc_ovr',\n",
              " 'roc_auc_ovr_weighted',\n",
              " 'v_measure_score']"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V-3Sd5CBLAdr"
      },
      "source": [
        "print(\"Evaluating...\")\n",
        "\n",
        "test_pred_list = []\n",
        "for clf in trained_model_list:\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Mum91Xtkhmf",
        "outputId": "8cb541be-8afc-408c-f4ea-ef7339c38286"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "balanced_train, balanced_train_label = sample_train_dataset(positive_count=len(train_1), negative_count=len(train_1))\n",
        "\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', verbose=True, probability=True))\n",
        "clf.fit(balanced_train, balanced_train_label)\n",
        "\n",
        "from sklearn import metrics\n",
        "\n",
        "test_pred = clf.predict_proba(test_df)\n",
        " \n",
        "\n",
        "# metrics.f1_score(test_pred, balanced_train_label)\n",
        "metrics.roc_auc_score(test_label_df, test_pred[:, 1], average=None)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Positive sample counts in the training set: 909\n",
            "Negative sample counts in the training set: 909\n",
            "[LibSVM]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6284599388430963"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "swajv7u0nOFs"
      },
      "source": [
        "# train 10 models\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "MODEL_CNT = int(len(train_0)/len(train_1))\n",
        "sample_cnt_per_portion = int(len(train_0)/MODEL_CNT)\n",
        "\n",
        "positive_count = len(train_1)\n",
        "negative_count = len(train_1)\n",
        "\n",
        "print(\"Model count: \", MODEL_CNT)\n",
        "print(\"sample_cnt_per_portion:\", sample_cnt_per_portion)\n",
        "trained_model_list = []\n",
        "scores_list = []\n",
        "for i in range(MODEL_CNT):\n",
        "    print(f\"Training # {i + 1} model...\")\n",
        "    start_row = i * sample_cnt_per_portion\n",
        "    end_row = start_row + sample_cnt_per_portion\n",
        "    print(start_row, end_row)\n",
        "    balanced_train = np.concatenate((train_1, train_0[start_row:end_row]), axis=0)\n",
        "    balanced_train_label = np.concatenate(([1] * positive_count, [0] * negative_count), axis=0)\n",
        "\n",
        "\n",
        "    \n",
        "    clf = make_pipeline(StandardScaler(), SVC(gamma='auto',\n",
        "                                              kernel='rbf',\n",
        "                                              verbose=True, probability=True))\n",
        "    # clf.fit(balanced_train, balanced_train_label)\n",
        "\n",
        "    scores = cross_val_score(clf, balanced_train, balanced_train_label, cv=10)\n",
        "\n",
        "    print(\"\\n%0.2f accuracy with a standard deviation of %0.2f\" % (scores.mean(), scores.std()))\n",
        "\n",
        "    trained_model_list.append(clf)\n",
        "    scores_list.append(scores)\n",
        "\n",
        "    # test_pred = clf.predict_proba(test_df)\n",
        "    # auc_score = metrics.roc_auc_score(test_label_df, test_pred[:, 1], average=None)\n",
        "    # print(\"auc_score:\", auc_score, '\\n')\n",
        "\n",
        "print(\"Evaluating...\")\n",
        "\n",
        "test_pred_list = []\n",
        "for clf in trained_model_list:\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)\n",
        "\n",
        "test_pred_all = np.array(test_pred_list)\n",
        "\n",
        "\n",
        "auc_score = metrics.roc_auc_score(test_label_df, test_pred_all[:, :, 1].mean(axis=0), average=None)\n",
        "print(\"auc_score:\", auc_score)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tezG6BiP2aNd"
      },
      "source": [
        "test_pred_list = []\n",
        "for clf in trained_model_list:\n",
        "    test_pred = clf.predict_proba(test_df)\n",
        "    test_pred_list.append(test_pred)\n",
        "\n",
        "test_pred_np = np.array(test_pred_list)\n",
        "test_pred_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V27KisSE3NDQ",
        "outputId": "b514c896-24c9-46c9-fd9f-b800a5616c39"
      },
      "source": [
        "test_pred_np = np.array(test_pred_list)\n",
        "test_pred_np.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 10000, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 223
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h-vJ1d973mRv",
        "outputId": "c45e8294-0055-438f-c484-56fe45b526ac"
      },
      "source": [
        "test_pred_np[:, :, 1].mean(axis=0).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 229
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ehWHGzS53HGf",
        "outputId": "afe4a144-9753-4090-b027-b3c9692ebcc3"
      },
      "source": [
        "auc_score = metrics.roc_auc_score(test_label_df, test_pred_np[:, :, 1].mean(axis=0), average=None)\n",
        "print(\"auc_score:\", auc_score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "auc_score: 0.6503078942286684\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxaCX_sssi4T",
        "outputId": "37fe867b-7ae6-46bc-bdab-ff4ac68efc6a"
      },
      "source": [
        "import  joblib\n",
        "% cd /content/drive/MyDrive/USC_courses/CSCE822/HW2\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/USC_courses/CSCE822/HW2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQZamkZJv-Nt",
        "outputId": "ed095abc-3b8a-4dda-c055-127a322fd9be"
      },
      "source": [
        "joblib.dump(clf, 'SVM_oversampling.joblib') "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['SVM_oversampling.joblib']"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRkS-ej04VAP"
      },
      "source": [
        "# DNN for thermal regression"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YWa0pMq25AV8"
      },
      "source": [
        "## Load packages"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfJreLSO5IIz"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "%matplotlib inline\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h12DftNw4cNQ"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2PU5z2iwGkM"
      },
      "source": [
        "data_csv = r'https://raw.githubusercontent.com/gladcolor/SVM_DNN_testing/master/themal_dataset.csv'\n",
        "\n",
        "data_df = pd.read_csv(data_csv)\n",
        "features_df = data_df.iloc[:, 1:21]\n",
        "y_label = data_df.iloc[:, 22]\n",
        "y_label = np.array(y_label)\n",
        "y_label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tb4N5NY38_kM"
      },
      "source": [
        "## Standardize features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0RVhn-tp5ivh",
        "outputId": "a77a76f7-5076-489b-dfe8-54c710722c51"
      },
      "source": [
        "from sklearn import preprocessing\n",
        "input_features = preprocessing.StandardScaler().fit_transform(features_df)\n",
        "\n",
        "print(\"Feature shape:\", input_features.shape)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature shape: (370, 20)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1G8TbaeQXzZ"
      },
      "source": [
        "## create k-fold dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYDwPgF9ikfY"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, features_np, labels_np):\n",
        "        features_np = preprocessing.StandardScaler().fit_transform(features_np)\n",
        "        self.features = torch.from_numpy(features_np)\n",
        "        self.labels = torch.from_numpy(labels_np)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        features = self.features[index, 1:21]        \n",
        "        label = self.labels[index]\n",
        "        \n",
        "        return features, label\n",
        "\n",
        "feature_dataset = FeatureDataset(features_np=input_features, labels_np=y_label)\n",
        "\n",
        "train_dataloader = DataLoader(feature_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "# list(train_dataloader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uHasAnOpQdMR"
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "\n",
        "fold_k = 10\n",
        "k_fold_spliter = KFold(n_splits=fold_k, random_state=None, shuffle=True)\n",
        "\n",
        "def train_a_model():\n",
        "\n",
        "    pass\n",
        "\n",
        "for  idx, (train_index, test_index) in enumerate(k_fold_spliter.split(input_features)):\n",
        "    # print(idx,  train_index, test_index)\n",
        "    print(f\"Processing {idx} fold.\")\n",
        "    # print(input_features[train_index].shape)\n",
        "    # print(y_label[test_index].shape)\n",
        "    feature_dataset = FeatureDataset(features_np=input_features[train_index], labels_np=y_label[train_index])\n",
        "\n",
        "    train_dataloader = DataLoader(feature_dataset, batch_size=1, shuffle=True)\n",
        "\n",
        "    print(list(train_dataloader))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KFDdHbxqgsTs"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8ywQ9Ek9QKZ"
      },
      "source": [
        "## Create neural network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCo94RqI5irV"
      },
      "source": [
        "x = torch.tensor(input_features, dtype = float).to('cuda')\n",
        "y = torch.tensor(y_label, dtype = float).to('cuda')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 725
        },
        "id": "_uGIQv5a5ijX",
        "outputId": "457eb741-f5ad-4f29-8315-64637227a33a"
      },
      "source": [
        "## 权重参数初始化 ([348,14] [14, 128] [128, 1])\n",
        "# 将当前输入的特征 (这里有14个特征) 转换为隐藏的特征 (这里设计为 128 个神经元来表示)\n",
        "weights = torch.randn((20, 128), dtype = float, requires_grad = True) \n",
        "# 偏置参数的 shape 与结果一致 (上面输出 128 个隐藏的特征), 故这里设置为 128, 即对这 128 个隐藏的特征都进行微调\n",
        "biases = torch.randn(128, dtype = float, requires_grad = True) \n",
        "# 因为我们做的是回归任务, 需要得到一个实际的值, 即将这 128 个特征转换为一个值\n",
        "weights2 = torch.randn((128, 1), dtype = float, requires_grad = True) \n",
        "# 同上, 取 1\n",
        "biases2 = torch.randn(1, dtype = float, requires_grad = True) \n",
        "\n",
        "learning_rate = 0.0001 \n",
        "losses = []\n",
        "\n",
        "for i in range(100000):\n",
        "    # 计算隐层\n",
        "    hidden = x.mm(weights) + biases\n",
        "    # 加入激活函数\n",
        "    hidden = torch.relu(hidden)\n",
        "    # 得到预测结果\n",
        "    predictions = hidden.mm(weights2) + biases2\n",
        "    # 计算损失值 (均方误差)\n",
        "    loss = torch.mean((predictions - y) ** 2) \n",
        "    losses.append(loss.data.numpy())\n",
        "\n",
        "    # 打印损失值\n",
        "    if i % 1000 == 0:\n",
        "        print('loss:', loss)\n",
        "    #返向传播计算\n",
        "    loss.backward()\n",
        "\n",
        "    # 更新参数 (梯度下降)\n",
        "    weights.data\n",
        "    weights.data.add_(- learning_rate * weights.grad.data)  \n",
        "    biases.data.add_(- learning_rate * biases.grad.data)\n",
        "    weights2.data.add_(- learning_rate * weights2.grad.data)\n",
        "    biases2.data.add_(- learning_rate * biases2.grad.data)\n",
        "\n",
        "    # 每次迭代都得记得将梯度清空, 防止累加\n",
        "    weights.grad.data.zero_()\n",
        "    biases.grad.data.zero_()\n",
        "    weights2.grad.data.zero_()\n",
        "    biases2.grad.data.zero_()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loss: tensor(5161.3208, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2414.9358, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2406.8189, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2403.7416, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2402.1950, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2401.3247, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2400.7961, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2400.4360, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2400.1695, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.9628, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.7967, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.6643, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.5532, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.4600, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.3800, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.3103, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.2493, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.1947, dtype=torch.float64, grad_fn=<MeanBackward0>)\n",
            "loss: tensor(2399.1461, dtype=torch.float64, grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-924011d92488>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'loss:'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#返向传播计算\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# 更新参数 (梯度下降)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TH2i6qr45ibj",
        "outputId": "fea94dbe-8069-49a9-ab2c-f0152aae3cac"
      },
      "source": [
        "input_size = input_features.shape[1] # 20\n",
        "hidden_size = 256\n",
        "output_size = 1\n",
        "batch_size = 8\n",
        "my_nn = torch.nn.Sequential(\n",
        "    # 第一层: 全连接层\n",
        "    torch.nn.Linear(input_size, hidden_size),\n",
        "    torch.nn.Linear(hidden_size, hidden_size),\n",
        "    # 激活函数\n",
        "    torch.nn.ReLU(),\n",
        "    # 第二层: 全连接层\n",
        "    torch.nn.Linear(hidden_size, output_size),\n",
        ")\n",
        "# 损失函数: 均方误差\n",
        "cost = torch.nn.MSELoss(reduction='mean')\n",
        "# 优化器 (动态调整学习率)\n",
        "optimizer = torch.optim.Adam(my_nn.parameters(), lr = 0.001)\n",
        "\n",
        "\n",
        "# 训练网络\n",
        "losses = []\n",
        "for i in range(10000):\n",
        "    batch_loss = []\n",
        "    # MINI-Batch 方法来进行训练\n",
        "    for start in range(0, len(input_features), batch_size):\n",
        "        end = start + batch_size if start + batch_size < len(input_features) else len(input_features)\n",
        "        # 一个 batch 输入数据\n",
        "        xx = torch.tensor(input_features[start:end], dtype = torch.float, requires_grad = True)\n",
        "        # 一个 batch 的期望值\n",
        "        yy = torch.tensor(y[start:end], dtype = torch.float, requires_grad = True)\n",
        "        # 前向传播\n",
        "        prediction = my_nn(xx).to('cuda')\n",
        "        # 计算损失值\n",
        "        loss = cost(prediction, yy)\n",
        "        # 优化并对梯度做清零\n",
        "        optimizer.zero_grad()\n",
        "        # 反向传播\n",
        "        loss.backward(retain_graph=True)\n",
        "        # 更新参数\n",
        "        optimizer.step()\n",
        "        batch_loss.append(loss.cpu().data.numpy())\n",
        "\n",
        "    # 打印损失\n",
        "    if i % 500==0:\n",
        "        losses.append(np.mean(batch_loss))\n",
        "        print(i, np.mean(batch_loss))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 2868.5024\n",
            "500 1440.0936\n",
            "1000 1292.2098\n",
            "1500 1255.4539\n",
            "2000 1234.3962\n",
            "2500 1242.9777\n",
            "3000 1239.6791\n",
            "3500 1226.8606\n",
            "4000 1236.2551\n",
            "4500 1225.0917\n",
            "5000 1226.589\n",
            "5500 1224.7754\n",
            "6000 1230.9584\n",
            "6500 1222.3491\n",
            "7000 1225.3822\n",
            "7500 1226.4371\n",
            "8000 1243.1149\n",
            "8500 1227.5492\n",
            "9000 1222.9178\n",
            "9500 1224.8018\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FMBlnN1FoBlz",
        "outputId": "dd8762b3-b318-4ef8-8150-948728fb6477"
      },
      "source": [
        "balanced_train_label.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1818,)"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hjuewYj6cUgB",
        "outputId": "f14ece5b-5b2b-469e-974c-6e152ddb3112"
      },
      "source": [
        "## Standardize data\n",
        "scaler = preprocessing.StandardScaler()\n",
        "\n",
        "scaler.fit(train_df) \n",
        "train_np = scaler.transform(train_df)\n",
        "\n",
        "scaler.fit(test_df) \n",
        "test_np = scaler.transform(test_df)\n",
        "\n",
        "print(\"Train data after stardardizing: \")\n",
        "train_np"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train data after stardardizing: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 0.95865399, -0.07246637, -0.56780365, ...,  0.72306558,\n",
              "        -0.18483915, -0.66374284],\n",
              "       [-1.04312861,  0.35965273, -0.56780598, ...,  1.05977189,\n",
              "        -0.86638465, -0.27401319],\n",
              "       [ 0.95865399,  0.35965273, -0.56780598, ...,  0.38635927,\n",
              "         0.48066999, -0.72105603],\n",
              "       ...,\n",
              "       [-1.04312861,  0.79177183, -0.56780598, ...,  1.28424277,\n",
              "         0.43256089, -0.6178923 ],\n",
              "       [ 0.95865399, -0.28852593, -0.56780598, ..., -0.96046598,\n",
              "         0.40850635, -0.28547583],\n",
              "       [ 0.95865399, -0.07246637,  1.76117084, ..., -0.28705335,\n",
              "        -0.4334028 ,  0.17302965]])"
            ]
          },
          "metadata": {},
          "execution_count": 131
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZVul2UYkdrOY"
      },
      "source": [
        "n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fiRzn3JJfpSY",
        "outputId": "d637c017-c09e-4eff-cd18-a70ea45b579b"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "\n",
        "clf = make_pipeline(StandardScaler(), SVC(gamma='auto', verbose=True))\n",
        "clf.fit(balanced_train, balanced_train_label)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 130
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ctbAkIc6hiTA",
        "outputId": "192e6544-6f28-4194-9866-b1d305389770"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.1716793125514215"
            ]
          },
          "metadata": {},
          "execution_count": 129
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsNx5G0Ph-fw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KNKv4bWKhMY-",
        "outputId": "3c345963-7dc5-45e2-a924-15d64f7f0e3b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1818,)"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15TT7-Yfdt9R",
        "outputId": "67a2c54b-a7fb-43e5-f537-3689ed041894"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LibSVM]"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('standardscaler',\n",
              "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
              "                ('svc',\n",
              "                 SVC(C=1.0, break_ties=False, cache_size=200, class_weight=None,\n",
              "                     coef0=0.0, decision_function_shape='ovr', degree=3,\n",
              "                     gamma='auto', kernel='rbf', max_iter=-1, probability=False,\n",
              "                     random_state=None, shrinking=True, tol=0.001,\n",
              "                     verbose=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cp8R2Anid6kx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fremN2Mpg7eJ",
        "outputId": "a22e3522-49ec-4cee-e6a5-f0071e5ccd6a"
      },
      "source": [
        "test_pred.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000,)"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N37i-n8vkFvx",
        "outputId": "270aa9c4-67fb-4c9e-ceb6-44ec1f52073f"
      },
      "source": [
        "(np.isnan(train_df)).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "30jqMIMIb8h3",
        "outputId": "927fac2b-dbcc-4f20-bdf2-d73dde5411e7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.2203597710547833"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqAf6rrbmLBL"
      },
      "source": [
        "test_np = np.array(test_df)\n",
        "test_np\n",
        "\n",
        "train_np = np.array(train_df)\n",
        "train_np\n",
        "\n",
        "train_label_np = np.array(train_label_df)\n",
        "train_label_np\n",
        "\n",
        "test_label_np = np.array(test_label_df)\n",
        "test_label_np"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvFV6o811eg7"
      },
      "source": [
        "## Types of data columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U57kbUJ_L7kL",
        "outputId": "1008effe-e87f-4333-c7ca-adf12d79d9b6"
      },
      "source": [
        "print(\"Column data types: \\n\")\n",
        "original_data.dtypes"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column data types: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Suburb            object\n",
              "Address           object\n",
              "Rooms              int64\n",
              "Type              object\n",
              "Price            float64\n",
              "Method            object\n",
              "SellerG           object\n",
              "Date              object\n",
              "Distance         float64\n",
              "Postcode         float64\n",
              "Bedroom2         float64\n",
              "Bathroom         float64\n",
              "Car              float64\n",
              "Landsize         float64\n",
              "BuildingArea     float64\n",
              "YearBuilt        float64\n",
              "CouncilArea       object\n",
              "Lattitude        float64\n",
              "Longtitude       float64\n",
              "Regionname        object\n",
              "Propertycount    float64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KYuuTapI1otE"
      },
      "source": [
        "## Unique values of nominal columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m6q81ITCMVyq",
        "outputId": "cb60532c-c1f9-496b-ee00-26997f59b353"
      },
      "source": [
        "print_str_unique(original_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Column        Suburb has   314 unique values.\n",
            "Column       Address has 13378 unique values.\n",
            "Column          Type has     3 unique values.\n",
            "Column        Method has     5 unique values.\n",
            "Column       SellerG has   268 unique values.\n",
            "Column          Date has    58 unique values.\n",
            "Column   CouncilArea has    34 unique values.\n",
            "Column    Regionname has     8 unique values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I-jYo7ag14D7"
      },
      "source": [
        "## Counts of missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tVZc0ZnXP__5",
        "outputId": "c8776db4-896d-489e-d974-25a0665e8771"
      },
      "source": [
        "print(\"Before imputing:\")\n",
        "count_column_nan(original_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Before imputing:\n",
            "Column        Suburb has    0  (0.0%) nan values.\n",
            "Column       Address has    0  (0.0%) nan values.\n",
            "Column         Rooms has    0  (0.0%) nan values.\n",
            "Column          Type has    0  (0.0%) nan values.\n",
            "Column         Price has    0  (0.0%) nan values.\n",
            "Column        Method has    0  (0.0%) nan values.\n",
            "Column       SellerG has    0  (0.0%) nan values.\n",
            "Column          Date has    0  (0.0%) nan values.\n",
            "Column      Distance has    0  (0.0%) nan values.\n",
            "Column      Postcode has    0  (0.0%) nan values.\n",
            "Column      Bedroom2 has    0  (0.0%) nan values.\n",
            "Column      Bathroom has    0  (0.0%) nan values.\n",
            "Column           Car has   62  (0.5%) nan values.\n",
            "Column      Landsize has    0  (0.0%) nan values.\n",
            "Column  BuildingArea has 6450 (47.5%) nan values.\n",
            "Column     YearBuilt has 5375 (39.6%) nan values.\n",
            "Column   CouncilArea has 1369 (10.1%) nan values.\n",
            "Column     Lattitude has    0  (0.0%) nan values.\n",
            "Column    Longtitude has    0  (0.0%) nan values.\n",
            "Column    Regionname has    0  (0.0%) nan values.\n",
            "Column Propertycount has    0  (0.0%) nan values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MtOmRpT1snfS"
      },
      "source": [
        "# Imputate missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UKoN5JygMthW",
        "outputId": "7974a682-6daf-41a3-9ffd-716f7abb75ef"
      },
      "source": [
        "IMPUTE_STRETEGY = ['most_frequent', 'mean', 'median']\n",
        "\n",
        "\n",
        "imputed_df = impute_df(df=original_data, strategy='most_frequent')\n",
        "print(\"After imputing:\")\n",
        "count_column_nan(imputed_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "After imputing:\n",
            "Column        Suburb has    0  (0.0%) nan values.\n",
            "Column       Address has    0  (0.0%) nan values.\n",
            "Column         Rooms has    0  (0.0%) nan values.\n",
            "Column          Type has    0  (0.0%) nan values.\n",
            "Column         Price has    0  (0.0%) nan values.\n",
            "Column        Method has    0  (0.0%) nan values.\n",
            "Column       SellerG has    0  (0.0%) nan values.\n",
            "Column          Date has    0  (0.0%) nan values.\n",
            "Column      Distance has    0  (0.0%) nan values.\n",
            "Column      Postcode has    0  (0.0%) nan values.\n",
            "Column      Bedroom2 has    0  (0.0%) nan values.\n",
            "Column      Bathroom has    0  (0.0%) nan values.\n",
            "Column           Car has    0  (0.0%) nan values.\n",
            "Column      Landsize has    0  (0.0%) nan values.\n",
            "Column  BuildingArea has    0  (0.0%) nan values.\n",
            "Column     YearBuilt has    0  (0.0%) nan values.\n",
            "Column   CouncilArea has    0  (0.0%) nan values.\n",
            "Column     Lattitude has    0  (0.0%) nan values.\n",
            "Column    Longtitude has    0  (0.0%) nan values.\n",
            "Column    Regionname has    0  (0.0%) nan values.\n",
            "Column Propertycount has    0  (0.0%) nan values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEkRPnPJUEm_"
      },
      "source": [
        "# Generate price classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t5BsGG-CUGe2",
        "outputId": "6e1eb4ee-b6d6-41e0-a3d6-c99d93c97b6f"
      },
      "source": [
        "print(\"Price column description: \\n\")\n",
        "imputed_df['Price'].describe()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Price column description: \n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    1.358000e+04\n",
              "mean     1.075684e+06\n",
              "std      6.393107e+05\n",
              "min      8.500000e+04\n",
              "25%      6.500000e+05\n",
              "50%      9.030000e+05\n",
              "75%      1.330000e+06\n",
              "max      9.000000e+06\n",
              "Name: Price, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "kqgvGt4EUKkZ",
        "outputId": "9477ba73-cd20-4a3f-b040-019993732021"
      },
      "source": [
        "imputed_df = assign_price_class(imputed_df)\n",
        "gb = imputed_df.groupby('Price_class')['Price_class'].count().to_frame()\n",
        "gb"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Price_class</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Price_class</th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2716</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "             Price_class\n",
              "Price_class             \n",
              "0                   2716\n",
              "1                   2716\n",
              "2                   2716\n",
              "3                   2716\n",
              "4                   2716"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SpmfRe4bVwyw"
      },
      "source": [
        "# Encode nominal columns (i.e., features)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BO0fI4kC3Q0Z"
      },
      "source": [
        "## encode dates"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 666
        },
        "id": "YEm369fg3Rcs",
        "outputId": "452d3e31-2530-4cfb-a30a-6cee3ec19bb1"
      },
      "source": [
        "from datetime import datetime\n",
        "\n",
        "\n",
        "imputed_df = encode_dates(imputed_df)\n",
        "imputed_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Suburb</th>\n",
              "      <th>Address</th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Price</th>\n",
              "      <th>Method</th>\n",
              "      <th>SellerG</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "      <th>Price_class</th>\n",
              "      <th>delta_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>85 Turner St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1480000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.79960</td>\n",
              "      <td>144.99840</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>25 Bloomburg St</td>\n",
              "      <td>2</td>\n",
              "      <td>h</td>\n",
              "      <td>1035000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80790</td>\n",
              "      <td>144.99340</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>5 Charles St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1465000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80930</td>\n",
              "      <td>144.99440</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>17259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>40 Federation La</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>850000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Biggin</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.79690</td>\n",
              "      <td>144.99690</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>17259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Abbotsford</td>\n",
              "      <td>55a Park St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1600000.0</td>\n",
              "      <td>VB</td>\n",
              "      <td>Nelson</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>Yarra</td>\n",
              "      <td>-37.80720</td>\n",
              "      <td>144.99410</td>\n",
              "      <td>Northern Metropolitan</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13575</th>\n",
              "      <td>Wheelers Hill</td>\n",
              "      <td>12 Strada Cr</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1245000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Barry</td>\n",
              "      <td>16.7</td>\n",
              "      <td>3150.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>652.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1981.0</td>\n",
              "      <td>Moreland</td>\n",
              "      <td>-37.90562</td>\n",
              "      <td>145.16761</td>\n",
              "      <td>South-Eastern Metropolitan</td>\n",
              "      <td>7392.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13576</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>77 Merrett Dr</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1031000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Williams</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>Moreland</td>\n",
              "      <td>-37.85927</td>\n",
              "      <td>144.87904</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13577</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>83 Power St</td>\n",
              "      <td>3</td>\n",
              "      <td>h</td>\n",
              "      <td>1170000.0</td>\n",
              "      <td>S</td>\n",
              "      <td>Raine</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>Moreland</td>\n",
              "      <td>-37.85274</td>\n",
              "      <td>144.88738</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13578</th>\n",
              "      <td>Williamstown</td>\n",
              "      <td>96 Verdon St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>2500000.0</td>\n",
              "      <td>PI</td>\n",
              "      <td>Sweeney</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>Moreland</td>\n",
              "      <td>-37.85908</td>\n",
              "      <td>144.89299</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13579</th>\n",
              "      <td>Yarraville</td>\n",
              "      <td>6 Agnes St</td>\n",
              "      <td>4</td>\n",
              "      <td>h</td>\n",
              "      <td>1285000.0</td>\n",
              "      <td>SP</td>\n",
              "      <td>Village</td>\n",
              "      <td>6.3</td>\n",
              "      <td>3013.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>Moreland</td>\n",
              "      <td>-37.81188</td>\n",
              "      <td>144.88449</td>\n",
              "      <td>Western Metropolitan</td>\n",
              "      <td>6543.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13580 rows × 22 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              Suburb           Address  ...  Price_class delta_days\n",
              "0         Abbotsford      85 Turner St  ...            0      16872\n",
              "1         Abbotsford   25 Bloomburg St  ...            0      16893\n",
              "2         Abbotsford      5 Charles St  ...            0      17259\n",
              "3         Abbotsford  40 Federation La  ...            0      17259\n",
              "4         Abbotsford       55a Park St  ...            0      16897\n",
              "...              ...               ...  ...          ...        ...\n",
              "13575  Wheelers Hill      12 Strada Cr  ...            4      17404\n",
              "13576   Williamstown     77 Merrett Dr  ...            4      17404\n",
              "13577   Williamstown       83 Power St  ...            4      17404\n",
              "13578   Williamstown      96 Verdon St  ...            4      17404\n",
              "13579     Yarraville        6 Agnes St  ...            4      17404\n",
              "\n",
              "[13580 rows x 22 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rfT66-6FbaQw"
      },
      "source": [
        "Print the unique value counts for each column.\n",
        "\n",
        "No need to encode addresses."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGVBDp_6bIxo",
        "outputId": "64c47e26-edf0-47d8-f7bd-6eb83e665364"
      },
      "source": [
        "print(\"Unique value count for each nominal column: \\n\")\n",
        "print_str_unique(original_data)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Unique value count for each nominal column: \n",
            "\n",
            "Column        Suburb has   314 unique values.\n",
            "Column       Address has 13378 unique values.\n",
            "Column          Type has     3 unique values.\n",
            "Column        Method has     5 unique values.\n",
            "Column       SellerG has   268 unique values.\n",
            "Column          Date has    58 unique values.\n",
            "Column   CouncilArea has    34 unique values.\n",
            "Column    Regionname has     8 unique values.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zy7VUP-Owq_J"
      },
      "source": [
        "## encode nominal values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 478
        },
        "id": "by7FuKgPlHlg",
        "outputId": "93e2a5ca-fb81-4eb8-a25b-d4e2bb2e3977"
      },
      "source": [
        "import category_encoders as ce\n",
        "\n",
        "ENCODING_COLUMNS = ['CouncilArea', 'Regionname', 'Type', 'Method']\n",
        "\n",
        "DROPPED_COLUMNS = ['Suburb', 'SellerG', 'Address', 'Date', 'Price']\n",
        "\n",
        "# DROPPED_COLUMNS = ['Suburb', 'SellerG', 'Address', 'delta_days']\n",
        "\n",
        "\n",
        "encoded_df = encoder_nominals(imputed_df, encode_method='target')#.drop(columns=['Price'])\n",
        "\n",
        "encoded_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Method</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "      <th>Price_class</th>\n",
              "      <th>delta_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>2</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.993017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>202.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>1.275116</td>\n",
              "      <td>-37.79960</td>\n",
              "      <td>144.99840</td>\n",
              "      <td>1.913882</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16872</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>2</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.993017</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>156.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>1.275116</td>\n",
              "      <td>-37.80790</td>\n",
              "      <td>144.99340</td>\n",
              "      <td>1.913882</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>2.089254</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>134.0</td>\n",
              "      <td>150.0</td>\n",
              "      <td>1900.0</td>\n",
              "      <td>1.275116</td>\n",
              "      <td>-37.80930</td>\n",
              "      <td>144.99440</td>\n",
              "      <td>1.913882</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>17259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.890026</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>94.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1970.0</td>\n",
              "      <td>1.275116</td>\n",
              "      <td>-37.79690</td>\n",
              "      <td>144.99690</td>\n",
              "      <td>1.913882</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>17259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>2.010842</td>\n",
              "      <td>2.5</td>\n",
              "      <td>3067.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>142.0</td>\n",
              "      <td>2014.0</td>\n",
              "      <td>1.275116</td>\n",
              "      <td>-37.80720</td>\n",
              "      <td>144.99410</td>\n",
              "      <td>1.913882</td>\n",
              "      <td>4019.0</td>\n",
              "      <td>0</td>\n",
              "      <td>16897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13575</th>\n",
              "      <td>4</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.993017</td>\n",
              "      <td>16.7</td>\n",
              "      <td>3150.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>652.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1981.0</td>\n",
              "      <td>2.810427</td>\n",
              "      <td>-37.90562</td>\n",
              "      <td>145.16761</td>\n",
              "      <td>3.397778</td>\n",
              "      <td>7392.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13576</th>\n",
              "      <td>3</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>2.089254</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>333.0</td>\n",
              "      <td>133.0</td>\n",
              "      <td>1995.0</td>\n",
              "      <td>2.810427</td>\n",
              "      <td>-37.85927</td>\n",
              "      <td>144.87904</td>\n",
              "      <td>2.083786</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13577</th>\n",
              "      <td>3</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.993017</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>436.0</td>\n",
              "      <td>120.0</td>\n",
              "      <td>1997.0</td>\n",
              "      <td>2.810427</td>\n",
              "      <td>-37.85274</td>\n",
              "      <td>144.88738</td>\n",
              "      <td>2.083786</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13578</th>\n",
              "      <td>4</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>1.890026</td>\n",
              "      <td>6.8</td>\n",
              "      <td>3016.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>5.0</td>\n",
              "      <td>866.0</td>\n",
              "      <td>157.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>2.810427</td>\n",
              "      <td>-37.85908</td>\n",
              "      <td>144.89299</td>\n",
              "      <td>2.083786</td>\n",
              "      <td>6380.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13579</th>\n",
              "      <td>4</td>\n",
              "      <td>2.097682</td>\n",
              "      <td>2.089254</td>\n",
              "      <td>6.3</td>\n",
              "      <td>3013.0</td>\n",
              "      <td>4.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>362.0</td>\n",
              "      <td>112.0</td>\n",
              "      <td>1920.0</td>\n",
              "      <td>2.810427</td>\n",
              "      <td>-37.81188</td>\n",
              "      <td>144.88449</td>\n",
              "      <td>2.083786</td>\n",
              "      <td>6543.0</td>\n",
              "      <td>4</td>\n",
              "      <td>17404</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>13580 rows × 18 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Rooms      Type    Method  ...  Propertycount  Price_class  delta_days\n",
              "0          2  2.097682  1.993017  ...         4019.0            0       16872\n",
              "1          2  2.097682  1.993017  ...         4019.0            0       16893\n",
              "2          3  2.097682  2.089254  ...         4019.0            0       17259\n",
              "3          3  2.097682  1.890026  ...         4019.0            0       17259\n",
              "4          4  2.097682  2.010842  ...         4019.0            0       16897\n",
              "...      ...       ...       ...  ...            ...          ...         ...\n",
              "13575      4  2.097682  1.993017  ...         7392.0            4       17404\n",
              "13576      3  2.097682  2.089254  ...         6380.0            4       17404\n",
              "13577      3  2.097682  1.993017  ...         6380.0            4       17404\n",
              "13578      4  2.097682  1.890026  ...         6380.0            4       17404\n",
              "13579      4  2.097682  2.089254  ...         6543.0            4       17404\n",
              "\n",
              "[13580 rows x 18 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gi7dFZIsb_7H"
      },
      "source": [
        "# Split train/test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZXVqfwxc0JU",
        "outputId": "384744d0-8764-4438-b450-4edd26b0e458"
      },
      "source": [
        "\n",
        "encoded_df = standardize_data(encoded_df, class_col='Price_class')\n",
        "\n",
        "xTrain, yTrain, xVal, yVal, xTest, yTest = split_data(encoded_df)\n",
        "\n",
        "print(f'Sample counts: xTrain: {len(xTrain)}, xVal: {len(xVal)}, x_test: {len(xTest)}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample counts: xTrain: 10185, xVal: 1358, x_test: 2037\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L7-W5nyQdOyf"
      },
      "source": [
        "# K nearest neighbors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 442
        },
        "id": "7EFR8q5S66u1",
        "outputId": "893c6ca6-7742-4c59-fe6f-c08224c22da7"
      },
      "source": [
        "xTrain"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rooms</th>\n",
              "      <th>Type</th>\n",
              "      <th>Method</th>\n",
              "      <th>Distance</th>\n",
              "      <th>Postcode</th>\n",
              "      <th>Bedroom2</th>\n",
              "      <th>Bathroom</th>\n",
              "      <th>Car</th>\n",
              "      <th>Landsize</th>\n",
              "      <th>BuildingArea</th>\n",
              "      <th>YearBuilt</th>\n",
              "      <th>CouncilArea</th>\n",
              "      <th>Lattitude</th>\n",
              "      <th>Longtitude</th>\n",
              "      <th>Regionname</th>\n",
              "      <th>Propertycount</th>\n",
              "      <th>delta_days</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>664</th>\n",
              "      <td>0.064876</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>-0.159798</td>\n",
              "      <td>-0.014358</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>0.673367</td>\n",
              "      <td>0.403998</td>\n",
              "      <td>-0.047717</td>\n",
              "      <td>0.102509</td>\n",
              "      <td>1.451197</td>\n",
              "      <td>-0.879128</td>\n",
              "      <td>0.310418</td>\n",
              "      <td>0.945839</td>\n",
              "      <td>-0.804755</td>\n",
              "      <td>0.080984</td>\n",
              "      <td>-1.344403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3270</th>\n",
              "      <td>-0.981463</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>0.061723</td>\n",
              "      <td>-0.268015</td>\n",
              "      <td>-0.947035</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>0.403998</td>\n",
              "      <td>0.006912</td>\n",
              "      <td>-0.144742</td>\n",
              "      <td>-0.405266</td>\n",
              "      <td>0.148444</td>\n",
              "      <td>0.828984</td>\n",
              "      <td>0.513742</td>\n",
              "      <td>1.283410</td>\n",
              "      <td>-1.029462</td>\n",
              "      <td>-1.311000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3873</th>\n",
              "      <td>-0.981463</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>0.181004</td>\n",
              "      <td>0.437813</td>\n",
              "      <td>-0.947035</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>-0.636847</td>\n",
              "      <td>-0.052729</td>\n",
              "      <td>-0.042783</td>\n",
              "      <td>0.110418</td>\n",
              "      <td>-0.295337</td>\n",
              "      <td>-0.731763</td>\n",
              "      <td>0.461775</td>\n",
              "      <td>-0.804755</td>\n",
              "      <td>0.307550</td>\n",
              "      <td>-0.832225</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13170</th>\n",
              "      <td>0.064876</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>1.612373</td>\n",
              "      <td>-0.323158</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>-0.636847</td>\n",
              "      <td>-0.009376</td>\n",
              "      <td>-0.042783</td>\n",
              "      <td>0.110418</td>\n",
              "      <td>1.230403</td>\n",
              "      <td>2.153285</td>\n",
              "      <td>0.544441</td>\n",
              "      <td>-0.217939</td>\n",
              "      <td>0.792885</td>\n",
              "      <td>1.377935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1730</th>\n",
              "      <td>1.111216</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>0.215084</td>\n",
              "      <td>0.636327</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>0.673367</td>\n",
              "      <td>0.403998</td>\n",
              "      <td>0.032222</td>\n",
              "      <td>0.255448</td>\n",
              "      <td>0.557344</td>\n",
              "      <td>-1.360186</td>\n",
              "      <td>-1.058548</td>\n",
              "      <td>0.507005</td>\n",
              "      <td>-0.804755</td>\n",
              "      <td>0.083953</td>\n",
              "      <td>-0.565001</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13123</th>\n",
              "      <td>0.064876</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>1.119472</td>\n",
              "      <td>-0.841402</td>\n",
              "      <td>-0.543729</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>0.403998</td>\n",
              "      <td>-0.086810</td>\n",
              "      <td>-0.042783</td>\n",
              "      <td>0.110418</td>\n",
              "      <td>1.230403</td>\n",
              "      <td>0.406939</td>\n",
              "      <td>-0.359595</td>\n",
              "      <td>-0.217939</td>\n",
              "      <td>1.019450</td>\n",
              "      <td>1.377935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3264</th>\n",
              "      <td>0.064876</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>0.061723</td>\n",
              "      <td>-0.268015</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>-0.636847</td>\n",
              "      <td>0.047509</td>\n",
              "      <td>-0.091213</td>\n",
              "      <td>-0.577161</td>\n",
              "      <td>0.148444</td>\n",
              "      <td>0.852957</td>\n",
              "      <td>0.508930</td>\n",
              "      <td>1.283410</td>\n",
              "      <td>-1.029462</td>\n",
              "      <td>0.208833</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9845</th>\n",
              "      <td>1.111216</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-1.379354</td>\n",
              "      <td>-0.585801</td>\n",
              "      <td>-0.521672</td>\n",
              "      <td>1.123604</td>\n",
              "      <td>0.673367</td>\n",
              "      <td>0.403998</td>\n",
              "      <td>-0.029424</td>\n",
              "      <td>0.301330</td>\n",
              "      <td>1.210544</td>\n",
              "      <td>1.230403</td>\n",
              "      <td>0.927146</td>\n",
              "      <td>-0.218033</td>\n",
              "      <td>-0.217939</td>\n",
              "      <td>0.856378</td>\n",
              "      <td>0.871324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10799</th>\n",
              "      <td>0.064876</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>-0.087583</td>\n",
              "      <td>0.317325</td>\n",
              "      <td>-0.356244</td>\n",
              "      <td>0.088284</td>\n",
              "      <td>-0.772376</td>\n",
              "      <td>-0.636847</td>\n",
              "      <td>0.011924</td>\n",
              "      <td>-0.042783</td>\n",
              "      <td>0.110418</td>\n",
              "      <td>-0.407697</td>\n",
              "      <td>1.118297</td>\n",
              "      <td>0.297693</td>\n",
              "      <td>-0.217939</td>\n",
              "      <td>3.242170</td>\n",
              "      <td>1.116279</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2732</th>\n",
              "      <td>1.111216</td>\n",
              "      <td>0.659632</td>\n",
              "      <td>1.119472</td>\n",
              "      <td>-0.636921</td>\n",
              "      <td>-1.040015</td>\n",
              "      <td>1.123604</td>\n",
              "      <td>0.673367</td>\n",
              "      <td>-0.636847</td>\n",
              "      <td>-0.059996</td>\n",
              "      <td>-0.017293</td>\n",
              "      <td>-1.780424</td>\n",
              "      <td>-0.223514</td>\n",
              "      <td>0.188031</td>\n",
              "      <td>-1.036612</td>\n",
              "      <td>0.212036</td>\n",
              "      <td>0.026398</td>\n",
              "      <td>-0.292211</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10185 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "          Rooms      Type    Method  ...  Regionname  Propertycount  delta_days\n",
              "664    0.064876  0.659632 -0.087583  ...   -0.804755       0.080984   -1.344403\n",
              "3270  -0.981463  0.659632 -0.087583  ...    1.283410      -1.029462   -1.311000\n",
              "3873  -0.981463  0.659632 -0.087583  ...   -0.804755       0.307550   -0.832225\n",
              "13170  0.064876  0.659632 -0.087583  ...   -0.217939       0.792885    1.377935\n",
              "1730   1.111216  0.659632 -0.087583  ...   -0.804755       0.083953   -0.565001\n",
              "...         ...       ...       ...  ...         ...            ...         ...\n",
              "13123  0.064876  0.659632  1.119472  ...   -0.217939       1.019450    1.377935\n",
              "3264   0.064876  0.659632 -0.087583  ...    1.283410      -1.029462    0.208833\n",
              "9845   1.111216  0.659632 -1.379354  ...   -0.217939       0.856378    0.871324\n",
              "10799  0.064876  0.659632 -0.087583  ...   -0.217939       3.242170    1.116279\n",
              "2732   1.111216  0.659632  1.119472  ...    0.212036       0.026398   -0.292211\n",
              "\n",
              "[10185 rows x 17 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6ikYMCl8LUJq",
        "outputId": "b2f06c32-b1cb-4a5d-bf36-a141496176ed"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn import metrics\n",
        "\n",
        "k_range = range(3, 11)\n",
        "scores_dict = {}\n",
        "scores_list = []\n",
        "\n",
        "\n",
        "\n",
        "for k in k_range:\n",
        "    knn = KNeighborsClassifier(n_neighbors = k)\n",
        "\n",
        "    knn.fit(xTrain, yTrain)\n",
        "    y_pred = knn.predict(xTest)\n",
        "    score = metrics.accuracy_score(yTest, y_pred)\n",
        "    scores_dict[f'k={k}'] = round(score, 5)\n",
        "    scores_list.append(score)\n",
        "\n",
        "scores_dict"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'k=10': 0.59548,\n",
              " 'k=3': 0.58714,\n",
              " 'k=4': 0.59352,\n",
              " 'k=5': 0.60677,\n",
              " 'k=6': 0.60088,\n",
              " 'k=7': 0.59647,\n",
              " 'k=8': 0.58567,\n",
              " 'k=9': 0.59352}"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SllcSmcZ9adV"
      },
      "source": [
        "# Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FGCFN97D8t8W",
        "outputId": "4ba231e9-ad99-4ec0-c994-d6fe8377bdce"
      },
      "source": [
        "DROPPED_COLUMNS = ['SellerG',   'Address', 'Date', 'Price'] # , 'BuildingArea', 'YearBuilt'\n",
        "ENCODING_COLUMNS = ['Suburb', 'Method', 'CouncilArea', 'Regionname', 'Type']\n",
        "\n",
        "pd.options.display.float_format = '{:,.4f}'.format\n",
        "\n",
        "\n",
        "IMPUTE_STRETEGY = ['mean', 'most_frequent',  'median']\n",
        "k_range = list(range(3, 11)) + [20]\n",
        "\n",
        "data_csv = r'https://github.com/gladcolor/Housing_RandomForest/raw/master/melb_data.csv'\n",
        "original_data = pd.read_csv(data_csv).drop(columns=DROPPED_COLUMNS)\n",
        "\n",
        "\n",
        "\n",
        "results_df = pd.DataFrame(columns=['Impute_strategy', 'Nominal_encoding', \n",
        "                                   'Radom_forest_50', \n",
        "                                   'Radom_forest_100', \n",
        "                                   'Radom_forest_200'] + \n",
        "                                   [f'KNN_{k}' for k in k_range]\n",
        "                                   )\n",
        "\n",
        "ENCODING_METHODS_DICT = {'one_hot': ce.OneHotEncoder,\n",
        "                         'hasing':ce.HashingEncoder, \n",
        "                         'leave_one_out':ce.LeaveOneOutEncoder,  # Accuracy 1.0. Need to dig it.\n",
        "                         'binary':ce.BinaryEncoder, \n",
        "                         'target':ce.TargetEncoder,\n",
        "                        #  'baseN':ce.BaseNEncoder, # the same results as one-hot and binary when base = 1 or 2.\n",
        "                         \n",
        "                         }\n",
        "\n",
        "def get_RandomForest_accuracy(xTrain, yTrain, xTest, yTest, n_estimators=50):\n",
        "    clf = RandomForestClassifier(n_estimators=n_estimators)\n",
        "    clf.fit(xTrain, yTrain)\n",
        "    yPred = clf.predict(xTest)\n",
        "    accuracy = metrics.accuracy_score(yTest, yPred)\n",
        "    return accuracy\n",
        "\n",
        "\n",
        "for impute_strategy in IMPUTE_STRETEGY:\n",
        "    imputed_df = impute_df(df=original_data, strategy=impute_strategy)\n",
        "    imputed_df = assign_price_class(imputed_df)\n",
        "    \n",
        "    for ce_encoder_name in ENCODING_METHODS_DICT.keys():   \n",
        "\n",
        "        encoded_df = encoder_nominals(imputed_df, encode_method=ce_encoder_name)\n",
        "\n",
        "        encoded_df = standardize_data(encoded_df, class_col='Price_class')\n",
        " \n",
        "        xTrain, yTrain, xVal, yVal, xTest, yTest = split_data(encoded_df)\n",
        " \n",
        "        current_row = len(results_df)\n",
        "\n",
        "        # conduct Random forest        \n",
        "        RF_score_50 = get_RandomForest_accuracy(xTrain, yTrain, xTest, yTest, n_estimators=50) \n",
        "        RF_score_100 = get_RandomForest_accuracy(xTrain, yTrain, xTest, yTest, n_estimators=100) \n",
        "        RF_score_200 = get_RandomForest_accuracy(xTrain, yTrain, xTest, yTest, n_estimators=200) \n",
        "        print(f\"Computed Random Forest, {impute_strategy}, {ce_encoder_name}, score: {RF_score_50:.5f}, {RF_score_100:.5f}, {RF_score_200:.5f}\")\n",
        "\n",
        "        # conduct KNN     \n",
        "        for k in k_range:\n",
        "            knn = KNeighborsClassifier(n_neighbors = k)\n",
        "            knn.fit(xTrain, yTrain)\n",
        "            y_pred = knn.predict(xTest)\n",
        "            score = metrics.accuracy_score(yTest, y_pred)\n",
        "            \n",
        "            # record the accuracy\n",
        "            column_name = f'KNN_{k}'\n",
        "            print(f\"Computed  {column_name}, {impute_strategy}, {ce_encoder_name}, score: {score:.5f}\")\n",
        "            \n",
        "\n",
        "            results_df.loc[current_row, column_name] = round(score, 5)\n",
        "            results_df.loc[current_row, 'Nominal_encoding'] = ce_encoder_name\n",
        "            results_df.loc[current_row, 'Impute_strategy'] = impute_strategy\n",
        "            results_df.loc[current_row, 'Radom_forest_50'] = round(RF_score_50, 5)\n",
        "            results_df.loc[current_row, 'Radom_forest_100'] = round(RF_score_100, 5)\n",
        "            results_df.loc[current_row, 'Radom_forest_200'] = round(RF_score_200, 5)\n",
        "            # print(results_df.head(10))\n",
        "\n",
        "results_df.to_csv(\"results.csv\")\n",
        "results_df"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, mean, one_hot, score: 0.71870, 0.71625, 0.71674\n",
            "Computed  KNN_3, mean, one_hot, score: 0.65734\n",
            "Computed  KNN_4, mean, one_hot, score: 0.67108\n",
            "Computed  KNN_5, mean, one_hot, score: 0.67108\n",
            "Computed  KNN_6, mean, one_hot, score: 0.66814\n",
            "Computed  KNN_7, mean, one_hot, score: 0.66618\n",
            "Computed  KNN_8, mean, one_hot, score: 0.67305\n",
            "Computed  KNN_9, mean, one_hot, score: 0.66961\n",
            "Computed  KNN_10, mean, one_hot, score: 0.67207\n",
            "Computed  KNN_20, mean, one_hot, score: 0.64948\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, mean, hasing, score: 0.73834, 0.73883, 0.73490\n",
            "Computed  KNN_3, mean, hasing, score: 0.56063\n",
            "Computed  KNN_4, mean, hasing, score: 0.55572\n",
            "Computed  KNN_5, mean, hasing, score: 0.57339\n",
            "Computed  KNN_6, mean, hasing, score: 0.57094\n",
            "Computed  KNN_7, mean, hasing, score: 0.57732\n",
            "Computed  KNN_8, mean, hasing, score: 0.57634\n",
            "Computed  KNN_9, mean, hasing, score: 0.57388\n",
            "Computed  KNN_10, mean, hasing, score: 0.57192\n",
            "Computed  KNN_20, mean, hasing, score: 0.57192\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, mean, leave_one_out, score: 0.99951, 1.00000, 0.99951\n",
            "Computed  KNN_3, mean, leave_one_out, score: 0.59254\n",
            "Computed  KNN_4, mean, leave_one_out, score: 0.60285\n",
            "Computed  KNN_5, mean, leave_one_out, score: 0.61463\n",
            "Computed  KNN_6, mean, leave_one_out, score: 0.60432\n",
            "Computed  KNN_7, mean, leave_one_out, score: 0.61267\n",
            "Computed  KNN_8, mean, leave_one_out, score: 0.60874\n",
            "Computed  KNN_9, mean, leave_one_out, score: 0.61217\n",
            "Computed  KNN_10, mean, leave_one_out, score: 0.60776\n",
            "Computed  KNN_20, mean, leave_one_out, score: 0.59254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, mean, binary, score: 0.74521, 0.75012, 0.74865\n",
            "Computed  KNN_3, mean, binary, score: 0.63770\n",
            "Computed  KNN_4, mean, binary, score: 0.64359\n",
            "Computed  KNN_5, mean, binary, score: 0.64507\n",
            "Computed  KNN_6, mean, binary, score: 0.64899\n",
            "Computed  KNN_7, mean, binary, score: 0.65390\n",
            "Computed  KNN_8, mean, binary, score: 0.66323\n",
            "Computed  KNN_9, mean, binary, score: 0.65636\n",
            "Computed  KNN_10, mean, binary, score: 0.65930\n",
            "Computed  KNN_20, mean, binary, score: 0.65488\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, mean, target, score: 0.75503, 0.75749, 0.75945\n",
            "Computed  KNN_3, mean, target, score: 0.59352\n",
            "Computed  KNN_4, mean, target, score: 0.60628\n",
            "Computed  KNN_5, mean, target, score: 0.61561\n",
            "Computed  KNN_6, mean, target, score: 0.60579\n",
            "Computed  KNN_7, mean, target, score: 0.61954\n",
            "Computed  KNN_8, mean, target, score: 0.61267\n",
            "Computed  KNN_9, mean, target, score: 0.61512\n",
            "Computed  KNN_10, mean, target, score: 0.61168\n",
            "Computed  KNN_20, mean, target, score: 0.59352\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, most_frequent, one_hot, score: 0.71379, 0.71625, 0.71870\n",
            "Computed  KNN_3, most_frequent, one_hot, score: 0.66176\n",
            "Computed  KNN_4, most_frequent, one_hot, score: 0.67354\n",
            "Computed  KNN_5, most_frequent, one_hot, score: 0.67501\n",
            "Computed  KNN_6, most_frequent, one_hot, score: 0.66716\n",
            "Computed  KNN_7, most_frequent, one_hot, score: 0.66618\n",
            "Computed  KNN_8, most_frequent, one_hot, score: 0.67108\n",
            "Computed  KNN_9, most_frequent, one_hot, score: 0.66618\n",
            "Computed  KNN_10, most_frequent, one_hot, score: 0.67108\n",
            "Computed  KNN_20, most_frequent, one_hot, score: 0.64850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, most_frequent, hasing, score: 0.74325, 0.74521, 0.73981\n",
            "Computed  KNN_3, most_frequent, hasing, score: 0.55817\n",
            "Computed  KNN_4, most_frequent, hasing, score: 0.55817\n",
            "Computed  KNN_5, most_frequent, hasing, score: 0.57732\n",
            "Computed  KNN_6, most_frequent, hasing, score: 0.56848\n",
            "Computed  KNN_7, most_frequent, hasing, score: 0.56996\n",
            "Computed  KNN_8, most_frequent, hasing, score: 0.57192\n",
            "Computed  KNN_9, most_frequent, hasing, score: 0.57339\n",
            "Computed  KNN_10, most_frequent, hasing, score: 0.56652\n",
            "Computed  KNN_20, most_frequent, hasing, score: 0.57094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, most_frequent, leave_one_out, score: 0.99951, 0.99951, 0.99951\n",
            "Computed  KNN_3, most_frequent, leave_one_out, score: 0.59499\n",
            "Computed  KNN_4, most_frequent, leave_one_out, score: 0.60530\n",
            "Computed  KNN_5, most_frequent, leave_one_out, score: 0.61954\n",
            "Computed  KNN_6, most_frequent, leave_one_out, score: 0.61463\n",
            "Computed  KNN_7, most_frequent, leave_one_out, score: 0.61267\n",
            "Computed  KNN_8, most_frequent, leave_one_out, score: 0.60825\n",
            "Computed  KNN_9, most_frequent, leave_one_out, score: 0.61119\n",
            "Computed  KNN_10, most_frequent, leave_one_out, score: 0.60383\n",
            "Computed  KNN_20, most_frequent, leave_one_out, score: 0.59107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, most_frequent, binary, score: 0.74227, 0.74472, 0.75061\n",
            "Computed  KNN_3, most_frequent, binary, score: 0.64016\n",
            "Computed  KNN_4, most_frequent, binary, score: 0.64752\n",
            "Computed  KNN_5, most_frequent, binary, score: 0.64850\n",
            "Computed  KNN_6, most_frequent, binary, score: 0.64850\n",
            "Computed  KNN_7, most_frequent, binary, score: 0.65439\n",
            "Computed  KNN_8, most_frequent, binary, score: 0.66078\n",
            "Computed  KNN_9, most_frequent, binary, score: 0.65390\n",
            "Computed  KNN_10, most_frequent, binary, score: 0.66421\n",
            "Computed  KNN_20, most_frequent, binary, score: 0.65439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, most_frequent, target, score: 0.75503, 0.76092, 0.76043\n",
            "Computed  KNN_3, most_frequent, target, score: 0.59745\n",
            "Computed  KNN_4, most_frequent, target, score: 0.60481\n",
            "Computed  KNN_5, most_frequent, target, score: 0.61905\n",
            "Computed  KNN_6, most_frequent, target, score: 0.61561\n",
            "Computed  KNN_7, most_frequent, target, score: 0.61561\n",
            "Computed  KNN_8, most_frequent, target, score: 0.61365\n",
            "Computed  KNN_9, most_frequent, target, score: 0.61807\n",
            "Computed  KNN_10, most_frequent, target, score: 0.60923\n",
            "Computed  KNN_20, most_frequent, target, score: 0.59450\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, median, one_hot, score: 0.71821, 0.71969, 0.72214\n",
            "Computed  KNN_3, median, one_hot, score: 0.66127\n",
            "Computed  KNN_4, median, one_hot, score: 0.67354\n",
            "Computed  KNN_5, median, one_hot, score: 0.67403\n",
            "Computed  KNN_6, median, one_hot, score: 0.66716\n",
            "Computed  KNN_7, median, one_hot, score: 0.66568\n",
            "Computed  KNN_8, median, one_hot, score: 0.67108\n",
            "Computed  KNN_9, median, one_hot, score: 0.66618\n",
            "Computed  KNN_10, median, one_hot, score: 0.67108\n",
            "Computed  KNN_20, median, one_hot, score: 0.64850\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, median, hasing, score: 0.73490, 0.74718, 0.73883\n",
            "Computed  KNN_3, median, hasing, score: 0.55817\n",
            "Computed  KNN_4, median, hasing, score: 0.55817\n",
            "Computed  KNN_5, median, hasing, score: 0.57634\n",
            "Computed  KNN_6, median, hasing, score: 0.56750\n",
            "Computed  KNN_7, median, hasing, score: 0.56996\n",
            "Computed  KNN_8, median, hasing, score: 0.57192\n",
            "Computed  KNN_9, median, hasing, score: 0.57290\n",
            "Computed  KNN_10, median, hasing, score: 0.56652\n",
            "Computed  KNN_20, median, hasing, score: 0.57094\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, median, leave_one_out, score: 1.00000, 1.00000, 0.99951\n",
            "Computed  KNN_3, median, leave_one_out, score: 0.59597\n",
            "Computed  KNN_4, median, leave_one_out, score: 0.60530\n",
            "Computed  KNN_5, median, leave_one_out, score: 0.61905\n",
            "Computed  KNN_6, median, leave_one_out, score: 0.61512\n",
            "Computed  KNN_7, median, leave_one_out, score: 0.61119\n",
            "Computed  KNN_8, median, leave_one_out, score: 0.60972\n",
            "Computed  KNN_9, median, leave_one_out, score: 0.61168\n",
            "Computed  KNN_10, median, leave_one_out, score: 0.60383\n",
            "Computed  KNN_20, median, leave_one_out, score: 0.59107\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, median, binary, score: 0.74423, 0.75061, 0.74963\n",
            "Computed  KNN_3, median, binary, score: 0.63967\n",
            "Computed  KNN_4, median, binary, score: 0.64703\n",
            "Computed  KNN_5, median, binary, score: 0.64752\n",
            "Computed  KNN_6, median, binary, score: 0.64850\n",
            "Computed  KNN_7, median, binary, score: 0.65390\n",
            "Computed  KNN_8, median, binary, score: 0.66078\n",
            "Computed  KNN_9, median, binary, score: 0.65390\n",
            "Computed  KNN_10, median, binary, score: 0.66421\n",
            "Computed  KNN_20, median, binary, score: 0.65439\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/category_encoders/utils.py:21: FutureWarning: is_categorical is deprecated and will be removed in a future version.  Use is_categorical_dtype instead\n",
            "  elif pd.api.types.is_categorical(cols):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computed Random Forest, median, target, score: 0.75896, 0.75994, 0.75945\n",
            "Computed  KNN_3, median, target, score: 0.59794\n",
            "Computed  KNN_4, median, target, score: 0.60481\n",
            "Computed  KNN_5, median, target, score: 0.61856\n",
            "Computed  KNN_6, median, target, score: 0.61561\n",
            "Computed  KNN_7, median, target, score: 0.61561\n",
            "Computed  KNN_8, median, target, score: 0.61414\n",
            "Computed  KNN_9, median, target, score: 0.61807\n",
            "Computed  KNN_10, median, target, score: 0.60874\n",
            "Computed  KNN_20, median, target, score: 0.59450\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Impute_strategy</th>\n",
              "      <th>Nominal_encoding</th>\n",
              "      <th>Radom_forest_50</th>\n",
              "      <th>Radom_forest_100</th>\n",
              "      <th>Radom_forest_200</th>\n",
              "      <th>KNN_3</th>\n",
              "      <th>KNN_4</th>\n",
              "      <th>KNN_5</th>\n",
              "      <th>KNN_6</th>\n",
              "      <th>KNN_7</th>\n",
              "      <th>KNN_8</th>\n",
              "      <th>KNN_9</th>\n",
              "      <th>KNN_10</th>\n",
              "      <th>KNN_20</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>mean</td>\n",
              "      <td>one_hot</td>\n",
              "      <td>0.7187</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.7167</td>\n",
              "      <td>0.6573</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6681</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.6731</td>\n",
              "      <td>0.6696</td>\n",
              "      <td>0.6721</td>\n",
              "      <td>0.6495</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>mean</td>\n",
              "      <td>hasing</td>\n",
              "      <td>0.7383</td>\n",
              "      <td>0.7388</td>\n",
              "      <td>0.7349</td>\n",
              "      <td>0.5606</td>\n",
              "      <td>0.5557</td>\n",
              "      <td>0.5734</td>\n",
              "      <td>0.5709</td>\n",
              "      <td>0.5773</td>\n",
              "      <td>0.5763</td>\n",
              "      <td>0.5739</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>0.5719</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>mean</td>\n",
              "      <td>leave_one_out</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.5925</td>\n",
              "      <td>0.6028</td>\n",
              "      <td>0.6146</td>\n",
              "      <td>0.6043</td>\n",
              "      <td>0.6127</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.6122</td>\n",
              "      <td>0.6078</td>\n",
              "      <td>0.5925</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>mean</td>\n",
              "      <td>binary</td>\n",
              "      <td>0.7452</td>\n",
              "      <td>0.7501</td>\n",
              "      <td>0.7487</td>\n",
              "      <td>0.6377</td>\n",
              "      <td>0.6436</td>\n",
              "      <td>0.6451</td>\n",
              "      <td>0.6490</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6632</td>\n",
              "      <td>0.6564</td>\n",
              "      <td>0.6593</td>\n",
              "      <td>0.6549</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>mean</td>\n",
              "      <td>target</td>\n",
              "      <td>0.7550</td>\n",
              "      <td>0.7575</td>\n",
              "      <td>0.7594</td>\n",
              "      <td>0.5935</td>\n",
              "      <td>0.6063</td>\n",
              "      <td>0.6156</td>\n",
              "      <td>0.6058</td>\n",
              "      <td>0.6195</td>\n",
              "      <td>0.6127</td>\n",
              "      <td>0.6151</td>\n",
              "      <td>0.6117</td>\n",
              "      <td>0.5935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>most_frequent</td>\n",
              "      <td>one_hot</td>\n",
              "      <td>0.7138</td>\n",
              "      <td>0.7163</td>\n",
              "      <td>0.7187</td>\n",
              "      <td>0.6618</td>\n",
              "      <td>0.6735</td>\n",
              "      <td>0.6750</td>\n",
              "      <td>0.6672</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>most_frequent</td>\n",
              "      <td>hasing</td>\n",
              "      <td>0.7432</td>\n",
              "      <td>0.7452</td>\n",
              "      <td>0.7398</td>\n",
              "      <td>0.5582</td>\n",
              "      <td>0.5582</td>\n",
              "      <td>0.5773</td>\n",
              "      <td>0.5685</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>0.5734</td>\n",
              "      <td>0.5665</td>\n",
              "      <td>0.5709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>most_frequent</td>\n",
              "      <td>leave_one_out</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.5950</td>\n",
              "      <td>0.6053</td>\n",
              "      <td>0.6195</td>\n",
              "      <td>0.6146</td>\n",
              "      <td>0.6127</td>\n",
              "      <td>0.6082</td>\n",
              "      <td>0.6112</td>\n",
              "      <td>0.6038</td>\n",
              "      <td>0.5911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>most_frequent</td>\n",
              "      <td>binary</td>\n",
              "      <td>0.7423</td>\n",
              "      <td>0.7447</td>\n",
              "      <td>0.7506</td>\n",
              "      <td>0.6402</td>\n",
              "      <td>0.6475</td>\n",
              "      <td>0.6485</td>\n",
              "      <td>0.6485</td>\n",
              "      <td>0.6544</td>\n",
              "      <td>0.6608</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6642</td>\n",
              "      <td>0.6544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>most_frequent</td>\n",
              "      <td>target</td>\n",
              "      <td>0.7550</td>\n",
              "      <td>0.7609</td>\n",
              "      <td>0.7604</td>\n",
              "      <td>0.5975</td>\n",
              "      <td>0.6048</td>\n",
              "      <td>0.6190</td>\n",
              "      <td>0.6156</td>\n",
              "      <td>0.6156</td>\n",
              "      <td>0.6137</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.6092</td>\n",
              "      <td>0.5945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>median</td>\n",
              "      <td>one_hot</td>\n",
              "      <td>0.7182</td>\n",
              "      <td>0.7197</td>\n",
              "      <td>0.7221</td>\n",
              "      <td>0.6613</td>\n",
              "      <td>0.6735</td>\n",
              "      <td>0.6740</td>\n",
              "      <td>0.6672</td>\n",
              "      <td>0.6657</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6662</td>\n",
              "      <td>0.6711</td>\n",
              "      <td>0.6485</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>median</td>\n",
              "      <td>hasing</td>\n",
              "      <td>0.7349</td>\n",
              "      <td>0.7472</td>\n",
              "      <td>0.7388</td>\n",
              "      <td>0.5582</td>\n",
              "      <td>0.5582</td>\n",
              "      <td>0.5763</td>\n",
              "      <td>0.5675</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.5719</td>\n",
              "      <td>0.5729</td>\n",
              "      <td>0.5665</td>\n",
              "      <td>0.5709</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>median</td>\n",
              "      <td>leave_one_out</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.9995</td>\n",
              "      <td>0.5960</td>\n",
              "      <td>0.6053</td>\n",
              "      <td>0.6190</td>\n",
              "      <td>0.6151</td>\n",
              "      <td>0.6112</td>\n",
              "      <td>0.6097</td>\n",
              "      <td>0.6117</td>\n",
              "      <td>0.6038</td>\n",
              "      <td>0.5911</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>median</td>\n",
              "      <td>binary</td>\n",
              "      <td>0.7442</td>\n",
              "      <td>0.7506</td>\n",
              "      <td>0.7496</td>\n",
              "      <td>0.6397</td>\n",
              "      <td>0.6470</td>\n",
              "      <td>0.6475</td>\n",
              "      <td>0.6485</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6608</td>\n",
              "      <td>0.6539</td>\n",
              "      <td>0.6642</td>\n",
              "      <td>0.6544</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>median</td>\n",
              "      <td>target</td>\n",
              "      <td>0.7590</td>\n",
              "      <td>0.7599</td>\n",
              "      <td>0.7594</td>\n",
              "      <td>0.5979</td>\n",
              "      <td>0.6048</td>\n",
              "      <td>0.6186</td>\n",
              "      <td>0.6156</td>\n",
              "      <td>0.6156</td>\n",
              "      <td>0.6141</td>\n",
              "      <td>0.6181</td>\n",
              "      <td>0.6087</td>\n",
              "      <td>0.5945</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Impute_strategy Nominal_encoding Radom_forest_50  ...  KNN_9 KNN_10 KNN_20\n",
              "0             mean          one_hot          0.7187  ... 0.6696 0.6721 0.6495\n",
              "1             mean           hasing          0.7383  ... 0.5739 0.5719 0.5719\n",
              "2             mean    leave_one_out          0.9995  ... 0.6122 0.6078 0.5925\n",
              "3             mean           binary          0.7452  ... 0.6564 0.6593 0.6549\n",
              "4             mean           target          0.7550  ... 0.6151 0.6117 0.5935\n",
              "5    most_frequent          one_hot          0.7138  ... 0.6662 0.6711 0.6485\n",
              "6    most_frequent           hasing          0.7432  ... 0.5734 0.5665 0.5709\n",
              "7    most_frequent    leave_one_out          0.9995  ... 0.6112 0.6038 0.5911\n",
              "8    most_frequent           binary          0.7423  ... 0.6539 0.6642 0.6544\n",
              "9    most_frequent           target          0.7550  ... 0.6181 0.6092 0.5945\n",
              "10          median          one_hot          0.7182  ... 0.6662 0.6711 0.6485\n",
              "11          median           hasing          0.7349  ... 0.5729 0.5665 0.5709\n",
              "12          median    leave_one_out          1.0000  ... 0.6117 0.6038 0.5911\n",
              "13          median           binary          0.7442  ... 0.6539 0.6642 0.6544\n",
              "14          median           target          0.7590  ... 0.6181 0.6087 0.5945\n",
              "\n",
              "[15 rows x 14 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fyTAq9CFgwuZ"
      },
      "source": [
        "# Problem 1 validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wCm2HvsoebU",
        "outputId": "a3f34d48-6350-4dc2-c699-72a359274f94"
      },
      "source": [
        "from sklearn import metrics\n",
        "import numpy as np\n",
        " \n",
        "\n",
        "classes = ['politics', 'business', 'tech', 'entertainment', 'sport']\n",
        "\n",
        "y_true = [0] * 141 + [1] * 167 + [2] * 133 + [3] * 128 + [4] * 166\n",
        "\n",
        "\n",
        "# row: actual, col: predict\n",
        "confusion_matrix = np.array([[140, 1, 0, 0, 0],\n",
        "                             [4, 160, 2, 0, 1],\n",
        "                             [1, 3, 128, 0, 1],\n",
        "                             [0, 0, 1, 127, 0],\n",
        "                             [0, 1, 0, 0, 165],])\n",
        "\n",
        "row_cnt, col_cnt = confusion_matrix.shape\n",
        "y_true = []\n",
        "y_pred = []\n",
        "for row in range(row_cnt):\n",
        "    y_true += [row] *  confusion_matrix[row, :].sum()\n",
        "    for col in range(col_cnt):\n",
        "        y_pred += [col] *  confusion_matrix[row, col] \n",
        "\n",
        "print(\"Confusion matix:\")\n",
        "print(metrics.confusion_matrix(y_true, y_pred))\n",
        "\n",
        "print(metrics.classification_report(y_true, y_pred, digits=4))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Confusion matix:\n",
            "[[140   1   0   0   0]\n",
            " [  4 160   2   0   1]\n",
            " [  1   3 128   0   1]\n",
            " [  0   0   1 127   0]\n",
            " [  0   1   0   0 165]]\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0     0.9655    0.9929    0.9790       141\n",
            "           1     0.9697    0.9581    0.9639       167\n",
            "           2     0.9771    0.9624    0.9697       133\n",
            "           3     1.0000    0.9922    0.9961       128\n",
            "           4     0.9880    0.9940    0.9910       166\n",
            "\n",
            "    accuracy                         0.9796       735\n",
            "   macro avg     0.9801    0.9799    0.9799       735\n",
            "weighted avg     0.9797    0.9796    0.9796       735\n",
            "\n"
          ]
        }
      ]
    }
  ]
}